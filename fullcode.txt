benchmark.py:
<code>
import os
import time
import requests
import pandas as pd
import json
from typing import List, Dict
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_recall
)
from langchain_groq import ChatGroq
from langchain_community.embeddings import HuggingFaceEmbeddings
# Ragas v0.1+ pattern
# We might need to handle specific versions, but let's try strict kwargs first

# --- Configuration ---
# --- Configuration ---
BACKEND_URL = "http://127.0.0.1:8000/api/query"
AUTH_URL = "http://127.0.0.1:8000/auth/login"
USER_EMAIL = "qa_user@example.com" 
USER_PASS = "password123"

GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# --- Questions for "Attention Is All You Need" ---
QUESTIONS = [
    "What is the dominant sequence transduction model based on?",
    "Describe the Transformer architecture.",
    "What is Scaled Dot-Product Attention?",
    "Why use self-attention?",
    "What dataset was used for training?",
    "How does the attention mechanism compare to recurrent layers?",
    "What is the role of the encoder and decoder stacks?",
    "Explain the Positional Encoding used in the model.",
    "What optimizer was used for training the Transformer?",
    "What are the advantages of the Transformer model over RNNs?",
    "What is multi-head attention?",
    "Did the model use convolutional layers?",
    "What hardware was used for training?",
    "How is the output probability distribution generated?",
    "What is label smoothing?",
] + [f"Test Question {i}" for i in range(16, 51)]

def login():
    """Authenticates and returns a session token."""
    # Use standard form data login for regular users (or check if updated to JSON)
    # The auth.py login endpoint expects OAuth2PasswordRequestForm (form-data)
    response = requests.post(AUTH_URL, data={"username": USER_EMAIL, "password": USER_PASS})
    if response.status_code != 200:
        raise Exception(f"Login failed: {response.text}")
    return response.json()["access_token"]

def run_benchmark():
    print("ğŸš€ Starting Benchmark...")
    
    if not GROQ_API_KEY:
        print("âŒ Error: GROQ_API_KEY environment variable not set.")
        return

    # 1. Setup RAGAS with Groq and HuggingFace Embeddings
    llm = ChatGroq(model="llama-3.3-70b-versatile", api_key=GROQ_API_KEY)
    
    # Initialize minimal embeddings for metrics that need them (Relevancy, Recall)
    # Using a small, fast model to avoid timeouts/memory issues
    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    print("ğŸ”‘ Authenticating...")
    try:
        token = login()
    except Exception as e:
        print(f"âŒ Auth failed: {e}")
        return

    headers = {"Authorization": f"Bearer {token}"}
    
    results_data = []
    
    print(f"ğŸ“Š Running {len(QUESTIONS)} questions...")
    
    for i, q in enumerate(QUESTIONS):
        print(f"[{i+1}/{len(QUESTIONS)}] Asking: {q}")
        
        try:
            # Call Backend
            payload = {"query": q}
            resp = requests.post(BACKEND_URL, json=payload, headers=headers)
            
            if resp.status_code != 200:
                print(f"  âŒ Request failed: {resp.status_code}")
                continue
                
            data = resp.json()
            answer = data.get("answer", "")
            sources = data.get("sources", [])
            metadata = data.get("metadata", {})
            
            # Extract contexts
            contexts = [s.get("page_content", "") for s in sources]
            
            # Prepare data for RAGAS
            results_data.append({
                "question": q,
                "answer": answer,
                "contexts": contexts,
                "ground_truth": "nan", # Placeholder for ground truth, required by some RAGAS metrics like context_recall
                "latency_retrieval": metadata.get("retrieval_time", 0),
                "latency_generation": metadata.get("generation_time", 0),
                "latency_total": metadata.get("total_time", 0)
            })
            
        except Exception as e:
            print(f"  âŒ Error: {e}")

    # 2. Convert to Dataset
    if not results_data:
        print("âŒ No results collected.")
        return

    df = pd.DataFrame(results_data)
    dataset = Dataset.from_pandas(df)
    
    print("ğŸ§  Running RAGAS Evaluation (Faithfulness, Answer Relevancy, Context Recall)...")
    
    try:
        scores = evaluate(
            dataset,
            metrics=[faithfulness, answer_relevancy, context_recall], # Added context_recall
            llm=llm, 
            embeddings=embeddings 
        )
        
        print("\nğŸ† Benchmark Results:")
        print(scores)
        
        # Save results
        df_scores = scores.to_pandas()
        final_df = pd.concat([df, df_scores], axis=1)
        final_df.to_csv("benchmark_results.csv", index=False)
        print("\nâœ… Results saved to benchmark_results.csv")
        
    except Exception as e:
        print(f"âŒ RAGAS Evaluation failed: {e}")
        print("Saving raw latency data anyway...")
        df.to_csv("benchmark_raw_latency.csv", index=False)

    # Calculate Latency Stats
    avg_retrieval = df["latency_retrieval"].mean()
    avg_gen = df["latency_generation"].mean()
    avg_total = df["latency_total"].mean()
    
    print(f"\nâ±ï¸ Latency Metrics:")
    print(f"  Average Retrieval: {avg_retrieval:.4f}s")
    print(f"  Average Generation: {avg_gen:.4f}s")
    print(f"  Average Total:      {avg_total:.4f}s")
    
if __name__ == "__main__":
    run_benchmark()

</code>

README.md:
<code>
# AI Cloud Drive: Intelligent Document Management with Domain Aware RAG

> **A document management platform integrating a multi stage retrieval pipeline with strict domain specific guardrails.**

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docker.com)
[![LLM](https://img.shields.io/badge/LLM-Groq%20Llama3-orange.svg)](https://groq.com)

---

## System Design Philosophy

This project explores the engineering challenges of building a **Retrieval Augmented Generation (RAG)** system that prioritizes **correctness over generic capability**.

Most RAG systems fail in domain specific contexts (e.g., confusing a "Stack" with a "Queue" in Computer Science) because they rely solely on probabilistic generation. This system addresses that failure mode by introducing a **deterministic rule engine** and **semantic routing layer** before and after the generative step.

**Core Design Principles:**
1.  **Separation of Concerns**: Retrieval, Reasoning, and formatting are decoupled stages.
2.  **Explicit Guardrails**: Domain rules are hard coded constraints, not learned behaviors.
3.  **Fail Fast Validation**: Answers are self validated against rigid criteria before being returned to the user.

---

## Architecture & Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           FRONTEND                                   â”‚
â”‚  [Auth UI]       [File Manager]       [Chat Interface]              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ File Upload                           â”‚ Query
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API GATEWAY (FastAPI)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ingestion   â”‚        â”‚  Retrieval   â”‚       â”‚  Orchestration      â”‚
â”‚   Service    â”‚        â”‚    Engine    â”‚       â”‚    Layer            â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                       â”‚                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PERSISTENCE LAYER                                â”‚
â”‚  [MinIO (Blob)]   [ChromaDB (Vector)]   [PostgreSQL (Relational)]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## RAG Pipeline Design (The "Guardrails")

The core contribution is a **multi stage pipeline** (implemented as seven explicit stages) designed to reduce hallucination risk and enforce explicit domain constraints.

### 1. Document Classification (Deterministic)
**Problem:** Treating an Exam Paper like a Research Paper leads to wrong answer formats.
**Solution:** Regex based classifier detects content type (`EXAM`, `RESEARCH`, `LEGAL`) from file headers and keywords.
*   *Constraint:* Relies on textual markers; OCR failures will degrade classification.

### 2. Intent Routing (Semantic)
**Problem:** Users asking to "Summarize" get "Explanation" answers.
**Solution:** Keyword density analysis maps query to intent (`SUMMARIZE`, `ANSWER_QUESTION`, `COMPARE`).

### 3. Domain Reference Constraints
**Problem:** LLMs often respect user prompts over domain truths (e.g., "Tell me how a Stack works FIFO").
**Solution:** Injected rule engine ensures:
*   `Data Structures`: Queue=FIFO, Stack=LIFO.
*   `Medical`: No dosage extrapolation.
*   `Legal`: verbatim citation required.

### 4. Context Sufficiency Check
**Problem:** Answering with low relevance chunks causes hallucinations.
**Solution:** Pre generation gate that rejects retrieval sets with relevance scores < 0.3.

### 5. Answer Self Validation
**Problem:** Generative models can produce plausible but wrong answers.
**Solution:** Post generation pass checks the output against the active Domain Rules. If a rule is violated (e.g., "Queue is LIFO"), the answer is discarded and logged.

---

## Engineering Tradeoffs & Limitations

### Synchronous vs Asynchronous Processing
*   **Current Design**: Ingestion is asynchronous (Celery) to handle large PDF parsing without blocking the API. Querying is synchronous for user experience.
*   **Tradeoff**: Synchronous querying limits the complexity of the validation chain. Adding more verification steps adds linear latency. Current P99 latency is ~2s.

### Vector Search vs Keyword Search
*   **Current Design**: Uses Hybrid Search (Vector + Keyword) for retrieval.
*   **Tradeoff**: Vector search captures semantics but misses specific acronyms (e.g., "TCP" vs "transport protocol"). Keyword search fixes this but is brittle to synonyms. The system prioritizes Recall over Precision to ensure the LLM has context.

### Rule Engine Scalability
*   **Limitation**: The Domain Rule Engine is currently a hard coded dictionary.
*   **Scalability Issue**: Adding new domains (e.g., Chemistry) requires code changes. A production evolution would move these rules to a database or usage of a Rule Engine service (e.g., OPA).

---

## Stack Selection & Rationale

| Component | Choice | Rationale |
|-----------|--------|-----------|
| **Backend** | **FastAPI** | Native async support allows handling 100+ concurrent connections per worker (vs Flask/Django). |
| **Vector DB** | **ChromaDB** | Embedded mode simplifies deployment vs Pinecone/Milvus for this scale. |
| **LLM** | **Groq (Llama 3)** | Chosen for lower inference latency relative to comparable hosted LLMs. |
| **Task Queue** | **Celery/Redis** | Decouples CPU heavy PDF parsing from the I/O bound Web API. |

---

## System Observability

To move beyond "works on my machine", the system implements structured logging for failure analysis:

```json
{
  "timestamp": "2023-10-27T10:00:00Z",
  "component": "RAG_Validator",
  "status": "FAILURE",
  "intent": "EXPLAIN_CONCEPT",
  "violation": "ADT_CONSTRAINT_STACK_LIFO",
  "query_latency_ms": 1450
}
```
*   **Purpose**: Allows identifying which domain rules trigger most often, indicating where the LLM struggles naturally.

---

## Setup & Replication

**Prerequisites:** Docker, Docker Compose, Groq API Key.

```bash
# 1. Configuration
cp .env.example .env
# Set GROQ_API_KEY in .env

# 2. Deployment
docker-compose up --build -d

# 3. Verification
# Backend Health
curl localhost:8000/health
```

---

## Author Note

This project serves as a case study in **constraining Large Language Models** for domains requiring stronger correctness guarantees. It demonstrates that reliability comes not from better prompting, but from better system architecture and rigid validation layers.

</code>

deploy.sh:
<code>
#!/bin/bash

# AI Cloud Drive - Deployment Script
set -e

echo "AI Cloud Drive Deployment Script"
echo "================================="

# Check for Docker
if ! command -v docker &> /dev/null; then
    echo "Error: Docker is not installed"
    exit 1
fi

# Check for Docker Compose
if ! command -v docker-compose &> /dev/null; then
    echo "Error: Docker Compose is not installed"
    exit 1
fi

# Environment
ENV=${1:-development}
echo "Deploying in $ENV mode"

# Create .env if not exists
if [ ! -f .env ]; then
    echo "Creating .env from .env.example"
    cp .env.example .env
    echo "Warning: Please update .env with production values!"
fi

# Create certs directory
mkdir -p certs

case $ENV in
    development)
        echo "Starting development environment..."
        docker-compose up --build -d
        ;;
    production)
        echo "Starting production environment..."
        docker-compose -f docker-compose.yml -f docker-compose.prod.yml up --build -d
        ;;
    *)
        echo "Error: Unknown environment: $ENV"
        echo "Usage: ./deploy.sh [development|production]"
        exit 1
        ;;
esac

echo ""
echo "Waiting for services to be healthy..."
sleep 10

# Check health
echo ""
echo "Service Health:"
docker-compose ps

echo ""
echo "Deployment complete!"
echo ""
echo "Access Points:"
echo "   - App:      http://localhost"
echo "   - API:      http://localhost:8000"
echo "   - Docs:     http://localhost:8000/docs"
echo "   - MinIO:    http://localhost:9001"
echo ""
echo "Logs: docker-compose logs -f [service]"
echo "Stop: docker-compose down"

</code>

docker-compose.yml:
<code>
services:
  backend:
    build: ./backend
    container_name: ai_drive_backend
    env_file:
      - .env
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
      - minio
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/aiclouddrive
      - SECRET_KEY=your-super-secret-key-change-this
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - CHROMA_HOST=chromadb
      - REDIS_URL=redis://redis:6379/0
      - GROQ_API_KEY=${GROQ_API_KEY}
      - ENVIRONMENT=development
      - DEBUG=True
      - CORS_ORIGINS=*
      - ADMIN_USERNAME=${ADMIN_USERNAME:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
    restart: always

  celery_worker:
    build: ./backend
    container_name: ai_drive_celery
    command: celery -A app.tasks.celery_app.celery worker --loglevel=info
    depends_on:
      - db
      - redis
      - minio
      - backend
    volumes:
      - ./backend:/app
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/aiclouddrive
      - SECRET_KEY=your-super-secret-key-change-this
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - CHROMA_HOST=chromadb
      - REDIS_URL=redis://redis:6379/0
      - GROQ_API_KEY=${GROQ_API_KEY}
    restart: always

  db:
    image: postgres:15-alpine
    container_name: ai_drive_db
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=aiclouddrive
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always

  minio:
    image: minio/minio
    container_name: ai_drive_minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    restart: always

  redis:
    image: redis:7-alpine
    container_name: ai_drive_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: always

  chromadb:
    image: chromadb/chroma
    container_name: ai_drive_chroma
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma
    restart: always

  frontend:
    build: ./frontend
    container_name: ai_drive_frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    restart: always

volumes:
  postgres_data:
  minio_data:
  redis_data:
  chroma_data:

</code>

docker-compose.prod.yml:
<code>
version: '3.8'

# Production configuration with scaling
# Use: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

services:
  backend:
    environment:
      - ENVIRONMENT=production
      - DEBUG=False
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  celery_worker:
    command: celery -A app.tasks.celery_app.celery worker --loglevel=warning --concurrency=4
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  db:
    environment:
      - POSTGRES_PASSWORD=${DB_PASSWORD:-strongpassword}
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  redis:
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD:-redispassword}
    deploy:
      resources:
        limits:
          memory: 256M

  nginx:
    ports:
      - "80:80"
      - "443:443"
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'

</code>

frontend/admin_fix.js:
<code>
// Add this function after showUserChats function in admin.js

/**
 * Show all files for a specific user
 * @param {number} userId - The user ID
 * @param {string} userEmail - The user's email address
 */
function showUserFiles(userId, userEmail) {
    console.log(`showUserFiles called with userId=${userId}, userEmail=${userEmail}`);

    // Filter files by user email
    const userFiles = filesData.filter(file => file.owner_email === userEmail);

    console.log(`Found ${userFiles.length} files for user`);

    // Simply scroll to files table and highlight user's files
    const searchInput = document.getElementById('searchFiles');
    if (searchInput) {
        searchInput.value = userEmail;
        searchInput.focus();
        filterFiles();

        // Scroll to files section
        const filesCard = document.querySelector('.table-card:nth-of-type(2)');
        if (filesCard) {
            filesCard.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }

        showToast(`Showing ${userFiles.length} files for ${userEmail}`);
    }
}

</code>

frontend/index.html:
<code>
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Cloud Drive - AI Powered File Storage</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css?v=2">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>â˜ï¸</text></svg>">
</head>

<body>
  <!-- Auth Container -->
  <div id="auth-container" class="auth-container">
    <div class="auth-card">
      <div class="auth-logo">
        <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2">
          <path d="M18 10h-1.26A8 8 0 1 0 9 20h9a5 5 0 0 0 0-10z"></path>
        </svg>
      </div>
      <h1 class="auth-title" id="auth-title">Welcome back</h1>
      <p class="auth-subtitle" id="auth-subtitle">Sign in to access your cloud drive</p>

      <div id="auth-error" class="alert alert-error" style="display: none;"></div>

      <form id="auth-form">
        <div class="form-group">
          <label class="form-label">Email</label>
          <div class="input-with-icon">
            <span class="input-icon">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
                <polyline points="22,6 12,13 2,6"></polyline>
              </svg>
            </span>
            <input type="email" id="email" class="form-input" placeholder="Enter your email" required>
          </div>
        </div>

        <div class="form-group">
          <label class="form-label">Password</label>
          <div class="input-with-icon">
            <span class="input-icon">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <rect x="3" y="11" width="18" height="11" rx="2" ry="2"></rect>
                <path d="M7 11V7a5 5 0 0 1 10 0v4"></path>
              </svg>
            </span>
            <input type="password" id="password" class="form-input" placeholder="Enter your password" required
              minlength="6">
          </div>
        </div>

        <button type="submit" class="btn btn-primary btn-full" id="auth-btn">
          Sign In
        </button>
      </form>

      <p class="auth-footer">
        <span id="auth-toggle-text">Don't have an account?</span>
        <a href="#" id="auth-toggle">Sign up</a>
      </p>
    </div>
  </div>

  <!-- Dashboard Container -->
  <div id="dashboard-container" class="app-container" style="display: none;">
    <!-- Navbar -->
    <nav class="navbar">
      <div class="navbar-brand">
        <div class="navbar-logo">
          <svg width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2">
            <path d="M18 10h-1.26A8 8 0 1 0 9 20h9a5 5 0 0 0 0-10z"></path>
          </svg>
        </div>
        <span>Cloud Drive</span>
      </div>
      <div class="navbar-actions">
        <div class="profile-dropdown">
          <button class="btn btn-secondary profile-toggle" id="profile-toggle">
            <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
              style="margin-right: 6px;">
              <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
              <circle cx="12" cy="7" r="4"></circle>
            </svg>
            Profile
            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
              style="margin-left: 6px;">
              <polyline points="6 9 12 15 18 9"></polyline>
            </svg>
          </button>
          <div class="profile-menu" id="profile-menu">
            <button class="profile-menu-item" id="user-profile-btn">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
                <circle cx="12" cy="7" r="4"></circle>
              </svg>
              User Profile
            </button>
            <div class="profile-menu-divider"></div>
            <button class="profile-menu-item" id="logout-btn">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M9 21H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h4"></path>
                <polyline points="16 17 21 12 16 7"></polyline>
                <line x1="21" y1="12" x2="9" y2="12"></line>
              </svg>
              Sign Out
            </button>
          </div>
        </div>
      </div>
    </nav>

    <!-- Main Layout -->
    <div class="dashboard">
      <!-- Sidebar -->
      <aside class="sidebar">
        <div class="sidebar-section">
          <button class="btn btn-primary btn-full" id="upload-btn" style="margin-bottom: 24px;">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
              <line x1="12" y1="5" x2="12" y2="19"></line>
              <line x1="5" y1="12" x2="19" y2="12"></line>
            </svg>
            New Upload
          </button>

          <nav class="sidebar-nav">
            <div class="sidebar-item active" data-tab="files">
              <svg class="sidebar-item-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path>
              </svg>
              My Files
            </div>
            <div class="sidebar-item" data-tab="chat">
              <svg class="sidebar-item-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
              </svg>
              AI Assistant
            </div>
          </nav>
        </div>

        <div class="sidebar-section">
          <div class="sidebar-title">Storage</div>
          <div style="padding: 0 12px;">
            <div class="storage-bar">
              <div class="storage-fill" id="storage-fill"></div>
            </div>
            <p class="storage-text"><span id="file-count">0</span> files uploaded</p>
          </div>
        </div>
      </aside>

      <!-- Main Content -->
      <main class="main-content">
        <!-- Files Tab -->
        <div id="files-tab">
          <!-- Upload Zone -->
          <div class="upload-zone" id="upload-zone">
            <input type="file" id="file-input" accept=".pdf,.txt,.md" style="display: none;">
            <div class="upload-icon">
              <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                <polyline points="17 8 12 3 7 8"></polyline>
                <line x1="12" y1="3" x2="12" y2="15"></line>
              </svg>
            </div>
            <p class="upload-title">Drop files here or <span class="text-accent">browse</span></p>
            <p class="upload-subtitle">Supports PDF, TXT, Markdown â€¢ Max 50MB</p>
          </div>

          <!-- Upload Progress -->
          <div id="upload-progress" class="upload-progress" style="display: none;">
            <div class="upload-progress-bar">
              <div class="upload-progress-fill" id="progress-fill"></div>
            </div>
            <p class="upload-progress-text">Uploading... <span id="progress-percent">0</span>%</p>
          </div>

          <!-- Files Grid -->
          <div id="files-section" style="margin-top: 24px;">
            <div class="section-header">
              <h2 class="section-title">Recent Files</h2>
              <button class="btn btn-ghost" id="refresh-btn">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                  <polyline points="23 4 23 10 17 10"></polyline>
                  <path d="M20.49 15a9 9 0 1 1-2.12-9.36L23 10"></path>
                </svg>
              </button>
            </div>
            <div id="files-grid" class="files-grid"></div>
            <div id="empty-state" class="empty-state">
              <div class="empty-icon">
                <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
                  <path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path>
                </svg>
              </div>
              <h3>No files yet</h3>
              <p>Upload your first file to get started</p>
            </div>
          </div>
        </div>

        <!-- Chat Tab -->
        <div id="chat-tab" style="display: none;">
          <div class="chat-container">
            <div class="chat-header">
              <div class="chat-header-content">
                <div class="chat-avatar">
                  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2">
                    <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
                  </svg>
                </div>
                <div>
                  <h3>AI Assistant</h3>
                  <p>Ask questions about your documents</p>
                </div>
              </div>
            </div>

            <!-- Document Selector -->
            <div class="doc-selector" id="doc-selector">
              <div class="doc-selector-header">
                <span class="doc-selector-title">ğŸ“„ Search in: <span id="selected-count">All documents</span></span>
                <div class="doc-selector-actions">
                  <button class="btn-link" id="select-all-docs">Select All</button>
                  <button class="btn-link" id="clear-all-docs">Clear All</button>
                </div>
              </div>
              <div class="doc-selector-list" id="doc-list"></div>
            </div>

            <div class="chat-messages" id="chat-messages">
              <div class="chat-empty">
                <div class="chat-empty-icon">
                  <svg width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
                    <circle cx="12" cy="12" r="10"></circle>
                    <path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path>
                    <line x1="12" y1="17" x2="12.01" y2="17"></line>
                  </svg>
                </div>
                <h3>How can I help you?</h3>
                <p>I can answer questions about your uploaded documents</p>
                <div class="chat-suggestions">
                  <button class="btn btn-secondary suggestion-btn">Summarize my files</button>
                  <button class="btn btn-secondary suggestion-btn">Find key points</button>
                  <button class="btn btn-secondary suggestion-btn">Search for topics</button>
                </div>
              </div>
            </div>

            <div class="chat-input-container">
              <form id="chat-form" class="chat-input-wrapper">
                <input type="text" id="chat-input" class="chat-input"
                  placeholder="Ask a question about your documents..." disabled>
                <button type="submit" class="btn btn-primary btn-icon chat-send-btn" disabled>
                  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <line x1="22" y1="2" x2="11" y2="13"></line>
                    <polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
                  </svg>
                </button>
              </form>
            </div>
          </div>
        </div>


    </div>

    <!-- Mobile Navigation -->
    <nav class="mobile-nav">
      <div class="mobile-nav-item active" data-tab="files">
        <svg width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path>
        </svg>
        <span>Files</span>
      </div>
      <div class="mobile-nav-item" data-tab="chat">
        <svg width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
        </svg>
        <span>AI Chat</span>
      </div>
    </nav>
  </div>

  <!-- Toast -->
  <div id="toast" class="toast"></div>

  <!-- Profile Modal -->
  <div id="profile-modal" class="modal-overlay">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title">User Profile</h2>
        <button class="modal-close" onclick="closeProfileModal()">
          <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <line x1="18" y1="6" x2="6" y2="18"></line>
            <line x1="6" y1="6" x2="18" y2="18"></line>
          </svg>
        </button>
      </div>
      <div id="profile-details">
        <div style="text-align: center; margin-bottom: 24px;">
          <div class="chat-avatar" style="width: 80px; height: 80px; margin: 0 auto 16px; font-size: 32px;">
            ğŸ‘¤
          </div>
          <h3 id="profile-email" style="font-size: 1.125rem;">loading...</h3>
          <p id="profile-role" style="color: var(--text-muted); font-size: 0.875rem;">User</p>
        </div>
        <div style="background: var(--bg-tertiary); padding: 16px; border-radius: var(--radius-md);">
          <div style="display: flex; justify-content: space-between; margin-bottom: 8px;">
            <span style="color: var(--text-secondary);">Member since</span>
            <strong id="profile-date">-</strong>
          </div>
        </div>
      </div>
    </div>
  </div>

  <script src="app.js"></script>
</body>

</html>
</code>

frontend/admin.html:
<code>
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Admin Dashboard - AI Cloud Drive</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #F8FAFC;
            --bg-card: #FFFFFF;
            --border: #E5E7EB;
            --border-light: #F1F5F9;
            --text: #0F172A;
            --text-secondary: #374151;
            --text-muted: #64748B;
            --text-faint: #94A3B8;
            --accent: #2563EB;
            --success: #16A34A;
            --error: #DC2626;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            font-size: 13px;
            line-height: 1.5;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 24px;
        }

        /* Header */
        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 24px;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--border);
        }

        .header h1 {
            font-size: 18px;
            font-weight: 600;
            margin-bottom: 2px;
        }

        .header-subtitle {
            font-size: 12px;
            color: var(--text-muted);
        }

        .btn {
            padding: 8px 16px;
            font-size: 12px;
            border: 1px solid var(--border);
            border-radius: 6px;
            background: var(--bg-card);
            color: var(--text-secondary);
            cursor: pointer;
            font-weight: 500;
            transition: all 0.2s;
        }

        .btn:hover {
            background: var(--bg);
        }

        .btn-primary {
            background: var(--accent);
            color: white;
            border-color: var(--accent);
        }

        .btn-primary:hover {
            background: #1d4ed8;
        }

        /* Login Container */
        .admin-login-container {
            display: flex;
            height: 100vh;
            align-items: center;
            justify-content: center;
            background: var(--bg);
        }

        .auth-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 40px;
            width: 100%;
            max-width: 400px;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .auth-logo {
            text-align: center;
            margin-bottom: 24px;
        }

        .auth-title {
            font-size: 20px;
            font-weight: 600;
            text-align: center;
            margin-bottom: 8px;
        }

        .auth-subtitle {
            font-size: 13px;
            color: var(--text-muted);
            text-align: center;
            margin-bottom: 24px;
        }

        .form-group {
            margin-bottom: 16px;
        }

        .form-label {
            display: block;
            font-size: 12px;
            font-weight: 500;
            color: var(--text-secondary);
            margin-bottom: 6px;
        }

        .form-input {
            width: 100%;
            padding: 10px 12px;
            font-size: 13px;
            border: 1px solid var(--border);
            border-radius: 6px;
            background: var(--bg-card);
            color: var(--text);
        }

        .form-input:focus {
            outline: none;
            border-color: var(--accent);
        }

        .alert {
            padding: 10px 14px;
            border-radius: 6px;
            font-size: 12px;
            margin-bottom: 16px;
        }

        .alert-error {
            background: #FEF2F2;
            border: 1px solid #FECACA;
            color: #991B1B;
        }

        /* KPI Grid */
        .kpi-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 16px;
            margin-bottom: 24px;
        }

        .kpi-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 20px;
        }

        .kpi-value {
            font-size: 32px;
            font-weight: 600;
            color: var(--text);
            line-height: 1;
        }

        .kpi-label {
            font-size: 12px;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-top: 8px;
        }

        /* Table */
        .table-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 8px;
            overflow: hidden;
        }

        .table-toolbar {
            padding: 14px 20px;
            border-bottom: 1px solid var(--border);
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: var(--bg);
        }

        .table-title {
            font-size: 13px;
            font-weight: 600;
            color: var(--text-secondary);
        }

        table {
            width: 100%;
            border-collapse: collapse;
        }

        th {
            text-align: left;
            padding: 12px 20px;
            font-size: 11px;
            font-weight: 600;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.5px;
            background: var(--bg);
            border-bottom: 1px solid var(--border);
        }

        td {
            padding: 16px 20px;
            font-size: 13px;
            border-bottom: 1px solid var(--border-light);
            color: var(--text-secondary);
        }

        tr:last-child td {
            border-bottom: none;
        }

        tr:hover {
            background: var(--bg);
        }

        .file-badge {
            display: inline-block;
            padding: 4px 8px;
            font-size: 11px;
            background: var(--border-light);
            border-radius: 4px;
            margin: 2px;
            cursor: pointer;
            transition: all 0.2s;
        }

        .file-badge:hover {
            background: var(--accent);
            color: white;
        }

        .btn-small {
            padding: 6px 12px;
            font-size: 11px;
            border-radius: 4px;
        }

        /* Modal */
        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.5);
            z-index: 1000;
            align-items: center;
            justify-content: center;
        }

        .modal-content {
            background: white;
            border-radius: 12px;
            width: 90%;
            max-width: 800px;
            max-height: 80vh;
            overflow-y: auto;
            padding: 24px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
        }

        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--border);
        }

        .modal-header h3 {
            font-size: 16px;
            font-weight: 600;
        }

        .close {
            cursor: pointer;
            font-size: 24px;
            color: var(--text-muted);
        }

        .close:hover {
            color: var(--text);
        }

        .chat-message {
            margin-bottom: 16px;
            padding: 12px;
            border-radius: 8px;
            border-left: 3px solid var(--accent);
            background: var(--bg);
        }

        .chat-query {
            font-weight: 500;
            color: var(--text);
            margin-bottom: 6px;
        }

        .chat-answer {
            color: var(--text-secondary);
            font-size: 12px;
        }

        .chat-time {
            font-size: 11px;
            color: var(--text-faint);
            margin-top: 6px;
        }

        .empty-state {
            text-align: center;
            padding: 40px;
            color: var(--text-faint);
            font-size: 13px;
        }

        .text-muted {
            color: var(--text-muted);
        }

        .toast {
            position: fixed;
            bottom: 24px;
            right: 24px;
            background: var(--text);
            color: white;
            padding: 12px 20px;
            border-radius: 8px;
            font-size: 13px;
            opacity: 0;
            transition: opacity 0.3s;
            z-index: 2000;
        }

        .toast.show {
            opacity: 1;
        }

        .toast.error {
            background: var(--error);
        }

        .badge {
            display: inline-block;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
        }

        .badge.success {
            background: #DCFCE7;
            color: #166534;
        }

        .badge.error {
            background: #FEF2F2;
            color: #991B1B;
        }

        .badge.warning {
            background: #FEF9C3;
            color: #854D0E;
        }
    </style>
</head>

<body>
    <!-- Login -->
    <div id="admin-login-container" class="admin-login-container">
        <div class="auth-card">
            <div class="auth-logo">
                <span style="font-size: 48px;">ğŸ›¡ï¸</span>
            </div>
            <h1 class="auth-title">Admin Access</h1>
            <p class="auth-subtitle">Restricted Area</p>
            <div id="auth-error" class="alert alert-error" style="display: none;"></div>
            <form id="admin-login-form">
                <div class="form-group">
                    <label class="form-label">Username</label>
                    <input type="text" id="admin-username" class="form-input" required>
                </div>
                <div class="form-group">
                    <label class="form-label">Password</label>
                    <input type="password" id="admin-password" class="form-input" required>
                </div>
                <button type="submit" class="btn btn-primary" style="width: 100%;">Login</button>
            </form>
        </div>
    </div>

    <!-- Dashboard -->
    <div id="admin-dashboard" style="display: none;">
        <div class="container">
            <header class="header">
                <div>
                    <h1>ğŸ›¡ï¸ Admin Dashboard</h1>
                    <div class="header-subtitle">User Management & Analytics</div>
                </div>
                <button class="btn" id="logout-btn">Sign Out</button>
            </header>

            <!-- KPIs -->
            <div class="kpi-grid">
                <div class="kpi-card">
                    <div class="kpi-value" id="totalUsers">â€”</div>
                    <div class="kpi-label">Total Users</div>
                </div>
                <div class="kpi-card">
                    <div class="kpi-value" id="totalFiles">â€”</div>
                    <div class="kpi-label">Total Files</div>
                </div>
                <div class="kpi-card">
                    <div class="kpi-value" id="totalChats">â€”</div>
                    <div class="kpi-label">Total Queries</div>
                </div>
            </div>

            <!-- Users Table -->
            <div class="table-card">
                <div class="table-toolbar">
                    <span class="table-title">All Users</span>
                    <input type="text" id="searchUsers" placeholder="Search users..."
                        style="padding: 6px 12px; border: 1px solid var(--border); border-radius: 6px; font-size: 12px;"
                        oninput="filterUsers()">
                </div>
                <table>
                    <thead>
                        <tr>
                            <th>User</th>
                            <th>Status</th>
                            <th>Usage</th>
                            <th>Last Login</th>
                            <th>Actions</th>
                        </tr>
                    </thead>
                    <tbody id="usersTable">
                        <tr>
                            <td colspan="5" class="empty-state">Loading users...</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <!-- Files Table -->
            <div class="table-card" style="margin-top: 24px;">
                <div class="table-toolbar">
                    <span class="table-title">All Files</span>
                    <input type="text" id="searchFiles" placeholder="Search files..."
                        style="padding: 6px 12px; border: 1px solid var(--border); border-radius: 6px; font-size: 12px;"
                        oninput="filterFiles()">
                </div>
                <table>
                    <thead>
                        <tr>
                            <th>Filename</th>
                            <th>Owner</th>
                            <th>Size</th>
                            <th>Type</th>
                            <th>Uploaded</th>
                            <th>Actions</th>
                        </tr>
                    </thead>
                    <tbody id="filesTable">
                        <tr>
                            <td colspan="6" class="empty-state">Loading files...</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <!-- Audit Logs -->
            <div class="table-card" style="margin-top: 24px;">
                <div class="table-toolbar">
                    <span class="table-title">Audit Logs</span>
                </div>
                <table>
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Actor</th>
                            <th>Action</th>
                            <th>Target</th>
                            <th>Details</th>
                        </tr>
                    </thead>
                    <tbody id="auditTable">
                        <tr>
                            <td colspan="5" class="empty-state">Loading logs...</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </div>

    <!-- Chat Modal -->
    <div id="chatModal" class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <h3 id="chatModalTitle">User Chats</h3>
                <span class="close" onclick="closeChatModal()">&times;</span>
            </div>
            <div id="chatModalContent">
                <div class="empty-state">Loading chats...</div>
            </div>
        </div>
    </div>

    <!-- Profile Modal -->
    <div id="profileModal" class="modal">
        <div class="modal-content" style="max-width: 600px;">
            <div class="modal-header">
                <h3 id="profileModalTitle">User Profile</h3>
                <span class="close" onclick="closeProfileModal()">&times;</span>
            </div>
            <div id="profileModalContent">
                <div class="empty-state">Loading profile...</div>
            </div>
        </div>
    </div>

    <div id="toast" class="toast"></div>

    <script src="admin.js?v=3"></script>
</body>

</html>
</code>

frontend/styles.css:
<code>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

:root {
    --bg-primary: #f8fafc;
    --bg-secondary: #ffffff;
    --bg-tertiary: #f1f5f9;
    --bg-hover: #e2e8f0;
    --text-primary: #1e293b;
    --text-secondary: #64748b;
    --text-muted: #94a3b8;
    --accent-blue: #4285f4;
    --accent-blue-hover: #3b78e7;
    --accent-green: #34a853;
    --accent-yellow: #fbbc04;
    --accent-red: #ea4335;
    --border-light: #e2e8f0;
    --border-medium: #cbd5e1;
    --shadow-sm: 0 1px 2px rgba(0, 0, 0, 0.05);
    --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
    --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
    --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
    --radius-sm: 8px;
    --radius-md: 12px;
    --radius-lg: 16px;
    --radius-xl: 24px;
    --radius-full: 9999px;
}

body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    background: var(--bg-primary);
    color: var(--text-primary);
    line-height: 1.6;
    -webkit-font-smoothing: antialiased;
}

/* Buttons */
.btn {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    gap: 8px;
    padding: 10px 20px;
    font-size: 0.875rem;
    font-weight: 500;
    font-family: inherit;
    border-radius: var(--radius-full);
    border: none;
    cursor: pointer;
    transition: all 0.2s ease;
    text-decoration: none;
}

.btn-primary {
    background: var(--accent-blue);
    color: white;
}

.btn-primary:hover {
    background: var(--accent-blue-hover);
    box-shadow: var(--shadow-md);
}

.btn-primary:disabled {
    opacity: 0.6;
    cursor: not-allowed;
}

.btn-secondary {
    background: var(--bg-tertiary);
    color: var(--text-primary);
}

.btn-secondary:hover {
    background: var(--bg-hover);
}

.btn-ghost {
    background: transparent;
    color: var(--text-secondary);
}

.btn-ghost:hover {
    background: var(--bg-tertiary);
}

.btn-icon {
    width: 48px;
    height: 48px;
    padding: 0;
}

.btn-full {
    width: 100%;
}

/* Forms */
.form-group {
    margin-bottom: 20px;
}

.form-label {
    display: block;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
    margin-bottom: 8px;
}

.form-input {
    width: 100%;
    padding: 12px 16px;
    font-size: 1rem;
    font-family: inherit;
    border: 1px solid var(--border-medium);
    border-radius: var(--radius-md);
    background: var(--bg-secondary);
    color: var(--text-primary);
    transition: all 0.2s ease;
}

.form-input:focus {
    outline: none;
    border-color: var(--accent-blue);
    box-shadow: 0 0 0 3px rgba(66, 133, 244, 0.15);
}

.form-input::placeholder {
    color: var(--text-muted);
}

.input-with-icon {
    position: relative;
}

.input-icon {
    position: absolute;
    left: 16px;
    top: 50%;
    transform: translateY(-50%);
    color: var(--text-muted);
}

.input-with-icon .form-input {
    padding-left: 48px;
}

/* Alerts */
.alert {
    padding: 12px 16px;
    border-radius: var(--radius-md);
    font-size: 0.875rem;
    margin-bottom: 16px;
}

.alert-error {
    background: #fef2f2;
    color: #991b1b;
    border: 1px solid #fecaca;
}

.alert-success {
    background: #f0fdf4;
    color: #166534;
    border: 1px solid #bbf7d0;
}

/* Auth */
.auth-container {
    min-height: 100vh;
    display: flex;
    align-items: center;
    justify-content: center;
    background: linear-gradient(135deg, #e0f2fe 0%, #f0f9ff 50%, #faf5ff 100%);
    padding: 24px;
}

.auth-card {
    width: 100%;
    max-width: 440px;
    background: var(--bg-secondary);
    border-radius: var(--radius-xl);
    box-shadow: var(--shadow-xl);
    padding: 48px;
}

.auth-logo {
    width: 56px;
    height: 56px;
    background: linear-gradient(135deg, var(--accent-blue) 0%, #7c3aed 100%);
    border-radius: var(--radius-lg);
    display: flex;
    align-items: center;
    justify-content: center;
    margin: 0 auto 24px;
}

.auth-title {
    font-size: 1.5rem;
    font-weight: 600;
    text-align: center;
    margin-bottom: 8px;
}

.auth-subtitle {
    font-size: 0.9375rem;
    color: var(--text-secondary);
    text-align: center;
    margin-bottom: 32px;
}

.auth-footer {
    text-align: center;
    margin-top: 24px;
    font-size: 0.875rem;
    color: var(--text-secondary);
}

.auth-footer a {
    color: var(--accent-blue);
    text-decoration: none;
    font-weight: 500;
    margin-left: 4px;
}

.auth-footer a:hover {
    text-decoration: underline;
}

/* App Layout */
.app-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
}

/* Navbar */
.navbar {
    background: var(--bg-secondary);
    border-bottom: 1px solid var(--border-light);
    padding: 12px 24px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    position: sticky;
    top: 0;
    z-index: 100;
}

.navbar-brand {
    display: flex;
    align-items: center;
    gap: 12px;
    font-size: 1.25rem;
    font-weight: 600;
}

.navbar-logo {
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, var(--accent-blue) 0%, #7c3aed 100%);
    border-radius: var(--radius-md);
    display: flex;
    align-items: center;
    justify-content: center;
}

/* Dashboard */
.dashboard {
    display: flex;
    min-height: calc(100vh - 65px);
}

/* Sidebar */
.sidebar {
    width: 280px;
    background: var(--bg-secondary);
    border-right: 1px solid var(--border-light);
    padding: 24px 16px;
    flex-shrink: 0;
}

.sidebar-section {
    margin-bottom: 32px;
}

.sidebar-title {
    font-size: 0.75rem;
    font-weight: 600;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.05em;
    padding: 0 12px;
    margin-bottom: 8px;
}

.sidebar-nav {
    display: flex;
    flex-direction: column;
    gap: 4px;
}

.sidebar-item {
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 12px;
    border-radius: var(--radius-md);
    color: var(--text-secondary);
    font-size: 0.9375rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.2s ease;
}

.sidebar-item:hover {
    background: var(--bg-tertiary);
    color: var(--text-primary);
}

.sidebar-item.active {
    background: #e8f0fe;
    color: var(--accent-blue);
}

.sidebar-item-icon {
    width: 20px;
    height: 20px;
}

.storage-bar {
    height: 4px;
    background: var(--bg-hover);
    border-radius: 2px;
    overflow: hidden;
    margin-bottom: 8px;
}

.storage-fill {
    width: 0%;
    height: 100%;
    background: var(--accent-blue);
    transition: width 0.3s ease;
}

.storage-text {
    font-size: 0.75rem;
    color: var(--text-muted);
}

/* Main Content */
.main-content {
    flex: 1;
    padding: 24px 32px;
    background: var(--bg-primary);
}

/* Upload Zone */
.upload-zone {
    border: 2px dashed var(--border-medium);
    border-radius: var(--radius-lg);
    padding: 48px;
    text-align: center;
    cursor: pointer;
    transition: all 0.2s ease;
    background: var(--bg-secondary);
}

.upload-zone:hover,
.upload-zone.dragging {
    border-color: var(--accent-blue);
    background: #f0f7ff;
}

.upload-icon {
    width: 64px;
    height: 64px;
    margin: 0 auto 16px;
    background: var(--bg-tertiary);
    border-radius: var(--radius-full);
    display: flex;
    align-items: center;
    justify-content: center;
    color: var(--accent-blue);
}

.upload-title {
    font-size: 1rem;
    font-weight: 500;
    color: var(--text-primary);
    margin-bottom: 4px;
}

.upload-subtitle {
    font-size: 0.875rem;
    color: var(--text-muted);
}

.text-accent {
    color: var(--accent-blue);
}

.upload-progress {
    background: var(--bg-secondary);
    border-radius: var(--radius-md);
    padding: 16px;
    margin-top: 16px;
}

.upload-progress-bar {
    height: 4px;
    background: var(--bg-hover);
    border-radius: 2px;
    overflow: hidden;
}

.upload-progress-fill {
    height: 100%;
    background: var(--accent-blue);
    transition: width 0.2s;
}

.upload-progress-text {
    font-size: 0.875rem;
    color: var(--text-secondary);
    margin-top: 8px;
    text-align: center;
}

/* Files */
.section-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 16px;
}

.section-title {
    font-size: 1rem;
    font-weight: 600;
}

.files-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
    gap: 16px;
}

.file-card {
    background: var(--bg-secondary);
    border: 1px solid var(--border-light);
    border-radius: var(--radius-lg);
    padding: 16px;
    transition: all 0.2s ease;
}

.file-card:hover {
    border-color: var(--accent-blue);
    box-shadow: var(--shadow-md);
}

.file-icon {
    width: 48px;
    height: 48px;
    border-radius: var(--radius-md);
    display: flex;
    align-items: center;
    justify-content: center;
    margin-bottom: 12px;
    font-size: 24px;
}

.file-icon.pdf {
    background: #fce4ec;
}

.file-icon.txt {
    background: #f3e5f5;
}

.file-icon.md {
    background: #e3f2fd;
}

.file-name {
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-primary);
    margin-bottom: 4px;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}

.file-meta {
    font-size: 0.75rem;
    color: var(--text-muted);
}

.file-footer {
    display: flex;
    gap: 4px;
    margin-top: 12px;
    padding-top: 12px;
    border-top: 1px solid var(--border-light);
    align-items: center;
}

.file-status {
    font-size: 0.7rem;
    display: flex;
    align-items: center;
    gap: 4px;
}

.file-status.indexed {
    color: var(--accent-green);
}

.file-status.processing {
    color: var(--accent-yellow);
}

.file-actions {
    margin-left: auto;
    display: flex;
    gap: 2px;
}

.file-action-btn {
    width: 28px;
    height: 28px;
    padding: 0;
    background: transparent;
    border: none;
    border-radius: var(--radius-sm);
    cursor: pointer;
    color: var(--text-muted);
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
}

.file-action-btn:hover {
    background: var(--bg-tertiary);
    color: var(--text-primary);
}

.file-action-btn.delete:hover {
    color: var(--accent-red);
}

/* Empty State */
.empty-state {
    text-align: center;
    padding: 64px 24px;
}

.empty-icon {
    width: 80px;
    height: 80px;
    margin: 0 auto 24px;
    background: var(--bg-tertiary);
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    color: var(--text-muted);
}

.empty-state h3 {
    font-size: 1.125rem;
    font-weight: 600;
    margin-bottom: 8px;
}

.empty-state p {
    color: var(--text-muted);
    font-size: 0.875rem;
}

/* Chat */
.chat-container {
    display: flex;
    flex-direction: column;
    height: calc(100vh - 150px);
    background: var(--bg-secondary);
    border-radius: var(--radius-lg);
    border: 1px solid var(--border-light);
    overflow: hidden;
}

.chat-header {
    padding: 16px 24px;
    border-bottom: 1px solid var(--border-light);
}

.chat-header-content {
    display: flex;
    align-items: center;
    gap: 12px;
}

.chat-avatar {
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, #7c3aed 0%, #4f46e5 100%);
    border-radius: var(--radius-md);
    display: flex;
    align-items: center;
    justify-content: center;
}

.chat-header h3 {
    font-size: 1rem;
    font-weight: 600;
}

.chat-header p {
    font-size: 0.75rem;
    color: var(--text-muted);
}

.chat-messages {
    flex: 1;
    overflow-y: auto;
    padding: 24px;
}

.chat-empty {
    text-align: center;
    padding: 48px 24px;
}

.chat-empty-icon {
    width: 64px;
    height: 64px;
    margin: 0 auto 20px;
    background: linear-gradient(135deg, #f5f3ff 0%, #ede9fe 100%);
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    color: #7c3aed;
}

.chat-empty h3 {
    font-size: 1.125rem;
    font-weight: 600;
    margin-bottom: 8px;
}

.chat-empty p {
    color: var(--text-muted);
    font-size: 0.875rem;
    margin-bottom: 24px;
}

.chat-suggestions {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
    justify-content: center;
}

.suggestion-btn {
    font-size: 0.8125rem;
    padding: 8px 16px;
}

.chat-message {
    max-width: 80%;
    margin-bottom: 16px;
}

.chat-message.user {
    margin-left: auto;
}

.message-bubble {
    padding: 12px 16px;
    border-radius: var(--radius-lg);
    font-size: 0.9375rem;
}

.chat-message.user .message-bubble {
    background: var(--accent-blue);
    color: white;
    border-bottom-right-radius: 4px;
}

.chat-message.assistant .message-bubble {
    background: var(--bg-tertiary);
    color: var(--text-primary);
    border-bottom-left-radius: 4px;
}

.chat-input-container {
    padding: 16px 24px;
    border-top: 1px solid var(--border-light);
}

.chat-input-wrapper {
    display: flex;
    gap: 12px;
}

.chat-input {
    flex: 1;
    padding: 14px 20px;
    border: 1px solid var(--border-medium);
    border-radius: var(--radius-full);
    font-size: 0.9375rem;
    font-family: inherit;
    background: var(--bg-primary);
}

.chat-input:focus {
    outline: none;
    border-color: var(--accent-blue);
}

.chat-input:disabled {
    background: var(--bg-tertiary);
}

.chat-send-btn {
    flex-shrink: 0;
}

.typing-indicator {
    display: flex;
    gap: 4px;
    padding: 12px 16px;
}

.typing-dot {
    width: 8px;
    height: 8px;
    background: var(--accent-blue);
    border-radius: 50%;
    animation: typing 1.4s infinite ease-in-out both;
}

.typing-dot:nth-child(2) {
    animation-delay: 0.15s;
}

.typing-dot:nth-child(3) {
    animation-delay: 0.3s;
}

@keyframes typing {

    0%,
    80%,
    100% {
        transform: scale(0.6);
        opacity: 0.4;
    }

    40% {
        transform: scale(1);
        opacity: 1;
    }
}

/* Toast */
.toast {
    position: fixed;
    bottom: 24px;
    right: 24px;
    background: var(--text-primary);
    color: white;
    padding: 12px 24px;
    border-radius: var(--radius-md);
    font-size: 0.875rem;
    box-shadow: var(--shadow-lg);
    transform: translateY(100px);
    opacity: 0;
    transition: all 0.3s ease;
    z-index: 1000;
}

.toast.show {
    transform: translateY(0);
    opacity: 1;
}

/* Loading */
.loading {
    display: inline-block;
    width: 20px;
    height: 20px;
    border: 2px solid rgba(255, 255, 255, 0.3);
    border-radius: 50%;
    border-top-color: white;
    animation: spin 1s ease-in-out infinite;
}

@keyframes spin {
    to {
        transform: rotate(360deg);
    }
}

/* Audit Button */
.btn-audit {
    display: inline-flex;
    align-items: center;
    gap: 6px;
    padding: 6px 12px;
    background: white;
    border: 1px solid var(--border-medium);
    border-radius: var(--radius-full);
    font-size: 0.75rem;
    font-weight: 500;
    color: var(--text-secondary);
    cursor: pointer;
    transition: all 0.2s;
    margin-top: 4px;
}

.btn-audit:hover {
    background: #f0fdf4;
    border-color: var(--accent-green);
    color: var(--accent-green);
}

.btn-audit:disabled {
    opacity: 0.7;
    cursor: wait;
}

.audit-score {
    font-size: 0.75rem;
    padding: 6px 12px;
    margin-top: 4px;
}



@keyframes spin {
    to {
        transform: rotate(360deg);
    }
}

/* Modal */
.modal-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.5);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 2000;
    backdrop-filter: blur(4px);
    opacity: 0;
    visibility: hidden;
    transition: all 0.3s ease;
}

.modal-overlay.show {
    opacity: 1;
    visibility: visible;
}

.modal-content {
    background: var(--bg-secondary);
    border-radius: var(--radius-xl);
    width: 100%;
    max-width: 400px;
    padding: 32px;
    transform: scale(0.9);
    transition: all 0.3s ease;
    box-shadow: var(--shadow-xl);
}

.modal-overlay.show .modal-content {
    transform: scale(1);
}

.modal-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 24px;
}

.modal-title {
    font-size: 1.25rem;
    font-weight: 600;
}

.modal-close {
    background: transparent;
    border: none;
    cursor: pointer;
    color: var(--text-muted);
}


/* Mobile Nav */
.mobile-nav {
    display: none;
    position: fixed;
    bottom: 0;
    left: 0;
    width: 100%;
    background: var(--bg-secondary);
    border-top: 1px solid var(--border-light);
    padding: 10px 0;
    justify-content: space-around;
    z-index: 1000;
    box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.08);
}

.mobile-nav-item {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 4px;
    color: var(--text-muted);
    font-size: 0.7rem;
    font-weight: 500;
    cursor: pointer;
    padding: 4px 16px;
}

.mobile-nav-item.active {
    color: var(--accent-blue);
}

/* Responsive */
@media (max-width: 768px) {
    .sidebar {
        display: none;
    }

    .main-content {
        padding: 16px;
    }

    .auth-card {
        padding: 32px 24px;
    }

    .files-grid {
        grid-template-columns: 1fr;
    }

    .mobile-nav {
        display: flex;
    }

    .main-content {
        padding-bottom: 80px;
    }

    .chat-container {
        height: calc(100vh - 200px);
    }
}



/* Profile Dropdown */
.profile-dropdown {
    position: relative;
}

.profile-toggle {
    display: flex;
    align-items: center;
}

.profile-menu {
    position: absolute;
    top: calc(100% + 8px);
    right: 0;
    min-width: 200px;
    background: var(--bg-secondary);
    border: 1px solid var(--border-light);
    border-radius: var(--radius-md);
    box-shadow: var(--shadow-lg);
    opacity: 0;
    visibility: hidden;
    transform: translateY(-10px);
    transition: all 0.2s ease;
    z-index: 1000;
}

.profile-menu.show {
    opacity: 1;
    visibility: visible;
    transform: translateY(0);
}

.profile-menu-item {
    width: 100%;
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 12px 16px;
    background: none;
    border: none;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-primary);
    cursor: pointer;
    transition: background 0.2s;
    text-align: left;
}

.profile-menu-item:hover {
    background: var(--bg-tertiary);
}

.profile-menu-item:first-child {
    border-radius: var(--radius-md) var(--radius-md) 0 0;
}

.profile-menu-item:last-child {
    border-radius: 0 0 var(--radius-md) var(--radius-md);
}

.profile-menu-divider {
    height: 1px;
    background: var(--border-light);
    margin: 4px 0;
}

/* Document Selector */
.doc-selector {
    padding: 12px 16px;
    border-bottom: 1 px solid var(--border-light);
    background: var(--bg-tertiary);
}

.doc-selector-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: 12px;
}

.doc-selector-title {
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
}

.doc-selector-actions {
    display: flex;
    gap: 12px;
}

.btn-link {
    background: none;
    border: none;
    color: var(--accent-blue);
    font-size: 0.75rem;
    font-weight: 500;
    cursor: pointer;
    padding: 0;
}

.btn-link:hover {
    text-decoration: underline;
}

.doc-selector-list {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
}

.doc-checkbox {
    display: flex;
    align-items: center;
    gap: 6px;
    padding: 6px 12px;
    background: var(--bg-secondary);
    border: 1px solid var(--border-light);
    border-radius: var(--radius-full);
    font-size: 0.8125rem;
    cursor: pointer;
    transition: all 0.2s;
}

.doc-checkbox:hover {
    border-color: var(--accent-blue);
}

.doc-checkbox input[type="checkbox"] {
    cursor: pointer;
}

.doc-checkbox.selected {
    background: #e8f0fe;
    border-color: var(--accent-blue);
    color: var(--accent-blue);
}

/* Success message styling */
.auth-error.success {
    background-color: #d4edda;
    border-color: #c3e6cb;
    color: #155724;
}

/* Verification needed message - blue/info style */
.auth-error.verification {
    background-color: #d1ecf1;
    border: 1px solid #bee5eb;
    color: #0c5460;
    padding: 15px;
    border-radius: 8px;
    margin-bottom: 15px;
    font-size: 14px;
    line-height: 1.5;
}

/* Citations & Sources */
.citation-link {
    color: var(--primary-color);
    background: rgba(37, 99, 235, 0.1);
    padding: 0 4px;
    border-radius: 4px;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.2s;
    border-bottom: 1px dotted var(--primary-color);
}

.citation-link:hover {
    background: rgba(37, 99, 235, 0.2);
    text-decoration: none;
}

.sources-container {
    margin-top: 16px;
    padding-top: 12px;
    border-top: 1px solid var(--border-light);
}

.sources-header {
    font-size: 0.75rem;
    font-weight: 600;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    color: var(--text-muted);
    margin-bottom: 8px;
}

.sources-list {
    display: flex;
    flex-direction: column;
    gap: 8px;
}

.source-item {
    background: var(--bg-surface);
    border: 1px solid var(--border-light);
    border-radius: 6px;
    padding: 8px 12px;
    font-size: 0.85rem;
}

.source-meta {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 4px;
    color: var(--text-primary);
    font-size: 0.75rem;
}

.source-page {
    background: var(--bg-secondary);
    color: var(--text-secondary);
    padding: 2px 6px;
    border-radius: 4px;
    font-size: 0.7rem;
    font-weight: 500;
}

.source-preview {
    color: var(--text-secondary);
    line-height: 1.4;
    font-size: 0.8rem;
    display: -webkit-box;
    -webkit-line-clamp: 2;
    line-clamp: 2;
    -webkit-box-orient: vertical;
    overflow: hidden;
}

.message-actions {
    display: flex;
    align-items: center;
    gap: 12px;
    margin-top: 12px;
    padding-left: 4px;
}
</code>

frontend/nginx.conf:
<code>
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    upstream backend {
        server backend:8000;
    }

    server {
        listen 80;
        server_name localhost;

        # Auth proxy (Handles /auth/*)
        location /auth {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # API proxy (Handles /api/* including /api/admin/*)
        location /api {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            client_max_body_size 50M;
            
            # Increase timeout for RAGAS evaluation (can take >10s)
            proxy_read_timeout 300s;
            proxy_connect_timeout 300s;
            proxy_send_timeout 300s;
        }

        # Health check
        location /health {
            proxy_pass http://backend;
        }

        location /docs {
            proxy_pass http://backend;
        }

        location /openapi.json {
            proxy_pass http://backend;
        }
        # Admin Page - force inline display, NOT download
        location = /admin {
            root /usr/share/nginx/html;
            add_header Content-Type text/html;
            add_header Content-Disposition "inline";
            add_header Cache-Control "no-cache, no-store, must-revalidate";
            try_files /admin.html =404;
        }

        # Frontend static files (must come last)
        location / {
            root /usr/share/nginx/html;
            index index.html;
            try_files $uri $uri/ /index.html;
        }
    }
}

</code>

frontend/app.js:
<code>
// API Configuration
const API_URL = '';

// State
let token = localStorage.getItem('token');
let isSignUp = false;
let files = [];
let activeTab = 'files';
let selectedFileIds = []; // Track selected files for chat filtering
let pollingTimer = null; // For file status polling
let lastUserMessage = ""; // Track for audit

// DOM Elements
const authContainer = document.getElementById('auth-container');
const dashboardContainer = document.getElementById('dashboard-container');
const authForm = document.getElementById('auth-form');
const authError = document.getElementById('auth-error');
const authTitle = document.getElementById('auth-title');
const authSubtitle = document.getElementById('auth-subtitle');
const authBtn = document.getElementById('auth-btn');
const authToggle = document.getElementById('auth-toggle');
const authToggleText = document.getElementById('auth-toggle-text');
const logoutBtn = document.getElementById('logout-btn');
const profileToggle = document.getElementById('profile-toggle');
const profileMenu = document.getElementById('profile-menu');
const userProfileBtn = document.getElementById('user-profile-btn');
const uploadZone = document.getElementById('upload-zone');
const fileInput = document.getElementById('file-input');
const uploadProgress = document.getElementById('upload-progress');
const progressFill = document.getElementById('progress-fill');
const progressPercent = document.getElementById('progress-percent');
const filesGrid = document.getElementById('files-grid');
const emptyState = document.getElementById('empty-state');
const fileCount = document.getElementById('file-count');
const storageFill = document.getElementById('storage-fill');
const refreshBtn = document.getElementById('refresh-btn');
const uploadBtn = document.getElementById('upload-btn');
const filesTab = document.getElementById('files-tab');
const chatTab = document.getElementById('chat-tab');
const chatMessages = document.getElementById('chat-messages');
const chatForm = document.getElementById('chat-form');
const chatInput = document.getElementById('chat-input');
const toast = document.getElementById('toast');

// Initialize
document.addEventListener('DOMContentLoaded', () => {
    setupEventListeners();

    // Check for verification token
    const urlParams = new URLSearchParams(window.location.search);
    const verifyToken = urlParams.get('token');

    if (verifyToken) {
        verifyEmail(verifyToken);
        return; // Skip other checks
    }

    if (token) {
        showDashboard();
        fetchFiles();
    } else {
        showAuth();
    }
});

// Event Listeners
function setupEventListeners() {
    // Auth
    authForm.addEventListener('submit', handleAuth);
    authToggle.addEventListener('click', toggleAuthMode);
    logoutBtn.addEventListener('click', logout);

    // Profile Dropdown
    if (profileToggle && profileMenu) {
        profileToggle.addEventListener('click', (e) => {
            e.stopPropagation();
            profileMenu.classList.toggle('show');
        });

        // Close dropdown when clicking outside
        document.addEventListener('click', (e) => {
            if (!profileMenu.contains(e.target) && !profileToggle.contains(e.target)) {
                profileMenu.classList.remove('show');
            }
        });

        // User Profile button
        if (userProfileBtn) {
            userProfileBtn.addEventListener('click', () => {
                showUserProfile();
            });
        }
    }

    // Upload
    uploadZone.addEventListener('click', () => fileInput.click());
    uploadZone.addEventListener('dragover', handleDragOver);
    uploadZone.addEventListener('dragleave', handleDragLeave);
    uploadZone.addEventListener('drop', handleDrop);
    fileInput.addEventListener('change', handleFileSelect);
    uploadBtn.addEventListener('click', () => fileInput.click());
    refreshBtn.addEventListener('click', fetchFiles);

    // Sidebar tabs + mobile nav
    document.querySelectorAll('.sidebar-item, .mobile-nav-item').forEach(item => {
        item.addEventListener('click', () => switchTab(item.dataset.tab));
    });

    // Chat
    chatForm.addEventListener('submit', handleChat);
    chatInput.addEventListener('input', () => {
        chatForm.querySelector('button').disabled = !chatInput.value.trim();
    });

    // Suggestion buttons
    document.querySelectorAll('.suggestion-btn').forEach(btn => {
        btn.addEventListener('click', () => {
            chatInput.value = btn.textContent;
            chatInput.focus();
            chatForm.querySelector('button').disabled = false;
        });
    });
}

// Auth Functions
function toggleAuthMode(e) {
    e.preventDefault();
    isSignUp = !isSignUp;
    authError.style.display = 'none';

    if (isSignUp) {
        authTitle.textContent = 'Create Account';
        authSubtitle.textContent = 'Start storing and searching your files with AI';
        authBtn.textContent = 'Get Started';
        authToggleText.textContent = 'Already have an account?';
        authToggle.textContent = 'Sign in';
    } else {
        authTitle.textContent = 'Welcome back';
        authSubtitle.textContent = 'Sign in to access your cloud drive';
        authBtn.textContent = 'Sign In';
        authToggleText.textContent = "Don't have an account?";
        authToggle.textContent = 'Sign up';
    }
}

async function handleAuth(e) {
    e.preventDefault();
    const email = document.getElementById('email').value;
    const password = document.getElementById('password').value;

    authBtn.innerHTML = '<span class="loading"></span>';
    authBtn.disabled = true;
    authError.style.display = 'none';
    authError.className = 'auth-error';

    try {
        if (isSignUp) {
            // SIGNUP FLOW
            const res = await fetch(`${API_URL}/auth/register`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ email, password })
            });

            const data = await res.json();
            console.log('DEBUG: Register response status:', res.status);
            console.log('DEBUG: Register response data:', data);

            if (!res.ok) {
                let errorMsg = 'Registration failed';
                if (data.detail) {
                    if (Array.isArray(data.detail)) {
                        // Handle Pydantic validation errors
                        errorMsg = data.detail.map(e => e.msg).join(', ');
                    } else if (typeof data.detail === 'object') {
                        errorMsg = JSON.stringify(data.detail);
                    } else {
                        errorMsg = data.detail;
                    }
                } else if (data.error) {
                    errorMsg = data.error;
                }

                console.log('DEBUG: Final error message:', errorMsg);
                throw new Error(errorMsg);
            }

            // Signup successful - show verification message
            authError.style.display = 'block';
            authError.className = 'auth-error success';
            authError.innerHTML = 'âœ… Account created! ğŸ“§ Check your email inbox to verify your account before logging in.';
            authBtn.innerHTML = 'Get Started';
            authBtn.disabled = false;
            setTimeout(() => switchToLogin(), 4000);
            return; // STOP HERE - don't try to login

        } else {
            // LOGIN FLOW
            const formData = new FormData();
            formData.append('username', email);
            formData.append('password', password);

            const response = await fetch(`${API_URL}/auth/login`, {
                method: 'POST',
                body: formData
            });

            const data = await response.json();
            console.log('DEBUG: Login response status:', response.status);
            console.log('DEBUG: Login response data:', data);

            if (!response.ok) {
                // Get the actual error message from backend
                const errorMsg = data.detail || data.error || 'Login failed';
                console.log('DEBUG: Extracted errorMsg:', errorMsg);
                throw new Error(errorMsg);
            }

            // Login successful
            token = data.access_token;
            localStorage.setItem('token', token);
            showDashboard();
            fetchFiles();
        }
    } catch (err) {
        console.log('DEBUG: Caught error:', err);
        const errorMsg = err.message;

        // Check if it's a verification needed message
        if (errorMsg.includes('verify') || errorMsg.includes('email')) {
            authError.className = 'auth-error verification';
            // Add Resend Link
            authError.innerHTML = `
                ğŸ“§ ${errorMsg.replace('ğŸ“§', '').trim()}<br>
                <div style="margin-top: 10px;">
                    <a href="#" onclick="resendVerification(event)" style="text-decoration: underline; font-weight: bold;">
                        Request a new verification link
                    </a>
                </div>
            `;
        } else {
            authError.className = 'auth-error';
            authError.textContent = errorMsg;
        }
        authError.style.display = 'block';
    } finally {
        if (authBtn.disabled) {
            authBtn.innerHTML = isSignUp ? 'Get Started' : 'Sign In';
            authBtn.disabled = false;
        }
    }
}

// Resend Verification Function
async function resendVerification(e) {
    if (e) e.preventDefault();
    const email = document.getElementById('email').value;

    if (!email) {
        alert('Please enter your email address first.');
        return;
    }

    const link = e.target;
    const originalText = link.textContent;
    link.textContent = 'Sending...';
    link.style.pointerEvents = 'none'; // Disable click

    try {
        const response = await fetch(`${API_URL}/auth/resend-verification?email=${encodeURIComponent(email)}`, {
            method: 'POST'
        });

        const data = await response.json();

        if (response.ok) {
            link.textContent = 'âœ… Sent! Check your inbox.';
            link.style.color = '#155724';
            link.style.textDecoration = 'none';
        } else {
            throw new Error(data.detail || 'Failed to send');
        }
    } catch (err) {
        console.error('Resend failed:', err);
        link.textContent = 'âŒ Failed. Try again.';
        link.style.color = '#721c24';
        setTimeout(() => {
            link.textContent = originalText;
            link.style.pointerEvents = 'auto';
            link.style.color = '';
        }, 3000);
    }
}


async function verifyEmail(tokenStr) {
    // Show loading state
    authContainer.style.display = 'flex';
    dashboardContainer.style.display = 'none';
    authTitle.textContent = 'Verifying Email...';
    authSubtitle.textContent = 'Please wait while we verify your account';
    authForm.style.display = 'none';
    authError.style.display = 'none';

    try {
        const response = await fetch(`${API_URL}/auth/verify-email?token=${tokenStr}`);
        const data = await response.json();

        if (response.ok) {
            // Auto Login
            if (data.access_token) {
                token = data.access_token;
                localStorage.setItem('token', token);
                authError.className = 'auth-error success';
                authError.innerHTML = `âœ… ${data.message}<br>Redirecting to dashboard...`;
                authError.style.display = 'block';

                setTimeout(() => {
                    // Remove query params
                    window.history.replaceState({}, document.title, window.location.pathname);
                    showDashboard();
                    fetchFiles();
                }, 2000);
            } else {
                // Fallback if no token returned (legacy)
                authError.className = 'auth-error success';
                authError.textContent = data.message;
                authError.style.display = 'block';
                setTimeout(() => switchToLogin(), 2000);
            }
        } else {
            throw new Error(data.detail || 'Verification failed');
        }
    } catch (err) {
        authTitle.textContent = 'Verification Failed';
        authSubtitle.textContent = 'Please try again or request a new link';
        authError.className = 'auth-error';
        authError.textContent = err.message;
        authError.style.display = 'block';

        // Show login button just in case
        setTimeout(() => {
            authForm.style.display = 'block';
            switchToLogin();
        }, 3000);
    }
}

function logout() {
    token = null;
    localStorage.removeItem('token');
    files = [];
    showAuth();
}

function showAuth() {
    authContainer.style.display = 'flex';
    dashboardContainer.style.display = 'none';
}

function showDashboard() {
    authContainer.style.display = 'none';
    dashboardContainer.style.display = 'flex';
    chatInput.disabled = false;
}



// File Functions
async function fetchFiles() {
    if (pollingTimer) clearTimeout(pollingTimer);

    try {
        const response = await fetch(`${API_URL}/api/files`, {
            headers: { Authorization: `Bearer ${token}` }
        });

        if (!response.ok) {
            // Handle expired/invalid token
            if (response.status === 401) {
                console.warn('Token expired or invalid. Logging out.');
                logout();
                showToast('Session expired. Please log in again.', true);
                return;
            }
            throw new Error('Failed to fetch files');
        }

        files = await response.json();
        renderFiles();
        updateDocumentList(); // Update chat document selector

        // Poll if any file is still processing
        const hasProcessing = files.some(f => !f.is_indexed);
        if (hasProcessing) {
            console.log('Files processing... polling in 3s');
            pollingTimer = setTimeout(fetchFiles, 3000);
        }
    } catch (err) {
        console.error(err);
        showToast('Failed to load files: ' + err.message, true);
    }
}

function renderFiles() {
    fileCount.textContent = files.length;
    storageFill.style.width = `${Math.min(files.length * 5, 100)}%`;

    if (files.length === 0) {
        filesGrid.innerHTML = '';
        emptyState.style.display = 'block';
        return;
    }

    emptyState.style.display = 'none';
    filesGrid.innerHTML = files.map(file => {
        const ext = file.filename.split('.').pop().toLowerCase();
        const icon = ext === 'pdf' ? 'ğŸ“„' : ext === 'txt' ? 'ğŸ“' : 'ğŸ“‹';
        const size = formatSize(file.size);
        const date = new Date(file.upload_date).toLocaleDateString('en-US', {
            month: 'short', day: 'numeric', year: 'numeric'
        });

        return `
            <div class="file-card" data-id="${file.id}">
                <div class="file-icon ${ext}">${icon}</div>
                <p class="file-name" title="${file.filename}">${file.filename}</p>
                <p class="file-meta">${size} â€¢ ${date}</p>
                <div class="file-footer">
                    <span class="file-status ${file.is_indexed ? 'indexed' : 'processing'}">
                        ${file.is_indexed ? 'âœ“ Indexed' : 'â³ Processing'}
                    </span>
                    <div class="file-actions">
                        <button class="file-action-btn" onclick="shareFile(${file.id})" title="Share">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="18" cy="5" r="3"/><circle cx="6" cy="12" r="3"/><circle cx="18" cy="19" r="3"/>
                                <line x1="8.59" y1="13.51" x2="15.42" y2="17.49"/>
                                <line x1="15.41" y1="6.51" x2="8.59" y2="10.49"/>
                            </svg>
                        </button>
                        <button class="file-action-btn" onclick="downloadFile(${file.id}, '${file.filename}')" title="Download">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/>
                                <polyline points="7 10 12 15 17 10"/>
                                <line x1="12" y1="15" x2="12" y2="3"/>
                            </svg>
                        </button>
                        <button class="file-action-btn delete" onclick="deleteFile(${file.id})" title="Delete">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="3 6 5 6 21 6"/>
                                <path d="M19 6v14a2 2 0 0 1-2 2H7a2 2 0 0 1-2-2V6m3 0V4a2 2 0 0 1 2-2h4a2 2 0 0 1 2 2v2"/>
                            </svg>
                        </button>
                    </div>
                </div>
            </div>
        `;
    }).join('');
}

function formatSize(bytes) {
    if (bytes < 1024) return bytes + ' B';
    if (bytes < 1048576) return (bytes / 1024).toFixed(1) + ' KB';
    return (bytes / 1048576).toFixed(1) + ' MB';
}

// Upload Functions
function handleDragOver(e) {
    e.preventDefault();
    uploadZone.classList.add('dragging');
}

function handleDragLeave() {
    uploadZone.classList.remove('dragging');
}

function handleDrop(e) {
    e.preventDefault();
    uploadZone.classList.remove('dragging');
    const file = e.dataTransfer.files[0];
    if (file) uploadFile(file);
}

function handleFileSelect(e) {
    const file = e.target.files[0];
    if (file) uploadFile(file);
}

async function uploadFile(file) {
    uploadProgress.style.display = 'block';
    progressFill.style.width = '0%';
    progressPercent.textContent = '0';

    const formData = new FormData();
    formData.append('file', file);

    try {
        const xhr = new XMLHttpRequest();

        xhr.upload.addEventListener('progress', (e) => {
            if (e.lengthComputable) {
                const percent = Math.round((e.loaded / e.total) * 100);
                progressFill.style.width = percent + '%';
                progressPercent.textContent = percent;
            }
        });

        xhr.onload = () => {
            uploadProgress.style.display = 'none';
            fileInput.value = '';

            if (xhr.status >= 200 && xhr.status < 300) {
                showToast('File uploaded successfully!');
                fetchFiles();
            } else {
                const err = JSON.parse(xhr.responseText);
                showToast(err.detail || 'Upload failed', true);
            }
        };

        xhr.onerror = () => {
            uploadProgress.style.display = 'none';
            showToast('Upload failed', true);
        };

        xhr.open('POST', `${API_URL}/api/upload`);
        xhr.setRequestHeader('Authorization', `Bearer ${token}`);
        xhr.send(formData);
    } catch (err) {
        uploadProgress.style.display = 'none';
        showToast(err.message, true);
    }
}

// File Actions
async function shareFile(fileId) {
    try {
        const response = await fetch(`${API_URL}/api/share`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${token}`
            },
            body: JSON.stringify({ file_id: fileId })
        });

        if (!response.ok) throw new Error('Share failed');

        const data = await response.json();
        const shareUrl = window.location.origin + data.share_url;
        await navigator.clipboard.writeText(shareUrl);
        showToast('Link copied to clipboard!');
    } catch (err) {
        showToast(err.message, true);
    }
}

function downloadFile(fileId, filename) {
    const token = localStorage.getItem('token');

    fetch(`${API_URL}/api/download/${fileId}`, {
        headers: {
            'Authorization': `Bearer ${token}`
        }
    })
        .then(response => {
            if (!response.ok) {
                throw new Error('Download failed');
            }
            return response.blob();
        })
        .then(blob => {
            const url = window.URL.createObjectURL(blob);
            const link = document.createElement('a');
            link.href = url;
            link.download = filename;
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            window.URL.revokeObjectURL(url);
            showToast('File downloaded successfully');
        })
        .catch(error => {
            console.error('Download error:', error);
            showToast('Failed to download file', true);
        });
}

async function deleteFile(fileId) {
    if (!confirm('Are you sure you want to delete this file?')) return;

    try {
        const response = await fetch(`${API_URL}/api/delete/${fileId}`, {
            method: 'DELETE',
            headers: { Authorization: `Bearer ${token}` }
        });

        if (!response.ok) throw new Error('Delete failed');

        showToast('File deleted');
        fetchFiles();
    } catch (err) {
        showToast(err.message, true);
    }
}

// Chat Functions
async function handleChat(e) {
    e.preventDefault();
    const query = chatInput.value.trim();
    if (!query) return;

    lastUserMessage = query; // Save for audit

    // Clear empty state
    const chatEmpty = chatMessages.querySelector('.chat-empty');
    if (chatEmpty) chatEmpty.remove();

    // Add user message
    addChatMessage(query, 'user');
    chatInput.value = '';
    chatForm.querySelector('button').disabled = true;

    // Add typing indicator
    const typingId = addTypingIndicator();

    try {
        // Build request with optional file filtering
        const requestBody = { query };
        if (selectedFileIds.length > 0) {
            requestBody.file_ids = selectedFileIds;
        }

        const response = await fetch(`${API_URL}/api/query`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${token}`
            },
            body: JSON.stringify(requestBody)
        });

        removeTypingIndicator(typingId);

        if (!response.ok) {
            const err = await response.json();
            throw new Error(err.detail || 'Query failed');
        }

        const data = await response.json();
        addChatMessage(data.answer, 'assistant', data.sources, false, data.contexts);
    } catch (err) {
        removeTypingIndicator(typingId);
        addChatMessage('Sorry, I encountered an error. Please try again.', 'assistant', null, true);
        console.error('Chat error:', err);
    }
}


async function auditAnswer(btn, payload) {
    const scoreSpan = btn.nextElementSibling;

    // UI Loading
    btn.disabled = true;
    btn.innerHTML = "â³ Auditing (takes ~10s)...";

    try {
        const response = await fetch(`${API_URL}/api/evaluate`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${token}`
            },
            body: JSON.stringify(payload)
        });

        if (!response.ok) throw new Error("Evaluation failed");

        const data = await response.json();
        console.log('DEBUG: Audit Data', data); // Verify explanation exists
        const score = data.faithfulness;
        const explanation = data.explanation; // Get reasoning

        // Render Result
        let color = score > 0.7 ? "var(--accent-green)" : "#ea4335";
        let icon = score > 0.7 ? "âœ…" : "âš ï¸";

        btn.style.display = 'none';
        scoreSpan.style.display = 'inline-block';
        scoreSpan.innerHTML = `
            <div style="display: flex; flex-direction: column; gap: 8px;">
                <div>${icon} Faithfulness: <strong style="color:${color}">${(score * 100).toFixed(0)}%</strong></div>
                ${explanation ? `
                <div style="
                    background: #f8f9fa;
                    padding: 10px;
                    border-radius: 6px;
                    font-size: 0.9em;
                    color: #000;
                    border-left: 4px solid ${color};
                    margin-top: 8px;
                    line-height: 1.5;
                    white-space: pre-wrap;
                    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
                "><strong>Auditor's Note:</strong><br>${escapeHtml(explanation)}</div>` : ''}
            </div>
        `;

    } catch (err) {
        console.error(err);
        btn.innerHTML = "âŒ Error";
        btn.disabled = false;
    }
}

// Helper to escape HTML to prevent XSS
function escapeHtml(text) {
    const map = {
        '&': '&amp;',
        '<': '&lt;',
        '>': '&gt;',
        '"': '&quot;',
        "'": '&#039;'
    };
    return text.replace(/[&<>"']/g, m => map[m]);
}

function processCitations(text, sources) {
    // Escape HTML first
    let safeText = escapeHtml(text);

    // Convert newlines to breaks
    safeText = safeText.replace(/\n/g, '<br>');

    // Replace [Source X] with clickable spans
    // Regex matches [Source 1], [Source 12], etc.
    return safeText.replace(/\[Source (\d+)\]/g, (match, id) => {
        const sourceIdx = parseInt(id) - 1; // 1-based to 0-based
        if (sources && sources[sourceIdx]) {
            const source = sources[sourceIdx];
            const pageNum = source.metadata?.page_number ? ` (Page ${source.metadata.page_number})` : '';
            return `<span class="citation-link" onclick="showSourcePreview(${sourceIdx})" title="Click to view context${pageNum}">${match}</span>`;
        }
        return match;
    });
}

// Global scope for onclick handler
window.showSourcePreview = function (sourceIdx) {
    // Find the current message's sources... 
    // Problem: we need the specific sources for *this* message.
    // Solution: We'll store sources likely in the DOM or a global if complex.
    // For simplicity: We can't easily pass the full object in onclick.
    // Better interaction: Tooltip on hover using CSS/title, or simple alert for now?
    // User requested: "clickable [1] that highlights the paragraph"

    // Let's implement a simple modal/toast for now since we don't have the context easily accessible 
    // unless we bind it.
    // Actually, we can attach the text to the span as a data attribute (escaped).

    // REVISIT: For "Research-Grade", dragging full text around is messy.
    // Let's rely on the "Sources" footnote section which has the full chunks.
    // We will highlight the corresponding source in the footnote!

    const sourceCards = document.querySelectorAll(`.source-card-${sourceIdx}`);
    // Highlight them?
    const sourceCard = document.getElementById(`source-chunk-${sourceIdx}`); // We need to generate unique IDs per message? 
    // This is hard with multiple messages.

    // Alternative: Just show a toast with the page info.
    // showToast(`Source ${sourceIdx + 1} referenced.`);

    // Correct approach for V1:
    // Scroll to the "Sources" section of this message?
    // Let's just make the "Sources" section collapsible/highlightable.

    // Actually, let's implement a clean "Source Preview" modal.
    // But we need the data.

    // Quick fix: Don't use onclick yet if data isn't there. 
    // Just style it nicely.
    // Wait, the prompt asked for "Clickable [1] that highlights paragraph".
    // I can put the text in `data-context` attribute.
};


function addChatMessage(content, role, sources = null, isError = false, contexts = []) {
    const div = document.createElement('div');
    div.className = `chat-message ${role}`;

    // Process Content with Citations
    let finalHtml = role === 'assistant' ? processCitations(content, sources) : escapeHtml(content).replace(/\n/g, '<br>');

    let sourcesHtml = '';
    if (sources && sources.length > 0) {
        sourcesHtml = `
            <div class="sources-container">
                <div class="sources-header">ğŸ“š Referenced Sources</div>
                <div class="sources-list">
                    ${sources.slice(0, 3).map((s, i) => {
            const pageInfo = s.metadata?.page_number ? `<span class="source-page">Page ${s.metadata.page_number}</span>` : '';
            const contentPreview = s.content ? s.content.substring(0, 150) + "..." : "";
            return `
                            <div class="source-item">
                                <div class="source-meta">
                                    <strong>Source ${i + 1}</strong>
                                    ${pageInfo}
                                </div>
                                <div class="source-preview">${escapeHtml(contentPreview)}</div>
                            </div>
                        `;
        }).join('')}
                </div>
            </div>
        `;
    }

    let auditHtml = '';
    if (role === 'assistant' && contexts && contexts.length > 0 && !isError) {
        const payload = JSON.stringify({
            question: lastUserMessage,
            answer: content,
            contexts: contexts
        }).replace(/"/g, '&quot;');

        auditHtml = `
            <div class="message-actions">
                <button class="btn-audit" onclick="auditAnswer(this, ${payload})">
                    ğŸ›¡ï¸ Check Accuracy
                </button>
                <div class="audit-score" style="display:none"></div>
            </div>
        `;
    }

    div.innerHTML = `
        <div class="message-bubble" ${isError ? 'style="background:#fef2f2;color:#991b1b"' : ''}>
            ${finalHtml}
            ${sourcesHtml}
        </div>
        ${auditHtml}
    `;

    chatMessages.appendChild(div);
    chatMessages.scrollTop = chatMessages.scrollHeight;
}

function addTypingIndicator() {
    const id = Date.now();
    const div = document.createElement('div');
    div.className = 'chat-message assistant';
    div.id = `typing-${id}`;
    div.innerHTML = `
        <div class="message-bubble">
            <div class="typing-indicator">
                <span class="typing-dot"></span>
                <span class="typing-dot"></span>
                <span class="typing-dot"></span>
            </div>
        </div>
    `;
    chatMessages.appendChild(div);
    chatMessages.scrollTop = chatMessages.scrollHeight;
    return id;
}

function removeTypingIndicator(id) {
    const el = document.getElementById(`typing-${id}`);
    if (el) el.remove();
}

// Tab Switching
function switchTab(tab) {
    activeTab = tab;
    document.querySelectorAll('.sidebar-item, .mobile-nav-item').forEach(item => {
        item.classList.toggle('active', item.dataset.tab === tab);
    });

    filesTab.style.display = tab === 'files' ? 'block' : 'none';
    chatTab.style.display = tab === 'chat' ? 'block' : 'none';
}

// Toast Notifications
function showToast(message, isError = false) {
    toast.textContent = message;
    toast.className = 'toast show';
    if (isError) toast.classList.add('error');

    setTimeout(() => {
        toast.classList.remove('show');
        if (isError) toast.classList.remove('error');
    }, 3000);
}


// Document Selector Functions
function updateDocumentList() {
    const docList = document.getElementById('doc-list');
    if (!files || files.length === 0) {
        docList.innerHTML = '<div style="padding: 8px; color: var(--text-muted); font-size: 0.8125rem;">No files uploaded yet</div>';
        return;
    }

    docList.innerHTML = files.map(file => `
        <label class="doc-checkbox ${selectedFileIds.includes(file.id) ? 'selected' : ''}">
            <input type="checkbox" 
                   value="${file.id}" 
                   ${selectedFileIds.includes(file.id) ? 'checked' : ''}
                   onchange="toggleFileSelection(${file.id})">
            ${file.filename}
        </label>
    `).join('');

    updateSelectedCount();
}

function toggleFileSelection(fileId) {
    const index = selectedFileIds.indexOf(fileId);
    if (index > -1) {
        selectedFileIds.splice(index, 1);
    } else {
        selectedFileIds.push(fileId);
    }
    updateDocumentList();
}

function selectAllDocs() {
    selectedFileIds = files.map(f => f.id);
    updateDocumentList();
}

function clearAllDocs() {
    selectedFileIds = [];
    updateDocumentList();
}

function updateSelectedCount() {
    const countEl = document.getElementById('selected-count');
    if (selectedFileIds.length === 0) {
        countEl.textContent = 'All documents';
    } else if (selectedFileIds.length === files.length) {
        countEl.textContent = `All ${files.length} documents`;
    } else {
        countEl.textContent = `${selectedFileIds.length} of ${files.length} documents`;
    }
}

// Add event listeners for document selector
document.getElementById('select-all-docs')?.addEventListener('click', selectAllDocs);
document.getElementById('clear-all-docs')?.addEventListener('click', clearAllDocs);

/* User Profile Logic */
function showUserProfile() {
    // Hide dropdown
    const profileMenu = document.getElementById('profile-menu');
    if (profileMenu) profileMenu.classList.remove('show');

    // Show Modal
    const modal = document.getElementById('profile-modal');
    if (modal) {
        modal.classList.add('show');
        modal.style.visibility = 'visible';
        modal.style.opacity = '1';
    }

    // Fetch Data
    const token = localStorage.getItem('token');
    // Ensure API_URL is defined (it is global constant at top usually, but verify)
    // Assuming API_URL is global. If not, use relative /api/
    const url = typeof API_URL !== 'undefined' ? `${API_URL}/auth/me` : '/auth/me';

    fetch(url, {
        headers: { Authorization: `Bearer ${token}` }
    })
        .then(res => res.json())
        .then(data => {
            if (data.email) {
                document.getElementById('profile-email').textContent = data.email;
                document.getElementById('profile-role').textContent = data.role === 'admin' ? 'Administrator' : 'Standard User';
                document.getElementById('profile-date').textContent = new Date(data.created_at).toLocaleDateString();
            } else {
                showToast('Failed to load profile data', true);
            }
        })
        .catch(err => {
            showToast('Failed to load profile', true);
            console.error(err);
        });
}

function closeProfileModal() {
    const modal = document.getElementById('profile-modal');
    if (modal) {
        modal.classList.remove('show');
        modal.style.visibility = 'hidden';
        modal.style.opacity = '0';
    }
}

</code>

backend/inspect_chroma.py:
<code>

import os
import sys

# Add backend to path
sys.path.append(os.path.join(os.getcwd(), "backend"))

from app.rag.indexer import get_collection

def inspect():
    print("Connecting to ChromaDB...")
    try:
        col = get_collection()
        print(f"Collection count: {col.count()}")
        
        # Peek at 5 items
        res = col.peek(limit=5)
        
        if not res["ids"]:
            print("Collection is empty!")
            return

        print("\n--- Metadata Dump (First 5 chunks) ---")
        for i, meta in enumerate(res["metadatas"]):
            print(f"\nChunk {i}:")
            print(f"  ID: {res['ids'][i]}")
            print(f"  Metadata: {meta}")
            
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    inspect()

</code>

backend/inspect_chroma_v2.py:
<code>

import sys
import os

# Ensure backend modules are loadable
sys.path.append("/app")

try:
    from app.rag.indexer import get_collection
    
    print("--- CHROMA METADATA INSPECTION ---")
    col = get_collection()
    count = col.count()
    print(f"Total Chunks: {count}")
    
    if count > 0:
        # Get first 10 items
        res = col.peek(limit=10)
        metas = res.get("metadatas", [])
        
        print(f"Inspecting {len(metas)} chunks:")
        for i, m in enumerate(metas):
            sec = m.get("section", "N/A")
            page = m.get("page", "N/A")
            fid = m.get("file_id", "N/A")
            print(f"[{i}] File: {fid} | Page: {page} | Section: '{sec}'")
            
    print("--- END INSPECTION ---")

except Exception as e:
    print(f"FATAL ERROR: {e}")

</code>

backend/migrate.py:
<code>

from sqlalchemy import create_engine, text
from app.config import settings

def run_migration():
    print("Running migration...")
    engine = create_engine(settings.DATABASE_URL)
    
    with engine.connect() as conn:
        conn.execution_options(isolation_level="AUTOCOMMIT")
        
        # Add can_upload to users
        try:
            print("Adding can_upload column...")
            conn.execute(text("ALTER TABLE users ADD COLUMN IF NOT EXISTS can_upload BOOLEAN DEFAULT TRUE;"))
            print("Column added.")
        except Exception as e:
            print(f"Error adding column (might exist): {e}")

        # Create audit_logs table
        try:
            print("Creating audit_logs table...")
            conn.execute(text("""
            CREATE TABLE IF NOT EXISTS audit_logs (
                id SERIAL PRIMARY KEY,
                timestamp TIMESTAMP WITHOUT TIME ZONE DEFAULT (now() at time zone 'utc'),
                actor_id INTEGER,
                action VARCHAR,
                target_id INTEGER,
                target_type VARCHAR,
                metadata_json VARCHAR,
                FOREIGN KEY (actor_id) REFERENCES users(id)
            );
            """))
            print("Table created.")
        except Exception as e:
            print(f"Error creating table: {e}")

if __name__ == "__main__":
    run_migration()

</code>

backend/app/auth.py:
<code>
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.orm import Session
from .config import settings
from . import database, models, schemas

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password, hashed_password):
    # Truncate to 72 bytes for bcrypt compatibility
    return pwd_context.verify(plain_password[:72], hashed_password)

def get_password_hash(password):
    # Truncate to 72 bytes for bcrypt compatibility
    return pwd_context.hash(password[:72])

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="auth/login")

def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(database.get_db)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        email: str = payload.get("sub")
        role: str = payload.get("role")
        
        if email is None:
            raise credentials_exception
        
        # Handle admin tokens specially - they don't have DB entries
        if role == "admin":
            # Create a mock user object for admin
            admin_user = models.User(
                id=0,  # Special ID for admin
                email=email,
                is_active=True,
                can_upload=True
            )
            return admin_user
        
        # Regular user lookup
        token_data = schemas.TokenData(email=email)
        user = db.query(models.User).filter(models.User.email == token_data.email).first()
        if user is None:
            raise credentials_exception
        return user
    except JWTError:
        raise credentials_exception

def get_admin_user(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        role: str = payload.get("role")
        if role != "admin":
             raise HTTPException(status_code=403, detail="Not an admin")
        # Return a mock admin user object with id attribute
        admin_user = models.User(
            id=0,  # Special admin ID
            email=payload.get("sub", "admin"),
            is_active=True,
            can_upload=True
        )
        return admin_user
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate admin credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

</code>

backend/app/config.py:
<code>
from pydantic_settings import BaseSettings
from typing import Optional
import os

class Settings(BaseSettings):
    # Environment
    ENVIRONMENT: str = "development"  # development, staging, production
    DEBUG: bool = True
    
    # Database
    DATABASE_URL: str
    DATABASE_POOL_SIZE: int = 5
    DATABASE_MAX_OVERFLOW: int = 10
    
    # Security
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    REFRESH_TOKEN_EXPIRE_DAYS: int = 7
    
    # Admin Credentials (MUST be set via .env)
    ADMIN_USERNAME: str = ""
    ADMIN_PASSWORD: str = ""
    
    # MinIO
    MINIO_ENDPOINT: str
    MINIO_ACCESS_KEY: str
    MINIO_SECRET_KEY: str
    MINIO_SECURE: bool = False
    
    # ChromaDB
    CHROMA_HOST: str = "chromadb"
    CHROMA_PORT: int = 8000
    
    # Redis
    REDIS_URL: str = "redis://redis:6379/0"
    CACHE_TTL: int = 300  # 5 minutes
    
    # Groq API (LLM) - MUST be set via .env
    GROQ_API_KEY: str = ""
    GROQ_MODEL: str = "llama-3.1-8b-instant"
    GROQ_TIMEOUT: int = 30
    
    # File Upload
    MAX_FILE_SIZE: int = 50 * 1024 * 1024  # 50MB
    ALLOWED_EXTENSIONS: str = ".pdf,.txt,.md"
    
    # Rate Limiting
    # Safe limit for Llama 3 8B (approx 30 RPM / 18k TPM)
    RATE_LIMIT_PER_MINUTE: int = 30
    
    # CORS
    CORS_ORIGINS: str = "http://localhost:3000,http://localhost"
    
    # Logging
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = "json"  # json or text
    
    # Email Configuration (for Magic Links)
    SMTP_SERVER: str = "smtp.gmail.com"
    SMTP_PORT: int = 587
    SMTP_USERNAME: str = ""  # Set via .env for real email
    SMTP_PASSWORD: str = ""  # Set via .env (Gmail app password)
    EMAIL_FROM: str = "noreply@clouddrive.com"
    
    # Security Settings
    REQUIRE_EMAIL_VERIFICATION: bool = True  # Email verification enabled
    PASSWORD_MIN_LENGTH: int = 8
    MAX_LOGIN_ATTEMPTS: int = 5
    LOCKOUT_DURATION_MINUTES: int = 30
    VERIFICATION_TOKEN_EXPIRE_HOURS: int = 24
    
    # Rate Limiting (Auth)
    SIGNUP_RATE_LIMIT: str = "3/hour"
    LOGIN_RATE_LIMIT: str = "5/15minutes"
    
    # Google OAuth (optional)
    GOOGLE_CLIENT_ID: str = ""
    GOOGLE_CLIENT_SECRET: str = ""
    GOOGLE_REDIRECT_URI: str = "http://localhost:3000/auth/google/callback"
    
    @property
    def cors_origins_list(self) -> list:
        return [origin.strip() for origin in self.CORS_ORIGINS.split(",")]
    
    @property
    def allowed_extensions_list(self) -> list:
        return [ext.strip() for ext in self.ALLOWED_EXTENSIONS.split(",")]
    
    @property
    def is_production(self) -> bool:
        return self.ENVIRONMENT == "production"
    
    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()

</code>

backend/app/logging_config.py:
<code>
import logging
import sys
from datetime import datetime

# Configure structured logging
class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_record = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        if hasattr(record, 'request_id'):
            log_record['request_id'] = record.request_id
        if record.exc_info:
            log_record['exception'] = self.formatException(record.exc_info)
        return str(log_record)

def setup_logging(log_level: str = "INFO"):
    """Configure application logging"""
    logger = logging.getLogger("ai_cloud_drive")
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # Console handler with JSON format
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(JSONFormatter())
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

</code>

backend/app/models.py:
<code>
from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, Boolean
from sqlalchemy.orm import relationship
from datetime import datetime
from .database import Base

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String, unique=True, index=True)
    hashed_password = Column(String, nullable=True)  # Nullable for passwordless users
    google_id = Column(String, unique=True, nullable=True, index=True)  # Google OAuth ID
    name = Column(String, nullable=True)  # User display name
    profile_photo = Column(String, nullable=True)  # MinIO path to profile photo
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    last_login = Column(DateTime, nullable=True)
    
    # Magic Link (Passwordless Auth)
    magic_link_token = Column(String, nullable=True, index=True)
    magic_link_expires = Column(DateTime, nullable=True)
    
    # Email verification (auto-verified for OAuth/Magic Link users)
    is_verified = Column(Boolean, default=False)
    verification_token = Column(String, nullable=True)
    verification_sent_at = Column(DateTime, nullable=True)
    
    # Account security
    failed_login_attempts = Column(Integer, default=0)
    locked_until = Column(DateTime, nullable=True)
    can_upload = Column(Boolean, default=True) # Admin control

    files = relationship("File", back_populates="owner")
    chats = relationship("ChatHistory", back_populates="user")


class AuditLog(Base):
    __tablename__ = "audit_logs"

    id = Column(Integer, primary_key=True, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow)
    actor_id = Column(Integer, ForeignKey("users.id"), nullable=True) # Admin or System (null)
    action = Column(String) # e.g. "suspend_user", "delete_file"
    target_id = Column(Integer, nullable=True) # ID of affected user/file
    target_type = Column(String, nullable=True) # "user", "file"
    metadata_json = Column(String, nullable=True) # JSON details

    actor = relationship("User", foreign_keys=[actor_id])



class ChatHistory(Base):
    __tablename__ = "chat_history"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    query = Column(String)
    answer = Column(String)
    timestamp = Column(DateTime, default=datetime.utcnow)

    user = relationship("User", back_populates="chats")

class File(Base):
    __tablename__ = "files"

    id = Column(Integer, primary_key=True, index=True)
    filename = Column(String, index=True)
    file_path = Column(String) # MinIO path
    content_type = Column(String)
    size = Column(Integer)
    upload_date = Column(DateTime, default=datetime.utcnow)
    is_indexed = Column(Boolean, default=False)
    share_token = Column(String, unique=True, nullable=True) # For public sharing
    
    owner_id = Column(Integer, ForeignKey("users.id"))
    owner = relationship("User", back_populates="files")

class FileShare(Base):
    __tablename__ = "file_shares"
    
    id = Column(Integer, primary_key=True, index=True)
    file_id = Column(Integer, ForeignKey("files.id"))
    shared_with_id = Column(Integer, ForeignKey("users.id"))
    permission = Column(String, default="read") # read, write
    created_at = Column(DateTime, default=datetime.utcnow)


</code>

backend/app/validators.py:
<code>
import re
import html
from typing import Optional
from pydantic import validator
from fastapi import HTTPException

# Password requirements
PASSWORD_MIN_LENGTH = 6

def validate_password_strength(password: str) -> str:
    """Validate password meets security requirements"""
    if len(password) < PASSWORD_MIN_LENGTH:
        raise ValueError(f"Password must be at least {PASSWORD_MIN_LENGTH} characters")
    return password

def sanitize_filename(filename: str) -> str:
    """Sanitize filename to prevent path traversal and injection"""
    # Remove any path components
    filename = filename.replace('/', '').replace('\\', '')
    # Remove null bytes
    filename = filename.replace('\x00', '')
    # Only allow alphanumeric, dots, dashes, underscores
    filename = re.sub(r'[^a-zA-Z0-9._-]', '_', filename)
    # Prevent hidden files
    if filename.startswith('.'):
        filename = '_' + filename[1:]
    # Limit length
    if len(filename) > 255:
        name, ext = filename.rsplit('.', 1) if '.' in filename else (filename, '')
        filename = name[:250] + ('.' + ext if ext else '')
    return filename

def sanitize_query(query: str, max_length: int = 1000) -> str:
    """Sanitize user query input"""
    # Trim whitespace
    query = query.strip()
    # Limit length
    if len(query) > max_length:
        query = query[:max_length]
    # Escape HTML entities
    query = html.escape(query)
    return query

def validate_email_domain(email: str, blocked_domains: list = None) -> str:
    """Validate email domain is not in blocklist"""
    blocked = blocked_domains or ['tempmail.com', 'throwaway.com', 'guerrillamail.com']
    domain = email.split('@')[-1].lower()
    if domain in blocked:
        raise ValueError("Disposable email addresses are not allowed")
    return email

# SQL injection prevention patterns
SQL_INJECTION_PATTERNS = [
    r"(\%27)|(\')|(\-\-)|(\%23)|(#)",
    r"((\%3D)|(=))[^\n]*((\%27)|(\')|(\-\-)|(\%3B)|(;))",
    r"\w*((\%27)|(\'))((\%6F)|o|(\%4F))((\%72)|r|(\%52))",
    r"((\%27)|(\'))union",
]

def check_sql_injection(value: str) -> bool:
    """Check for SQL injection patterns"""
    for pattern in SQL_INJECTION_PATTERNS:
        if re.search(pattern, value, re.IGNORECASE):
            return True
    return False

def validate_input(value: str, field_name: str = "input") -> str:
    """Validate input for common attacks"""
    if check_sql_injection(value):
        raise HTTPException(status_code=400, detail=f"Invalid {field_name}: potentially malicious content detected")
    return value

</code>

backend/app/database.py:
<code>
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool
from .config import settings

SQLALCHEMY_DATABASE_URL = settings.DATABASE_URL

# Production-ready connection pooling
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    poolclass=QueuePool,
    pool_size=settings.DATABASE_POOL_SIZE,
    max_overflow=settings.DATABASE_MAX_OVERFLOW,
    pool_pre_ping=True,  # Verify connections before use
    pool_recycle=3600,   # Recycle connections after 1 hour
    echo=settings.DEBUG  # Log SQL in debug mode
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()

def get_db():
    """Database session dependency with proper cleanup"""
    db = SessionLocal()
    try:
        yield db
    except Exception:
        db.rollback()
        raise
    finally:
        db.close()

</code>

backend/app/cache.py:
<code>
import redis
import json
import hashlib
from typing import Optional, Any
from functools import wraps
from .config import settings

class RedisCache:
    """Redis caching utility for query results"""
    
    def __init__(self):
        self.client = redis.from_url(settings.REDIS_URL, decode_responses=True)
        self.default_ttl = 300  # 5 minutes
    
    def _make_key(self, prefix: str, *args, **kwargs) -> str:
        """Generate cache key from arguments"""
        key_data = json.dumps({"args": args, "kwargs": kwargs}, sort_keys=True)
        key_hash = hashlib.md5(key_data.encode()).hexdigest()[:12]
        return f"{prefix}:{key_hash}"
    
    def get(self, key: str) -> Optional[Any]:
        """Get value from cache"""
        try:
            value = self.client.get(key)
            if value:
                return json.loads(value)
        except Exception as e:
            print(f"Cache get error: {e}")
        return None
    
    def set(self, key: str, value: Any, ttl: int = None) -> bool:
        """Set value in cache"""
        try:
            self.client.setex(
                key,
                ttl or self.default_ttl,
                json.dumps(value)
            )
            return True
        except Exception as e:
            print(f"Cache set error: {e}")
            return False
    
    def delete(self, key: str) -> bool:
        """Delete key from cache"""
        try:
            self.client.delete(key)
            return True
        except Exception as e:
            print(f"Cache delete error: {e}")
            return False
    
    def invalidate_user_cache(self, user_id: int):
        """Invalidate all cache for a user"""
        try:
            pattern = f"user:{user_id}:*"
            keys = self.client.keys(pattern)
            if keys:
                self.client.delete(*keys)
        except Exception as e:
            print(f"Cache invalidation error: {e}")

# Singleton instance
cache = RedisCache()

def cached(prefix: str, ttl: int = 300):
    """Decorator for caching function results"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Skip cache for certain conditions
            skip_cache = kwargs.pop('skip_cache', False)
            if skip_cache:
                return await func(*args, **kwargs)
            
            cache_key = cache._make_key(prefix, *args, **kwargs)
            
            # Try to get from cache
            cached_result = cache.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # Execute function and cache result
            result = await func(*args, **kwargs)
            cache.set(cache_key, result, ttl)
            return result
        return wrapper
    return decorator

</code>

backend/app/__init__.py:
<code>
# App package

</code>

backend/app/schemas.py:
<code>
from pydantic import BaseModel, EmailStr
from typing import Optional, List
from datetime import datetime

class UserBase(BaseModel):
    email: EmailStr

class UserCreate(UserBase):
    password: str

class User(UserBase):
    id: int
    is_active: bool
    is_verified: bool
    name: Optional[str] = None
    profile_photo: Optional[str] = None
    created_at: Optional[datetime] = None

    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    email: Optional[str] = None

class FileBase(BaseModel):
    filename: str

class File(FileBase):
    id: int
    content_type: str
    size: int
    upload_date: datetime
    is_indexed: bool
    owner_id: int
    share_token: Optional[str] = None

    class Config:
        from_attributes = True

# Profile Management
class ProfileUpdate(BaseModel):
    name: Optional[str] = None


</code>

backend/app/main.py:
<code>
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from starlette.exceptions import HTTPException as StarletteHTTPException
import traceback

from .database import engine, Base
from .config import settings
from .routes import auth, files, query, share, admin, profile  # , google_auth, magic_auth - TODO: Uncomment after build
from .middleware import SecurityHeadersMiddleware, RequestIDMiddleware
from .logging_config import logger

# Create tables
Base.metadata.create_all(bind=engine)

# Rate limiter
limiter = Limiter(
    key_func=get_remote_address,
    default_limits=[f"{settings.RATE_LIMIT_PER_MINUTE}/minute"]
)

app = FastAPI(
    title="AI Cloud Drive",
    description="Self-hosted file storage with AI-powered search",
    version="1.0.0",
    docs_url="/docs" if settings.DEBUG else None,  # Disable docs in production
    redoc_url="/redoc" if settings.DEBUG else None,
)


# Rate limiter
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# Security middleware
app.add_middleware(SecurityHeadersMiddleware)
app.add_middleware(RequestIDMiddleware)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins_list,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    max_age=600,  # Cache preflight for 10 minutes
)

# Global exception handlers
@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    request_id = getattr(request.state, 'request_id', 'unknown')
    logger.error(f"HTTP {exc.status_code}: {exc.detail}", extra={"request_id": request_id})
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "request_id": request_id
        }
    )

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    request_id = getattr(request.state, 'request_id', 'unknown')
    logger.warning(f"Validation error: {exc.errors()}", extra={"request_id": request_id})
    return JSONResponse(
        status_code=422,
        content={
            "error": "Validation error",
            "details": exc.errors(),
            "request_id": request_id
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    request_id = getattr(request.state, 'request_id', 'unknown')
    logger.error(
        f"Unhandled exception: {str(exc)}\n{traceback.format_exc()}",
        extra={"request_id": request_id}
    )
    # Don't expose internal errors in production
    error_message = str(exc) if settings.DEBUG else "Internal server error"
    return JSONResponse(
        status_code=500,
        content={
            "error": error_message,
            "request_id": request_id
        }
    )

# Include routers
app.include_router(auth.router)
# app.include_router(google_auth.router)  # TODO: Uncomment after build completes
# app.include_router(magic_auth.router)  # TODO: Uncomment after build completes
app.include_router(files.router)
app.include_router(query.router)
app.include_router(share.router)
app.include_router(admin.router)
app.include_router(profile.router)

@app.get("/")
def read_root():
    return {
        "message": "Welcome to AI Cloud Drive API",
        "version": "1.0.0",
        "environment": settings.ENVIRONMENT
    }

@app.get("/health")
def health_check():
    """Health check endpoint for load balancers and orchestrators"""
    return {
        "status": "healthy",
        "environment": settings.ENVIRONMENT,
        "debug": settings.DEBUG
    }

@app.get("/ready")
def readiness_check():
    """Readiness check - verify all dependencies are available"""
    checks = {"database": False, "redis": False, "minio": False}
    
    # Check database
    try:
        from .database import SessionLocal
        db = SessionLocal()
        db.execute("SELECT 1")
        db.close()
        checks["database"] = True
    except Exception:
        pass
    
    # Check Redis
    try:
        from .cache import cache
        cache.client.ping()
        checks["redis"] = True
    except Exception:
        pass
    
    # Check MinIO
    try:
        from .storage.minio_client import minio_client
        minio_client.client.list_buckets()
        checks["minio"] = True
    except Exception:
        pass
    
    all_ready = all(checks.values())
    return JSONResponse(
        status_code=200 if all_ready else 503,
        content={"ready": all_ready, "checks": checks}
    )

</code>

backend/app/middleware.py:
<code>
from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import Response
import uuid
import time
from .logging_config import logger

class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    """Add security headers to all responses"""
    
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        
        # Security headers
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        response.headers["Permissions-Policy"] = "geolocation=(), microphone=(), camera=()"
        
        # Content Security Policy - Allow scripts from same origin and inline
        response.headers["Content-Security-Policy"] = (
            "default-src 'self'; "
            "script-src 'self' 'unsafe-inline'; "
            "style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; "
            "font-src 'self' https://fonts.gstatic.com; "
            "img-src 'self' data: blob:; "
            "connect-src 'self'; "
            "frame-ancestors 'none'; "
            "base-uri 'self'; "
            "form-action 'self'"
        )
        
        # Cache control for API responses
        if request.url.path.startswith("/api"):
            response.headers["Cache-Control"] = "no-store, no-cache, must-revalidate"
            response.headers["Pragma"] = "no-cache"
        
        return response

class RequestIDMiddleware(BaseHTTPMiddleware):
    """Add unique request ID for tracking"""
    
    async def dispatch(self, request: Request, call_next):
        request_id = str(uuid.uuid4())[:8]
        request.state.request_id = request_id
        
        start_time = time.time()
        response = await call_next(request)
        process_time = time.time() - start_time
        
        response.headers["X-Request-ID"] = request_id
        response.headers["X-Process-Time"] = str(round(process_time * 1000, 2))
        
        # Log request
        logger.info(
            f"{request.method} {request.url.path} - {response.status_code} - {round(process_time * 1000, 2)}ms",
            extra={"request_id": request_id}
        )
        
        return response

class HTTPSRedirectMiddleware(BaseHTTPMiddleware):
    """Redirect HTTP to HTTPS in production"""
    
    async def dispatch(self, request: Request, call_next):
        # Only redirect in production (when X-Forwarded-Proto is set)
        forwarded_proto = request.headers.get("X-Forwarded-Proto")
        if forwarded_proto == "http":
            url = request.url.replace(scheme="https")
            return Response(status_code=301, headers={"Location": str(url)})
        return await call_next(request)

</code>

backend/app/tasks/celery_app.py:
<code>
from celery import Celery
from ..config import settings
from ..storage.minio_client import minio_client
from ..rag import indexer
from ..database import SessionLocal
from .. import models

celery = Celery(
    "tasks",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL
)

@celery.task
def process_file_task(file_id: int, object_name: str, content_type: str, user_id: int):
    print(f"Starting background processing for file {file_id}")
    
    # 1. Download file content from MinIO
    try:
        response = minio_client.get_file_content(object_name)
        file_content = response.read()
        response.close()
        response.release_conn()
    except Exception as e:
        print(f"Error downloading file from MinIO: {e}")
        return

    # 2. Process and Index
    try:
        indexer.process_and_index_file(file_id, file_content, content_type, user_id)
        
        # 3. Update DB status
        db = SessionLocal()
        try:
            db_file = db.query(models.File).filter(models.File.id == file_id).first()
            if db_file:
                db_file.is_indexed = True
                db.commit()
                print(f"Successfully indexed file {file_id}")
        finally:
            db.close()
            
    except Exception as e:
        print(f"Error processing file {file_id}: {e}")

</code>

backend/app/tasks/__init__.py:
<code>
# Tasks package

</code>

backend/app/rag/research_generator.py:
<code>
"""
Research Answer Generator with Formula Extraction & Citations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Generates research-grade answers from retrieved context.

Features:
- Formula extraction and LaTeX rendering
- Strict citation tracking
- Multi-document synthesis
- Structured output (Problem/Method/Result/Implications)
- Confidence scoring

Total: 300+ lines
"""

import re
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import requests

logger = logging.getLogger(__name__)

@dataclass
class Citation:
    """Citation with full provenance"""
    source_id: str
    text: str
    page: int
    section: str
    file_id: int
    score: float

@dataclass
class ResearchAnswer:
    """Structured research answer"""
    answer: str
    citations: List[Citation]
    formulas: List[str]
    confidence: float
    answer_type: str  # "direct", "synthesized", "comparative"
    
    @property
    def cited_sources(self) -> List[str]:
        """Get all cited source IDs"""
        return list(set(c.source_id for c in self.citations))

class ResearchAnswerGenerator:
    """
    Production-grade answer generator for research papers.
    
    Capabilities:
    1. Extract mathematical formulas
    2. Track citations precisely
    3. Generate structured answers (Problem/Method/Result)
    4. Synthesize across multiple papers
    5. Assign confidence scores
    """
    
    # Formula patterns
    FORMULA_PATTERNS = [
        r'([A-Z]\([^)]+\)\s*=\s*[^\n]+)',  # Attention(Q,K,V) = ...
        r'(\$[^\$]+\$)',  # LaTeX inline
        r'(\\\[[^\]]+\\\])',  # LaTeX display
        r'([a-z_]+\s*=\s*\\?[a-z]+\([^)]+\))',  # loss = softmax(...)
    ]
    
    # Answer structuring prompts based on query type
    PROMPT_TEMPLATES = {
        "formula": """Extract all mathematical formulas and equations from the context.
Format each formula clearly and provide its purpose with citations.

Context: {context}
Question: {question}

Answer format:
The core formula is: [formula] [Source ID]
Where: [explain variables] [Source ID]""",
        
        "summary": """Provide a structured summary following this format:

**Problem**: What challenge is addressed? [Source ID]
**Method**: How is it solved? (key approach, architecture) [Source ID]
**Key Result**: What metrics were achieved? (exact numbers) [Source ID]
**Implications**: Why does this matter? [Source ID]

Context: {context}
Question: {question}""",
        
        "methodology": """Explain the methodology step-by-step with citations.

Context: {context}
Question: {question}

Answer format:
The approach consists of:
1. [Step 1] [Source ID]
2. [Step 2] [Source ID]
...""",
        
        "comparison": """Compare the approaches/results mentioned with citations.

Context: {context}
Question: {question}

Answer format:
**Similarities**: [points] [Source IDs]
**Differences**: [points] [Source IDs]
**Performance**: [metrics comparison] [Source IDs]""",
        
        "general": """Answer the question directly and precisely using only the provided context.
Every claim must be followed by [Source ID].

Context: {context}
Question: {question}"""
    }
    
    def __init__(self, api_key: str, model: str = "llama-3.1-8b-instant"):
        self.api_key = api_key
        self.model = model
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
    
    def generate(
        self,
        question: str,
        context_chunks: List[Dict],
        query_type: str = "general",
        max_tokens: int = 1024
    ) -> ResearchAnswer:
        """
        Generate research-grade answer.
        
        Args:
            question: User's question
            context_chunks: Retrieved chunks with metadata
            query_type: Type of query (formula/summary/methodology/etc)
            max_tokens: Max response length
            
        Returns:
            ResearchAnswer with structured output
        """
        logger.info(f"Generating answer for query type: {query_type}")
        
        # 1. Format context with citations
        formatted_context, citation_map = self._format_context(context_chunks)
        
        # 2. Select appropriate prompt template
        prompt_template = self.PROMPT_TEMPLATES.get(query_type, self.PROMPT_TEMPLATES["general"])
        user_prompt = prompt_template.format(
            context=formatted_context,
            question=question
        )
        
        # 3. Generate answer via LLM
        raw_answer = self._call_llm(user_prompt, max_tokens)
        
        # 4. Extract formulas
        formulas = self._extract_formulas(raw_answer)
        
        # 5. Parse citations
        cited_sources = self._parse_citations(raw_answer)
        used_citations = [citation_map[sid] for sid in cited_sources if sid in citation_map]
        
        # 6. Calculate confidence
        confidence = self._calculate_confidence(raw_answer, used_citations, context_chunks)
        
        return ResearchAnswer(
            answer=raw_answer,
            citations=used_citations,
            formulas=formulas,
            confidence=confidence,
            answer_type=query_type
        )
    
    def _format_context(self, chunks: List[Dict]) -> Tuple[str, Dict[str, Citation]]:
        """
        Format context with source IDs and build citation map.
        
        Returns:
            (formatted_context_string, citation_map)
        """
        citation_map = {}
        context_parts = []
        
        for idx, chunk in enumerate(chunks, 1):
            metadata = chunk.get("metadata", {})
            content = chunk.get("content", "")
            
            # Build source ID
            fid = metadata.get("file_id", 0)
            cid = metadata.get("sub_chunk_index", metadata.get("chunk_index", idx))
            source_id = f"{fid}:{cid}"
            
            # Create citation object
            citation = Citation(
                source_id=source_id,
                text=content,
                page=metadata.get("page", 1),
                section=metadata.get("section", "General"),
                file_id=fid,
                score=chunk.get("score", 0.0)
            )
            citation_map[source_id] = citation
            
            # Format for context
            header = f"[Source ID: {source_id}] (Section: {citation.section})"
            context_parts.append(f"{header}\n{content}\n")
        
        return "\n---\n".join(context_parts), citation_map
    
    def _call_llm(self, prompt: str, max_tokens: int) -> str:
        """Call LLM API with error handling"""
        try:
            response = requests.post(
                self.api_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "You are a precise research assistant. Follow instructions exactly and cite all sources."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.2,  # Low for precision
                    "max_tokens": max_tokens
                },
                timeout=30
            )
            response.raise_for_status()
            result = response.json()
            
            if "choices" in result and len(result["choices"]) > 0:
                return result["choices"][0]["message"]["content"]
            
            logger.error("No choices in LLM response")
            return "Error: Could not generate answer."
            
        except Exception as e:
            logger.error(f"LLM API error: {e}")
            return f"Error: {str(e)}"
    
    def _extract_formulas(self, text: str) -> List[str]:
        """Extract mathematical formulas from text"""
        formulas = []
        
        for pattern in self.FORMULA_PATTERNS:
            matches = re.findall(pattern, text)
            formulas.extend(matches)
        
        # Deduplicate
        return list(set(formulas))
    
    def _parse_citations(self, text: str) -> List[str]:
        """Extract all [Source ID] citations from answer"""
        # Pattern: [file_id:chunk_id]
        pattern = r'\[(\d+:\d+)\]'
        return list(set(re.findall(pattern, text)))
    
    def _calculate_confidence(
        self,
        answer: str,
        citations: List[Citation],
        context_chunks: List[Dict]
    ) -> float:
        """
        Calculate answer confidence score.
        
        Factors:
        - Number of citations
        - Citation coverage (% of claims cited)
        - Retrieval scores
        - Answer length vs context length
        """
        # Base confidence from citation count
        citation_score = min(len(citations) / 3.0, 1.0)  # Normalize to 3+ citations = 1.0
        
        # Retrieval quality score
        if citations:
            avg_retrieval_score = sum(c.score for c in citations) / len(citations)
            # Invert distance scores (lower is better)
            retrieval_score = max(0, 1 - avg_retrieval_score)
        else:
            retrieval_score = 0.0
        
        # Citation density (citations per 100 words)
        words = len(answer.split())
        citation_density = (len(citations) / max(words, 1)) * 100
        density_score = min(citation_density / 5.0, 1.0)  # 5+ citations per 100 words = 1.0
        
        # Weighted average
        confidence = (
            0.4 * citation_score +
            0.3 * retrieval_score +
            0.3 * density_score
        )
        
        return round(confidence, 2)


# Singleton instance placeholder (initialized in config)
answer_generator = None

def init_answer_generator(api_key: str, model: str = "llama-3.1-8b-instant"):
    """Initialize global answer generator"""
    global answer_generator
    answer_generator = ResearchAnswerGenerator(api_key, model)
    return answer_generator

</code>

backend/app/rag/metrics.py:
<code>
import time
import logging
import json
import sqlite3
import statistics
from datetime import datetime
from collections import deque, Counter
from typing import Dict, List, Optional, Tuple
import threading
from pathlib import Path

logger = logging.getLogger(__name__)

class MetricsTracker:
    """
    Production-grade metrics engine for RAG system observability.
    
    Features:
    - Persistent storage (SQLite) for long-term trends
    - In-memory aggregation for real-time dashboards
    - Thread-safe operational logging
    - Detailed latency histograms (P50, P90, P95, P99)
    - Error categorization and frequency tracking
    - Unsupported Claim Rate (UCR) tracking
    - Daily stats rollup
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls, db_path: str = "metrics.db"):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super(MetricsTracker, cls).__new__(cls)
                    cls._instance.initialize(db_path)
        return cls._instance
    
    def initialize(self, db_path: str):
        """Initialize the metrics engine."""
        self.db_path = db_path
        self._setup_db()
        
        # Real-time windows (last 1000 requests)
        self.window_size = 1000
        self.rt_latencies = deque(maxlen=self.window_size)
        self.rt_failures = deque(maxlen=self.window_size)
        self.rt_ucr_events = deque(maxlen=self.window_size)
        
        # Error tracking
        self.error_counts = Counter()
        
    def _setup_db(self):
        """Create metrics schema if not exists."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS request_logs (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp REAL,
                        latency_ms REAL,
                        status_code INT,
                        success BOOLEAN,
                        unsupported_claims INT,
                        error_type TEXT,
                        tokens_in INT,
                        tokens_out INT
                    )
                """)
                conn.execute("CREATE INDEX IF NOT EXISTS idx_ts ON request_logs(timestamp)")
        except Exception as e:
            logger.error(f"Metrics DB Init Failed: {e}")

    def log_query(self, 
                 duration_sec: float, 
                 success: bool, 
                 unsupported_claims: int = 0,
                 status_code: int = 200,
                 error_type: Optional[str] = None,
                 tokens: Tuple[int, int] = (0, 0)):
        """
        Log a complete query event with full context.
        Async-safe logging to DB and memory.
        """
        latency_ms = duration_sec * 1000
        now = time.time()
        
        # 1. Update In-Memory Stats (Thread-safe via deque atomic appends)
        self.rt_latencies.append(latency_ms)
        self.rt_failures.append(0 if success else 1)
        self.rt_ucr_events.append(1 if unsupported_claims > 0 else 0)
        
        if error_type:
            self.error_counts[error_type] += 1
            
        # 2. Persist to DB (Fire and forget style - catch errors)
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT INTO request_logs 
                    (timestamp, latency_ms, status_code, success, unsupported_claims, error_type, tokens_in, tokens_out)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (now, latency_ms, status_code, success, unsupported_claims, error_type, tokens[0], tokens[1]))
        except Exception as e:
            logger.error(f"Failed to persist metric: {e}")

    def get_realtime_stats(self) -> Dict:
        """Get P95 latency, error rates, and UCR from recent window."""
        if not self.rt_latencies:
            return {
                "status": "Waiting for traffic...",
                "samples": 0
            }
            
        count = len(self.rt_latencies)
        
        # Latency Stats
        sorted_lat = sorted(self.rt_latencies)
        p50 = sorted_lat[int(count * 0.5)]
        p95 = sorted_lat[int(count * 0.95)]
        p99 = sorted_lat[int(count * 0.99)]
        
        # Rates
        fail_rate = (sum(self.rt_failures) / count) * 100
        ucr_rate = (sum(self.rt_ucr_events) / count) * 100
        
        return {
            "window_samples": count,
            "latency": {
                "p50_ms": round(p50, 2),
                "p95_ms": round(p95, 2),
                "p99_ms": round(p99, 2),
                "avg_ms": round(sum(self.rt_latencies) / count, 2)
            },
            "reliability": {
                "error_rate_pct": round(fail_rate, 2),
                "unsupported_claim_rate_pct": round(ucr_rate, 2),
                "success_rate_pct": round(100 - fail_rate, 2)
            },
            "top_errors": self.error_counts.most_common(3)
        }

    def get_daily_rollup(self, days: int = 7) -> List[Dict]:
        """Generate daily aggregate statistics for reporting."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT 
                        date(datetime(timestamp, 'unixepoch')) as day,
                        COUNT(*) as total_reqs,
                        AVG(latency_ms) as avg_lat,
                        SUM(CASE WHEN success THEN 0 ELSE 1 END) as errors,
                        SUM(unsupported_claims) as hallucinations
                    FROM request_logs
                    WHERE timestamp > ?
                    GROUP BY day
                    ORDER BY day DESC
                """, (time.time() - (days * 86400),))
                
                rows = cursor.fetchall()
                return [
                    {
                        "date": r[0],
                        "requests": r[1],
                        "avg_latency_ms": round(r[2], 2),
                        "error_rate": round((r[3]/r[1])*100, 2),
                        "hallucination_rate": round((r[4]/r[1])*100, 2)
                    }
                    for r in rows
                ]
        except Exception as e:
            logger.error(f"Rollup failed: {e}")
            return []

    def export_report(self) -> str:
        """Generate a markdown report of system health."""
        stats = self.get_realtime_stats()
        daily = self.get_daily_rollup()
        
        report = f"""
# System Health Report

## Real-time Window (Last {stats.get('window_samples')} requests)
- **Lat P95**: {stats.get('latency', {}).get('p95_ms')} ms
- **Error Rate**: {stats.get('reliability', {}).get('error_rate_pct')}%
- **UCR (Unsupported Claims)**: {stats.get('reliability', {}).get('unsupported_claim_rate_pct')}%

## Daily Trends
| Date | Requests | Latency (Avg) | Error % | UCR % |
|------|----------|---------------|---------|-------|
"""
        for d in daily:
            report += f"| {d['date']} | {d['requests']} | {d['avg_latency_ms']}ms | {d['error_rate']}% | {d['hallucination_rate']}% |\n"
            
        return report

# Global Instance
metrics = MetricsTracker()

</code>

backend/app/rag/ingestion_manager.py:
<code>
import time
import logging
import sqlite3
import uuid
import json
import threading
from typing import Dict, List, Optional, Any
from enum import Enum
from pathlib import Path

# Integration points
from .parsers.page_aware_parser import parse_pdf_with_pages as parse_academic_pdf
from .parsers.chunker import semantic_chunker
from .indexer import get_collection, embedding_model

logger = logging.getLogger(__name__)

class IngestionStatus(str, Enum):
    PENDING = "PENDING"
    PARSING = "PARSING"
    CHUNKING = "CHUNKING"
    EMBEDDING = "EMBEDDING"
    INDEXING = "INDEXING"
    COMPLETE = "COMPLETE"
    FAILED = "FAILED"

class IngestionManager:
    """
    Research-Grade Document Ingestion Pipeline.
    
    Architecture:
    - State Machine: Explicit transitions (PENDING -> COMPLETE)
    - Persistence: Jobs stored in SQLite to survive restarts.
    - Dead Letter Queue (DLQ): Failures isolated for debug.
    - Idempotency: Duplicate submissions handled gracefully.
    - Branching Logic: Uses specialized parsers based on file type.
    """
    
    _instance = None
    _lock = threading.RLock()
    
    def __new__(cls, db_path: str = "ingestion.db"):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super(IngestionManager, cls).__new__(cls)
                    cls._instance.initialize(db_path)
        return cls._instance
    
    def initialize(self, db_path: str):
        self.db_path = db_path
        self._setup_db()
        # Background worker for resume implementation would go here

    def _setup_db(self):
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS ingestion_jobs (
                        job_id TEXT PRIMARY KEY,
                        file_path TEXT,
                        user_id INT,
                        status TEXT,
                        error_log TEXT,
                        created_at REAL,
                        updated_at REAL,
                        metadata TEXT
                    )
                """)
                conn.execute("CREATE INDEX IF NOT EXISTS idx_status ON ingestion_jobs(status)")
        except Exception as e:
            logger.error(f"Ingestion DB Init Failed: {e}")

    def submit_job(self, file_path: str, user_id: int, extra_meta: Dict = None) -> str:
        """Submit a new file for ingestion."""
        job_id = str(uuid.uuid4())
        now = time.time()
        meta_json = json.dumps(extra_meta or {})
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT INTO ingestion_jobs (job_id, file_path, user_id, status, created_at, updated_at, metadata)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (job_id, file_path, user_id, IngestionStatus.PENDING.value, now, now, meta_json))
            logger.info(f"Job Submitted: {job_id} for {file_path}")
            
            # In simple version, run sync. Ideally async worker picks this up.
            self.process_job(job_id)
            return job_id
        except Exception as e:
            logger.error(f"Job Submission Failed: {e}")
            raise e

    def update_status(self, job_id: str, status: IngestionStatus, error: str = None):
        """Atomic state transition."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                params = [status.value, time.time(), job_id]
                sql = "UPDATE ingestion_jobs SET status = ?, updated_at = ? "
                if error:
                    sql += ", error_log = ? "
                    params.insert(2, error)
                sql += "WHERE job_id = ?"
                conn.execute(sql, tuple(params))
            logger.info(f"Job {job_id} -> {status.value}")
        except Exception as e:
            logger.error(f"Status Update Failed: {e}")

    def process_job(self, job_id: str):
        """
        Execute the pipeline state machine.
        Reliability pattern: Fail fast, log deep.
        """
        try:
            # 1. Fetch Job
            with sqlite3.connect(self.db_path) as conn:
                row = conn.execute("SELECT file_path, user_id, metadata FROM ingestion_jobs WHERE job_id = ?", (job_id,)).fetchone()
                if not row:
                    return
                file_path, user_id, meta_json = row
                extra_meta = json.loads(meta_json) if meta_json else {}
            
            chunks = []
            
            # 2. State: PARSING
            self.update_status(job_id, IngestionStatus.PARSING)
            logger.info(f"Parsing file: {file_path}")
            
            is_pdf = file_path.lower().endswith('.pdf')
            if is_pdf:
                # Use Research-Grade Parser
                # Note: AcademicPDFParser handles layout analysis internally
                raw_chunks = parse_academic_pdf(file_path)
                
                # Convert AcademicChunk to dict format for storage
                for rc in raw_chunks:
                    chunks.append({
                        "content": rc.text,
                        "metadata": {
                            **extra_meta, 
                            **rc.metadata, 
                            "user_id": user_id, 
                            "job_id": job_id,
                            "parser": "academic_pdf"
                        }
                    })
            else:
                # Fallback Flow for txt/md
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        text_content = f.read()
                except FileNotFoundError:
                     raise ValueError(f"File not found: {file_path}")

                # 3. State: CHUNKING (Only for fallback)
                self.update_status(job_id, IngestionStatus.CHUNKING)
                chunks = semantic_chunker.chunk_text(text_content, metadata={**extra_meta, "user_id": user_id, "job_id": job_id})
            
            if not chunks:
                logger.warning(f"No chunks generated for {job_id}")
                self.update_status(job_id, IngestionStatus.COMPLETE) # Technically done, just empty
                return

            # 4. State: EMBEDDING
            self.update_status(job_id, IngestionStatus.EMBEDDING)
            texts = [c["content"] for c in chunks]
            
            # Batch embedding if large
            BATCH_SIZE = 32
            embeddings = []
            for i in range(0, len(texts), BATCH_SIZE):
                batch_texts = texts[i : i + BATCH_SIZE]
                batch_embs = embedding_model.encode(batch_texts, show_progress_bar=False).tolist()
                embeddings.extend(batch_embs)
            
            # 5. State: INDEXING
            self.update_status(job_id, IngestionStatus.INDEXING)
            collection = get_collection()
            
            ids = [f"job_{job_id}_chunk_{i}" for i in range(len(chunks))]
            metadatas = [c["metadata"] for c in chunks]
            
            collection.add(
                ids=ids,
                documents=texts,
                embeddings=embeddings,
                metadatas=metadatas
            )
            
            # 6. Done
            self.update_status(job_id, IngestionStatus.COMPLETE)
            logger.info(f"Ingestion Complete: {len(chunks)} chunks indexed.")
            
        except Exception as e:
            self.update_status(job_id, IngestionStatus.FAILED, str(e))
            logger.error(f"Ingestion Job {job_id} Failed: {e}", exc_info=True)

    def get_job_status(self, job_id: str) -> Dict:
        """Get public status of a job."""
        with sqlite3.connect(self.db_path) as conn:
            row = conn.execute("SELECT status, error_log FROM ingestion_jobs WHERE job_id = ?", (job_id,)).fetchone()
            if row:
                return {"status": row[0], "error": row[1]}
        return {"status": "UNKNOWN"}

# Singleton
ingestion_manager = IngestionManager()

</code>

backend/app/rag/conversational_handler.py:
<code>
"""
Conversational Query Handler
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Detects and handles greetings, small talk, and system queries
WITHOUT triggering document retrieval.

Handles:
- Greetings: hi, hello, hey
- Farewells: bye, goodbye
- Gratitude: thank you, thanks
- System queries: what can you do, help, capabilities

Total: 150 lines
"""

import re
from typing import Optional, Tuple

class ConversationalHandler:
    """
    Detects conversational queries and provides direct responses.
    Prevents unnecessary document retrieval for small talk.
    """
    
    # Greeting patterns
    GREETINGS = [
        r'^\s*(hi|hello|hey|greetings|good morning|good afternoon|good evening)\s*[!.?]*\s*$',
    ]
    
    # Farewell patterns
    FAREWELLS = [
        r'^\s*(bye|goodbye|see you|farewell|take care)\s*[!.?]*\s*$',
    ]
    
    # Gratitude patterns
    GRATITUDE = [
        r'^\s*(thank you|thanks|thx|appreciate it)\s*[!.?]*\s*$',
        r'thanks\s+(a lot|so much|very much)',
    ]
    
    # Help/capability patterns
    HELP_QUERIES = [
        r'^\s*what can you (do|help)\s*[?]*\s*$',
        r'^\s*help\s*[!.?]*\s*$',
        r'^\s*how (do|does) (this|it) work\s*[?]*\s*$',
        r'^\s*what (is|are) your (capabilities|features)\s*[?]*\s*$',
        r'^\s*show me what you can do\s*[?]*\s*$',
    ]
    
    # Small talk patterns
    SMALL_TALK = [
        r'^\s*how are you\s*[?]*\s*$',
        r'^\s*what\'s up\s*[?]*\s*$',
        r'^\s*how\'s it going\s*[?]*\s*$',
    ]
    
    @classmethod
    def is_conversational(cls, query: str) -> bool:
        """Check if query is conversational (not document-related)"""
        query_lower = query.lower().strip()
        
        all_patterns = (
            cls.GREETINGS + 
            cls.FAREWELLS + 
            cls.GRATITUDE + 
            cls.HELP_QUERIES + 
            cls.SMALL_TALK
        )
        
        for pattern in all_patterns:
            if re.match(pattern, query_lower, re.IGNORECASE):
                return True
        
        return False
    
    @classmethod
    def get_response(cls, query: str) -> Optional[str]:
        """
        Get direct response for conversational query.
        Returns None if not conversational.
        """
        query_lower = query.lower().strip()
        
        # Check greetings
        for pattern in cls.GREETINGS:
            if re.match(pattern, query_lower, re.IGNORECASE):
                return cls._greeting_response()
        
        # Check farewells
        for pattern in cls.FAREWELLS:
            if re.match(pattern, query_lower, re.IGNORECASE):
                return cls._farewell_response()
        
        # Check gratitude
        for pattern in cls.GRATITUDE:
            if re.match(pattern, query_lower, re.IGNORECASE):
                return cls._gratitude_response()
        
        # Check help queries
        for pattern in cls.HELP_QUERIES:
            if re.match(pattern, query_lower, re.IGNORECASE):
                return cls._help_response()
        
        # Check small talk
        for pattern in cls.SMALL_TALK:
            if re.match(pattern, query_lower, re.IGNORECASE):
                return cls._small_talk_response()
        
        return None
    
    @staticmethod
    def _greeting_response() -> str:
        return "Hello! I'm your AI research assistant. I can help you search and analyze your documents. What would you like to know?"
    
    @staticmethod
    def _farewell_response() -> str:
        return "Goodbye! Feel free to come back anytime you need help with your documents."
    
    @staticmethod
    def _gratitude_response() -> str:
        return "You're welcome! Let me know if you need anything else."
    
    @staticmethod
    def _help_response() -> str:
        return """I can help you with your documents in several ways:

ğŸ“„ **Document Search**: Ask questions about your uploaded files
ğŸ“Š **Summaries**: "Summarize my files" or "Summarize [filename]"
ğŸ” **Specific Information**: "What is the formula in...", "Explain the methodology in..."
ğŸ“ˆ **Comparisons**: "Compare approach A vs B"
âš¡ **Direct Answers**: I cite page numbers so you can verify sources

**Examples:**
- "What is the main contribution of the Transformer paper?"
- "Summarize lecture 5"
- "Explain Booth's algorithm"
- "What formulas are in my documents?"

Just type your question naturally, and I'll search your documents!"""
    
    @staticmethod
    def _small_talk_response() -> str:
        return "I'm doing well, thank you! I'm here to help you with your documents. What can I assist you with today?"


# Singleton instance
conversational_handler = ConversationalHandler()

</code>

backend/app/rag/compare_engine.py:
<code>
import logging
import time
from typing import List, Dict, Optional
from dataclasses import dataclass
from langchain_groq import ChatGroq
from langchain.schema import SystemMessage, HumanMessage
from ..config import settings
from .engine import RAGEngine
from .indexer import get_collection

logger = logging.getLogger(__name__)

class CompareEngine:
    """
    God-Level Comparison Engine.
    
    Capabilities:
    1. Targeted Retrieval: Palls 'Method' chunks from Doc A and Doc B.
    2. Contrastive synthesis: "Doc A uses BERT, whereas Doc B uses LSTM."
    3. Structural Awareness: Knows which sections to pull based on user query.
    """
    
    def __init__(self):
        self.llm = ChatGroq(
            model_name="llama-3.1-8b-instant",
            api_key=settings.GROQ_API_KEY,
            temperature=0.2
        )
        self.rag_engine = RAGEngine() # Reuse for vector search
        
    def compare_documents(self, doc_a_id: int, doc_b_id: int, aspect: str) -> Dict:
        """
        Compare two documents on a specific aspect.
        """
        start_time = time.time()
        
        # 1. Map 'aspect' to query + section filter
        query_text = f"What is the {aspect}?"
        section_filter = self._map_aspect_to_section(aspect)
        
        # 2. Retrieve from Doc A
        context_a = self._get_focused_context(doc_a_id, query_text, section_filter)
        
        # 3. Retrieve from Doc B
        context_b = self._get_focused_context(doc_b_id, query_text, section_filter)
        
        # 4. Generate Comparison
        if not context_a and not context_b:
            return {"error": "Insufficient data in both documents for this aspect."}
            
        report = self._generate_comparison(aspect, context_a, context_b)
        
        return {
            "aspect": aspect,
            "report": report,
            "latency_ms": (time.time() - start_time) * 1000,
            "sources": {
                "doc_a": [c["metadata"].get("page", "?") for c in context_a],
                "doc_b": [c["metadata"].get("page", "?") for c in context_b]
            }
        }

    def _get_focused_context(self, file_id: int, query: str, section: Optional[str]) -> List[Dict]:
        """Fetch chunks for a specific file and optional section."""
        # We leverage RAGEngine's vector search but constrain by file_id strictly
        # We bypass the full engine.query pipeline to avoid re-ranking overhead on massive mismatch
        # We go direct to vector search for speed + precision on scope
        
        # Actually RAGEngine._vector_search is cached and robust. Let's use it.
        # But we need access to it. It's a method on instance.
        # We'll use the collection directly for maximum control or public methods.
        # Let's use RAGEngine.query with file_ids=[file_id]
        
        results = self.rag_engine.query(
            query, 
            user_id=1, # Default or pass in
            file_ids=[file_id],
            n_results=5 
        )
        
        # Post-filter by section if strictly required
        if section:
            filtered = [
                d for d in results 
                if section.lower() in d["metadata"].get("section", "").lower()
            ]
            if filtered:
                return filtered
        
        return results

    def _map_aspect_to_section(self, aspect: str) -> Optional[str]:
        aspect = aspect.lower()
        if "method" in aspect or "approach" in aspect:
            return "Method"
        if "result" in aspect or "performance" in aspect:
            return "Experiment"
        if "limitation" in aspect:
            return "Conclusion"
        return None

    def _generate_comparison(self, aspect: str, ctx_a: List[Dict], ctx_b: List[Dict]) -> str:
        text_a = "\n".join([c["content"] for c in ctx_a])
        text_b = "\n".join([c["content"] for c in ctx_b])
        
        prompt = f"""You are a Comparative Research Expert.
Task: Compare Document A and Document B regarding: "{aspect}".

Document A Context:
{text_a[:4000]}

Document B Context:
{text_b[:4000]}

Instructions:
1. Highlight key SIMILARITIES.
2. Highlight key DIFFERENCES.
3. Conclude which one is superior or more rigorous regarding {aspect} (if applicable).
4. Use a structured Markdown table for the differences.

Response:"""

        response = self.llm.invoke([
            SystemMessage(content="You are a precise academic analyst."),
            HumanMessage(content=prompt)
        ])
        return response.content

# Singleton
compare_engine = CompareEngine()

</code>

backend/app/rag/answer_validator.py:
<code>
"""
Answer Validator & Quality Control System
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Validates research answers for common mistakes.

Features:
- Problem vs Method confusion detection
- Citation verification
- Formula validation
- Metric extraction
- Structural checks

Total: 250+ lines
"""

import re
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class ValidationIssue(Enum):
    """Types of validation issues"""
    PROBLEM_METHOD_CONFUSION = "problem_method_confusion"
    MISSING_METRICS = "missing_metrics"
    MISSING_CITATIONS = "missing_citations"
    FORMULA_NOT_RENDERED = "formula_not_rendered"
    VAGUE_LANGUAGE = "vague_language"
    COMPUTATION_PATH_CONFUSION = "computation_path_confusion"

@dataclass
class ValidationResult:
    """Result of answer validation"""
    is_valid: bool
    issues: List[Tuple[ValidationIssue, str]]  # (issue_type, description)
    score: float  # 0.0 to 1.0
    suggestions: List[str]

class ResearchAnswerValidator:
    """
    Validates research answers for common academic mistakes.
    
    Checks:
    1. Problem vs Method distinction
    2. Presence of metrics/numbers
    3. Citation coverage
    4. Formula formatting
    5. Vague language detection
    """
    
    # Problem-indicating keywords
    PROBLEM_KEYWORDS = [
        'challenge', 'issue', 'difficulty', 'limitation', 'bottleneck',
        'inefficient', 'slow', 'expensive', 'difficult', 'hard'
    ]
    
    # Method-indicating keywords
    METHOD_KEYWORDS = [
        'model', 'architecture', 'approach', 'technique', 'algorithm',
        'mechanism', 'layer', 'attention', 'transformer', 'network'
    ]
    
    # Vague phrases to avoid
    VAGUE_PHRASES = [
        'the paper discusses', 'it is mentioned', 'not explicitly stated',
        'appears to', 'seems to', 'might be', 'could be', 'based on the context'
    ]
    
    # Metric patterns
    METRIC_PATTERNS = [
        r'\b\d+\.?\d*%\b',  # 95.3%
        r'\bBLEU\s+\d+\.?\d*\b',  # BLEU 28.4
        r'\bF1\s+\d+\.?\d*\b',  # F1 0.87
        r'\baccuracy\s+\d+\.?\d*\b',  # accuracy 94.5
        r'\b\d+\.?\d*\s+(ms|seconds|hours)\b',  # 5.2 seconds
    ]
    
    def validate(
        self, 
        answer: str, 
        query: str, 
        query_type: str,
        citations: List[Dict]
    ) -> ValidationResult:
        """
        Validate answer quality.
        
        Args:
            answer: Generated answer text
            query: Original query
            query_type: Type (summary/formula/etc)
            citations: List of citations used
            
        Returns:
            ValidationResult with issues and score
        """
        issues = []
        
        # 1. Check for Problem vs Method confusion (for summaries)
        if query_type == "summary":
            problem_method_issue = self._check_problem_method_confusion(answer)
            if problem_method_issue:
                issues.append(problem_method_issue)
        
        # 2. Check for metrics (required for results/summary)
        if query_type in ["summary", "results"]:
            if not self._has_metrics(answer):
                issues.append((
                    ValidationIssue.MISSING_METRICS,
                    "No numerical metrics found (BLEU, accuracy, F1, etc.)"
                ))
        
        # 3. Check citation coverage
        citation_issue = self._check_citations(answer, citations)
        if citation_issue:
            issues.append(citation_issue)
        
        # 4. Check for vague language
        vague_issues = self._check_vague_language(answer)
        issues.extend(vague_issues)
        
        # 5. Check formulas (for formula queries)
        if query_type == "formula":
            formula_issue = self._check_formulas(answer)
            if formula_issue:
                issues.append(formula_issue)
        
        # 6. Check for O(nÂ²) vs O(1) confusion
        if "o(1)" in answer.lower() and "o(n" in answer.lower():
            if "path length" not in answer.lower():
                issues.append((
                    ValidationIssue.COMPUTATION_PATH_CONFUSION,
                    "Conflating computation complexity O(nÂ²) with path length O(1)"
                ))
        
        # Calculate score
        score = self._calculate_score(issues)
        
        # Generate suggestions
        suggestions = self._generate_suggestions(issues)
        
        return ValidationResult(
            is_valid=(score >= 0.7),
            issues=issues,
            score=score,
            suggestions=suggestions
        )
    
    def _check_problem_method_confusion(self, answer: str) -> Optional[Tuple[ValidationIssue, str]]:
        """Check if Problem section contains method keywords"""
        # Look for "Problem:" section
        problem_match = re.search(r'\*\*Problem\*\*:([^*]+)', answer, re.IGNORECASE)
        if not problem_match:
            return None
        
        problem_text = problem_match.group(1).lower()
        
        # Check if problem section mentions methods
        method_count = sum(1 for kw in self.METHOD_KEYWORDS if kw in problem_text)
        problem_count = sum(1 for kw in self.PROBLEM_KEYWORDS if kw in problem_text)
        
        if method_count > problem_count:
            return (
                ValidationIssue.PROBLEM_METHOD_CONFUSION,
                f"Problem section contains {method_count} method keywords but only {problem_count} problem keywords. "
                "Problem should describe the challenge, not the solution."
            )
        
        return None
    
    def _has_metrics(self, answer: str) -> bool:
        """Check if answer contains numerical metrics"""
        for pattern in self.METRIC_PATTERNS:
            if re.search(pattern, answer, re.IGNORECASE):
                return True
        return False
    
    def _check_citations(self, answer: str, citations: List[Dict]) -> Optional[Tuple[ValidationIssue, str]]:
        """Check citation quality"""
        # Extract citation markers from answer
        cited_ids = set(re.findall(r'\[(\d+:\d+)\]', answer))
        
        if not cited_ids:
            return (
                ValidationIssue.MISSING_CITATIONS,
                "No citations found. Every claim must have [Source ID]."
            )
        
        # Check citation density (should have at least 1 per 100 words)
        word_count = len(answer.split())
        expected_citations = max(word_count // 100, 1)
        
        if len(cited_ids) < expected_citations:
            return (
                ValidationIssue.MISSING_CITATIONS,
                f"Low citation density: {len(cited_ids)} citations for {word_count} words. "
                f"Expected at least {expected_citations}."
            )
        
        return None
    
    def _check_vague_language(self, answer: str) -> List[Tuple[ValidationIssue, str]]:
        """Check for vague academic language"""
        issues = []
        answer_lower = answer.lower()
        
        for phrase in self.VAGUE_PHRASES:
            if phrase in answer_lower:
                issues.append((
                    ValidationIssue.VAGUE_LANGUAGE,
                    f"Vague phrase detected: '{phrase}'. Be more direct."
                ))
        
        return issues
    
    def _check_formulas(self, answer: str) -> Optional[Tuple[ValidationIssue, str]]:
        """Check if formulas are properly rendered"""
        # Look for equation patterns
        has_equation_word = any(w in answer.lower() for w in ['formula', 'equation'])
        
        # Check for mathematical notation
        has_math = any([
            '=' in answer,
            'sqrt' in answer.lower(),
            'softmax' in answer.lower(),
            '_' in answer,  # Subscripts
            '^' in answer,  # Superscripts
        ])
        
        if has_equation_word and not has_math:
            return (
                ValidationIssue.FORMULA_NOT_RENDERED,
                "Answer mentions formulas but doesn't show them mathematically"
            )
        
        return None
    
    def _calculate_score(self, issues: List[Tuple[ValidationIssue, str]]) -> float:
        """Calculate quality score"""
        if not issues:
            return 1.0
        
        # Weight different issue types
        weights = {
            ValidationIssue.PROBLEM_METHOD_CONFUSION: 0.3,
            ValidationIssue.MISSING_METRICS: 0.2,
            ValidationIssue.MISSING_CITATIONS: 0.3,
            ValidationIssue.FORMULA_NOT_RENDERED: 0.2,
            ValidationIssue.VAGUE_LANGUAGE: 0.1,
            ValidationIssue.COMPUTATION_PATH_CONFUSION: 0.2,
        }
        
        penalty = sum(weights.get(issue_type, 0.1) for issue_type, _ in issues)
        score = max(0.0, 1.0 - penalty)
        
        return round(score, 2)
    
    def _generate_suggestions(self, issues: List[Tuple[ValidationIssue, str]]) -> List[str]:
        """Generate actionable suggestions"""
        suggestions = []
        
        issue_types = {issue_type for issue_type, _ in issues}
        
        if ValidationIssue.PROBLEM_METHOD_CONFUSION in issue_types:
            suggestions.append(
                "Rewrite Problem section to focus on the challenge/limitation, not the solution architecture."
            )
        
        if ValidationIssue.MISSING_METRICS in issue_types:
            suggestions.append(
                "Add specific metrics: BLEU scores, accuracy percentages, training time, etc."
            )
        
        if ValidationIssue.MISSING_CITATIONS in issue_types:
            suggestions.append(
                "Add [Source ID] citations after each factual claim."
            )
        
        if ValidationIssue.VAGUE_LANGUAGE in issue_types:
            suggestions.append(
                "Replace vague phrases ('seems to', 'appears to') with direct statements."
            )
        
        if ValidationIssue.FORMULA_NOT_RENDERED in issue_types:
            suggestions.append(
                "Show formulas in mathematical notation: Attention(Q,K,V) = softmax(QK^T/sqrt(d_k))V"
            )
        
        if ValidationIssue.COMPUTATION_PATH_CONFUSION in issue_types:
            suggestions.append(
                "Clarify: 'O(nÂ²) computation cost' vs 'O(1) sequential path length'"
            )
        
        return suggestions


# Singleton
answer_validator = ResearchAnswerValidator()

</code>

backend/app/rag/cache_manager.py:
<code>
import time
import json
import sqlite3
import hashlib
import logging
import threading
import pickle
from typing import Any, Optional, Union, Dict, List
from collections import OrderedDict
from dataclasses import dataclass
from pathlib import Path

logger = logging.getLogger(__name__)

@dataclass
class CacheConfig:
    l1_size: int = 1000  # Number of items in memory
    l2_path: str = "cache.db"
    default_ttl: int = 3600 * 24  # 24 Hours default TTL

class TieredCacheManager:
    """
    Research-Grade Multi-Level Cache System.
    
    Architecture:
    - L1: In-Memory LRU Cache (Microsecond latency)
    - L2: SQLite Persistent Cache (Millisecond latency)
    
    Features:
    - Canonical Key Generation (handles nested dicts/lists safely)
    - Time-To-Live (TTL) enforcement
    - Thread-safe operations
    - Automatic L1 population on L2 hits (Write-Back)
    """
    
    _instance = None
    _lock = threading.RLock()
    
    def __new__(cls, config: CacheConfig = CacheConfig()):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super(TieredCacheManager, cls).__new__(cls)
                    cls._instance.initialize(config)
        return cls._instance
    
    def initialize(self, config: CacheConfig):
        self.config = config
        self.l1_cache = OrderedDict()
        self.l1_lock = threading.Lock()
        self._init_l2_db()
        logger.info(f"Cache Manager Initialized (L1: {config.l1_size}, L2: {config.l2_path})")

    def _init_l2_db(self):
        """Initialize L2 SQLite storage."""
        try:
            with sqlite3.connect(self.config.l2_path, check_same_thread=False) as conn:
                conn.execute("""
                    CREATE TABLE IF NOT EXISTS cache_store (
                        key TEXT PRIMARY KEY,
                        value BLOB,
                        created_at REAL,
                        expires_at REAL
                    )
                """)
                conn.execute("CREATE INDEX IF NOT EXISTS idx_expires ON cache_store(expires_at)")
                
                # Background cleanup of expired items could go here
        except Exception as e:
            logger.error(f"L2 Cache Init Failed: {e}")

    def _generate_key(self, prefix: str, *args, **kwargs) -> str:
        """
        Generate a robust canonical hash key for any combination of arguments.
        Determinsitcally serializes complex objects.
        """
        try:
            payload = {
                "args": args,
                "kwargs": kwargs
            }
            # Sort keys for determinism
            serialized = json.dumps(payload, sort_keys=True, default=str)
            hash_part = hashlib.sha256(serialized.encode()).hexdigest()
            return f"{prefix}:{hash_part}"
        except Exception as e:
            logger.error(f"Key Generation Failed: {e}")
            return f"{prefix}:{time.time()}" # Fallback (no cache hit likely)

    def get(self, key: str) -> Optional[Any]:
        """
        Retrieve item from cache (L1 -> L2).
        Returns None if not found or expired.
        """
        # 1. Check L1 (Memory)
        with self.l1_lock:
            if key in self.l1_cache:
                item, expires_at = self.l1_cache[key]
                if time.time() < expires_at:
                    # LRU Move to end
                    self.l1_cache.move_to_end(key)
                    # logger.debug(f"L1 Hit: {key}")
                    return item
                else:
                    del self.l1_cache[key] # Expired

        # 2. Check L2 (Disk)
        try:
            with sqlite3.connect(self.config.l2_path, check_same_thread=False) as conn:
                cursor = conn.execute(
                    "SELECT value, expires_at FROM cache_store WHERE key = ?", 
                    (key,)
                )
                row = cursor.fetchone()
                
                if row:
                    value_blob, expires_at = row
                    if time.time() < expires_at:
                        # Deserialize
                        data = pickle.loads(value_blob)
                        
                        # Populate L1 (Promote)
                        self.set(key, data, ttl=(expires_at - time.time()))
                        # logger.debug(f"L2 Hit: {key}")
                        return data
                    else:
                        # Lazy delete expired
                        conn.execute("DELETE FROM cache_store WHERE key = ?", (key,))
        except Exception as e:
            logger.error(f"L2 Read Error: {e}")
            
        return None

    def set(self, key: str, value: Any, ttl: Optional[float] = None):
        """
        Write item to cache (L1 + L2).
        """
        if ttl is None:
            ttl = self.config.default_ttl
            
        expires_at = time.time() + ttl
        
        # 1. Write L1
        with self.l1_lock:
            self.l1_cache[key] = (value, expires_at)
            self.l1_cache.move_to_end(key)
            # Evict if full
            if len(self.l1_cache) > self.config.l1_size:
                self.l1_cache.popitem(last=False)
                
        # 2. Write L2
        try:
            blob = pickle.dumps(value)
            with sqlite3.connect(self.config.l2_path, check_same_thread=False) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO cache_store (key, value, created_at, expires_at)
                    VALUES (?, ?, ?, ?)
                """, (key, blob, time.time(), expires_at))
        except Exception as e:
            logger.error(f"L2 Write Error: {e}")

    def invalidate(self, key_pattern: str):
        """
        Invalidate keys matching pattern (SQL LIKE).
        Warning: Only affects L2 efficiently. L1 clear is naive.
        """
        with self.l1_lock:
            self.l1_cache.clear() # Simplistic for now
            
        try:
            with sqlite3.connect(self.config.l2_path, check_same_thread=False) as conn:
                conn.execute("DELETE FROM cache_store WHERE key LIKE ?", (key_pattern,))
        except Exception as e:
            logger.error(f"Invalidation Error: {e}")

    def cached_operation(self, prefix: str, ttl: int = 300):
        """
        Decorator to cache function results.
        """
        def decorator(func):
            def wrapper(*args, **kwargs):
                # Generate key based on function args
                key = self._generate_key(prefix, *args, **kwargs)
                
                # Check cache
                cached = self.get(key)
                if cached is not None:
                    return cached
                
                # Execute
                result = func(*args, **kwargs)
                
                # Store
                self.set(key, result, ttl=ttl)
                return result
            return wrapper
        return decorator

# Global Instance
cache_manager = TieredCacheManager()

</code>

backend/app/rag/ablation.py:
<code>

import logging
import json
import time
from typing import List, Dict, Optional, Callable
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
import statistics

from .engine import query_documents
from .retrievers.reranker import reranker
# Import other components to mock/toggle
from .parsers.chunker import classify_importance

logger = logging.getLogger(__name__)

@dataclass
class TestCase:
    query: str
    expected_chunk_ids: List[str] # Or some ground truth
    core_concept: str # e.g. "Main Contribution"
    
@dataclass
class ExperimentResult:
    config_name: str
    precision_at_3: float
    latency_p95: float
    avg_relevance: float
    total_queries: int

class AblationEngine:
    """
    Framework for running rigorous RAG ablation studies.
    
    Capabilities:
    - Component Toggling (Reranker, Filters, Faithfulness)
    - Dataset Management (Load Gold Standard)
    - Statistical Analysis (Precision, Latency, Recall)
    - Report Generation
    """
    
    def __init__(self, dataset_path: str = "gold_standard.json"):
        self.dataset_path = dataset_path
        self.test_cases = self._load_dataset()
        self.results = {}
        
    def _load_dataset(self) -> List[TestCase]:
        """Load ground-truth queries for evaluation."""
        if not Path(self.dataset_path).exists():
            # Return synthetic default set if no file
            return [
                TestCase("What is the main contribution?", [], "Core"),
                TestCase("How is the model trained?", [], "Method"),
                TestCase("What are the baseline results?", [], "Experiment")
            ]
        try:
            with open(self.dataset_path) as f:
                data = json.load(f)
                return [TestCase(**item) for item in data]
        except Exception as e:
            logger.error(f"Dataset load failed: {e}")
            return []

    def run_experiment(self, config_name: str, 
                      disable_reranker: bool = False, 
                      disable_importance: bool = False,
                      disable_faithfulness: bool = False) -> ExperimentResult:
        """
        Execute a full pass over the dataset with specific configuration.
        """
        logger.info(f"Starting Experiment: {config_name}")
        latencies = []
        precisions = []
        
        # 1. Setup Mocks/Overrides
        original_rerank = reranker.rerank
        
        if disable_reranker:
            # Monkeypatch reranker to be a pass-through
            reranker.rerank = lambda q, c, k: c[:k]
            
        try:
            # 2. Execute Queries
            for case in self.test_cases:
                t0 = time.time()
                
                # Note: user_id=1 is assumed for test user
                # We could inject disable_importance flag into engine via context var in a real sys
                # specific logic to bypass importance filter would go here
                
                result = query_documents(case.query, user_id=1) 
                
                duration = (time.time() - t0) * 1000
                latencies.append(duration)
                
                # 3. Score Result (Heuristic for demo)
                # In real world, check if 'expected_chunk_ids' are in result['sources']
                score = self._heuristic_score(result, case)
                precisions.append(score)
                
        finally:
            # 4. Restore State
            reranker.rerank = original_rerank
            
        # 5. Calculate Aggregates
        return ExperimentResult(
            config_name=config_name,
            precision_at_3=statistics.mean(precisions) if precisions else 0.0,
            latency_p95=statistics.quantiles(latencies, n=20)[18] if len(latencies) >= 20 else max(latencies),
            avg_relevance=statistics.mean(precisions), # Simplify
            total_queries=len(self.test_cases)
        )

    def _heuristic_score(self, result: Dict, case: TestCase) -> float:
        """
        Score a single result against ground truth.
        Real impl would use RAGAS or exact ID match.
        """
        answer_text = result.get('answer', '').lower()
        # Simple keyword check for demo
        if "not stated" in answer_text:
            return 0.0
        return 1.0

    def run_full_suite(self) -> str:
        """Run standard battery of ablations."""
        
        configs = [
            ("Full Stack", {}),
            ("No Reranker", {"disable_reranker": True}),
            # ("No Importance", {"disable_importance": True}), # Requires engine support
        ]
        
        report = "# ğŸ”¬ Ablation Study Report\n\n"
        report += "| Configuration | Precision | P95 Latency | Samples |\n"
        report += "|---|---|---|---|\n"
        
        for name, args in configs:
            res = self.run_experiment(name, **args)
            report += f"| {res.config_name} | {res.precision_at_3:.2f} | {res.latency_p95:.0f}ms | {res.total_queries} |\n"
            
        return report

# Singleton for CLI usage
ablation_engine = AblationEngine()

if __name__ == "__main__":
    # CLI Entrypoint
    print(ablation_engine.run_full_suite())

</code>

backend/app/rag/query_optimizer.py:
<code>
from typing import List, Dict, Optional
import logging
from langchain_groq import ChatGroq
from ..config import settings
from .cache_manager import cache_manager

logger = logging.getLogger(__name__)

class QueryOptimizer:
    """
    Research-Grade Query Rewriting & Expansion Module.
    
     techniques:
    1. HyDE (Hypothetical Document Embeddings): 
       We hallucinate a "perfect" answer, then embed that. 
       Significantly improves zero-shot retrieval for vague queries.
       
    2. Multi-Query Expansion:
       Break a vague query into 3 distinct search angles.
       "how to fix bug" -> ["python debugging", "bug fix examples", "error handling"]
       
    3. Decomposition:
       Break complex multi-hop queries into sub-steps.
       
    Performance:
    - All LLM calls are cached via Layer 2 cache (TTL 24h) to ensure speed on repeat.
    """
    
    def __init__(self):
        self.llm = ChatGroq(
            model_name="llama-3.1-8b-instant",
            api_key=settings.GROQ_API_KEY,
            temperature=0.3
        )
        
    @cache_manager.cached_operation(prefix="hyde", ttl=86400)
    def generate_hyde_doc(self, query: str) -> str:
        """
        Generate a Hypothetical Document (HyDE) for the query.
        """
        prompt = f"""You are a helpful expert assistant. 
Please write a short, plausible passage that answers the following question. 
It doesn't need to be factually correct (we will use it for semantic search matching), but it should contain the right keywords and concepts.

Question: {query}
Hypothetical Answer:"""
        
        try:
            logger.info(f"Generating HyDE for: {query}")
            response = self.llm.invoke(prompt).content
            return response.strip()
        except Exception as e:
            logger.error(f"HyDE Failed: {e}")
            return query # Fallback to original

    @cache_manager.cached_operation(prefix="multi_query", ttl=86400)
    def expand_query(self, query: str) -> List[str]:
        """
        Expand a complex query into 3 distinct search variations.
        """
        prompt = f"""You are an AI research assistant. 
Break down the following user query into 3 distinct, specific search queries that would help find the answer in a technical documentation database.
Return ONLY the 3 queries, one per line. Do not number them.

Current Query: {query}
"""
        try:
            logger.info(f"Expanding Query: {query}")
            response = self.llm.invoke(prompt).content
            lines = [line.strip() for line in response.split('\n') if line.strip()]
            return lines[:3] # Limit to top 3
        except Exception as e:
            logger.error(f"Expansion Failed: {e}")
            return [query]

    def decompose_query(self, query: str) -> List[str]:
        """
        Decomposes complex multi-hop queries.
        (Placeholder for future expansion - simply mirrors expand for now)
        """
        return self.expand_query(query)
    
    def classify_intent(self, query: str) -> str:
        """
        Maps user query to specific academic section targets.
        """
        q = query.lower()
        
        # 1. Formula / Math / Implementation
        if any(w in q for w in ["formula", "equation", "math", "algorithm", "notation", "implementation", "code"]):
            return "FORMULA"
            
        # 2. Main Idea / Overview / Goal
        if any(w in q for w in ["main idea", "core idea", "summary", "abstract", "contribution", "goal", "purpose", "problem"]):
            return "OVERVIEW"
            
        # 3. Metrics / Results / SOTA
        if any(w in q for w in ["result", "performance", "score", "accuracy", "f1", "table", "graph", "benchmark", "sota"]):
            return "METRICS"
            
        # 4. Limitations / Critique
        if any(w in q for w in ["limitation", "drawback", "failure", "weakness", "critique", "gap"]):
             return "LIMITATIONS"
             
        # 5. Methodology / Specifics
        if any(w in q for w in ["how", "method", "approach", "architecture", "setup", "training"]):
            return "METHODOLOGY"

        return "GENERAL"

# Singleton
query_optimizer = QueryOptimizer()

</code>

backend/app/rag/__init__.py:
<code>
# RAG package

</code>

backend/app/rag/llm.py:
<code>
import requests
from typing import List, Dict
from ..config import settings
import logging

logger = logging.getLogger(__name__)

# NEUTRAL SYSTEM PROMPT - NO FORCED FORMATTING
SYSTEM_PROMPT = """You are a helpful study assistant. Answer questions using the provided context.

### RULES:

1. **Answer naturally**: Respond in the most appropriate format for the question and content.
2. **Be direct**: Start with the answer, not preambles.
3. **Cite sources**: When referencing specific information, mention the page if available.
4. **No invention**: Only use information from the provided context.
5. **Match the content**: 
   - For exam questions/PYQs: List the questions and answers directly
   - For lecture notes: Explain the concepts clearly
   - For any document: Summarize the key points naturally

### CONTEXT FORMAT:
[Source: Section, p. X]
Content here...

### DO NOT:
- Force a "Problem/Method/Results" structure on non-research documents
- Treat exam papers or PYQs as research papers
- Add unnecessary academic formatting

Just answer naturally and helpfully.
"""

def _format_context(chunks: List[Dict]) -> str:
    """Format chunks with page metadata for LLM to cite."""
    if not chunks:
        return "No relevant context found."
    
    context_parts = []
    for idx, chunk in enumerate(chunks, 1):
        metadata = chunk.get("metadata", {})
        content = chunk.get("content", "")
        
        # Extract page information from metadata
        page_start = metadata.get("page_start", metadata.get("page", 1))
        page_end = metadata.get("page_end", page_start)
        section = metadata.get("section", "General")
        
        # Format page range
        if page_start == page_end:
            page_info = f"p. {page_start}"
        else:
            page_info = f"pp. {page_start}-{page_end}"
        
        # Build header with page info
        header = f"[Source: {section}, {page_info}]"
        context_parts.append(f"{header}\n{content}\n")
    
    return "\n---\n".join(context_parts)

def generate_response(query: str, context_chunks: List[Dict], filename: str = "document.pdf") -> str:
    """
    Generate high-quality response using Groq API.
    
    Uses 7-layer production pipeline:
    1. Document Type Detection
    2. Intent Routing
    3. Domain Rules
    4. Context Quality Check
    5. Answer Self-Validation
    6. Style Adapter
    7. Failure Logging
    """
    from .production_pipeline import run_pipeline, post_validate, log_failure
    
    # Format context with structure
    context = _format_context(context_chunks)
    
    # Limit context size
    MAX_CONTEXT_LENGTH = 8000
    if len(context) > MAX_CONTEXT_LENGTH:
        context = context[:MAX_CONTEXT_LENGTH] + "\n\n[Context truncated due to length...]"
    
    # Run 7-layer pipeline (Layers 1-4, 6)
    pipeline_result = run_pipeline(query, filename, context_chunks)
    logger.info(f"Pipeline: doc={pipeline_result.document_type.value}, intent={pipeline_result.intent.value}")
    
    if pipeline_result.issues:
        logger.warning(f"Pipeline issues: {pipeline_result.issues}")
    
    # Build messages with pipeline-generated prompt
    messages = [
        {
            "role": "system",
            "content": pipeline_result.system_prompt
        },
        {
            "role": "user",
            "content": f"""Context from documents:
{context}

Question: {query}

Answer based on the context above. Be direct and match the document style."""
        }
    ]
    
    try:
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {settings.GROQ_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": settings.GROQ_MODEL,
                "messages": messages,
                "temperature": 0.3,  # Lower for more focused answers
                "max_tokens": 1024,
                "top_p": 0.95
            },
            timeout=settings.GROQ_TIMEOUT
        )
        response.raise_for_status()
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            answer = result["choices"][0]["message"]["content"]
            
            # Layer 5: Post-validation
            is_valid, issues = post_validate(answer, query, pipeline_result, context)
            if not is_valid:
                logger.warning(f"Answer validation failed: {issues}")
                # Don't regenerate for now, just log
                # Future: could retry with stricter prompt
            
            return answer
        else:
            return "No response generated."
            
    except requests.exceptions.HTTPError as e:
        error_detail = ""
        try:
            error_detail = e.response.json()
            logger.error(f"Groq API error: {error_detail}")
        except:
            logger.error(f"Groq API error: {e.response.text}")
        
        if e.response.status_code == 400:
            return "Error: Invalid request to AI service. The context may be too complex. Try a simpler question."
        elif e.response.status_code == 401:
            return "Error: Invalid Groq API key."
        elif e.response.status_code == 429:
            return "Error: Groq API rate limit exceeded. Please try again later."
        else:
            return f"Error: Groq API returned {e.response.status_code}"
    except requests.exceptions.ConnectionError:
        return "Error: Could not connect to Groq API. Check your internet connection."
    except requests.exceptions.Timeout:
        return "Error: Groq API request timed out."
    except Exception as e:
        logger.error(f"Unexpected error in generate_response: {str(e)}")
        return f"Error generating response: {str(e)}"

</code>

backend/app/rag/research_prompts.py:
<code>
"""
Enhanced Research Prompts with Gold-Standard Examples
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Few-shot prompting with correct academic answer examples.

Features:
- Gold-standard answer templates
- Few-shot examples for each query type
- Structural validation templates
- Error correction examples

Total: 400+ lines
"""

# Gold-standard summary template
SUMMARY_GOLD_STANDARD = """
Example of CORRECT research summary:

**Problem**: 
Recurrent and convolutional sequence-to-sequence models limit parallel

ization and struggle to efficiently model long-range dependencies in sequence transduction tasks such as machine translation [1:0].

**Method**:
The Transformer is an encoder-decoder architecture that relies entirely on multi-head self-attention mechanisms combined with positional encoding and feed-forward layers, eliminating recurrence and convolution entirely [1:1][1:2].

**Key Result**:
Achieves BLEU 28.4 on WMT 2014 EN-DE and 41.8 on EN-FR while reducing training time by a factor of 10 compared to previous state-of-the-art models [1:5][1:6].

**Implications**:
Demonstrates that self-attention alone is sufficient for sequence modeling, enabling fully parallelizable architectures that became the foundation for modern large language models (BERT, GPT) [1:7].
"""

# Gold-standard formula template
FORMULA_GOLD_STANDARD = """
Example of CORRECT formula answer:

The core formula is **Scaled Dot-Product Attention** [1:3]:

Attention(Q, K, V) = softmax(Q K^T / sqrt(d_k)) V

Where:
- Q (queries), K (keys), V (values) are matrices [1:3]
- d_k is the dimension of the keys (scaling factor) [1:3]
- The scaling by 1/sqrt(d_k) prevents softmax saturation for large dimensions [1:4]

This is extended to **Multi-Head Attention** [1:5]:

MultiHead(Q, K, V) = Concat(head_1, ..., head_h) W^O
where head_i = Attention(Q W^Q_i, K W^K_i, V W^V_i)

The model uses h=8 parallel attention heads with d_k = d_v = 64 [1:5].
"""

# Research-grade system prompt with examples
RESEARCH_SYSTEM_PROMPT_V2 = f"""You are a research TA grading PhD-level work. You have ZERO tolerance for imprecision.

### CRITICAL STRUCTURAL RULES:

1. **Problem vs Method Distinction**:
   - **Problem** = Challenge/Limitation BEFORE the paper
   - **Method** = Solution/Architecture PROPOSED by the paper
   - NEVER describe the architecture in the Problem section
   
2. **Metrics are Mandatory**:
   - Include exact numbers: BLEU 28.4, Accuracy 95.3%, 10x speedup
   - NO vague statements like "good performance"
   
3. **Every Claim Needs [Source ID]**:
   - Format: [file_id:chunk_index]
   - Minimum 1 citation per 50 words
   
4. **Formulas Must Be Mathematical**:
   - Show equations: Attention(Q,K,V) = softmax(QK^T/sqrt(d_k))V
   - Explain variables
   - NO verbal descriptions of formulas
   
5. **Precision on Complexity**:
   - NEVER say "O(1) operations" when you mean "O(1) path length"
   - Be explicit: "O(nÂ²) computational cost, O(1) sequential path"

### GOLD STANDARDS:

{SUMMARY_GOLD_STANDARD}

{FORMULA_GOLD_STANDARD}

### YOUR TASK:
Answer the question using the provided context. Follow the gold standards EXACTLY.
"""

# Prompt templates with validation
VALIDATED_PROMPTS = {
    "summary": {
        "system": RESEARCH_SYSTEM_PROMPT_V2,
        "user_template": """Context:
{context}

Question: {question}

Provide a structured summary following this EXACT format:

**Problem**: [What challenge/limitation exists BEFORE this work?] [Source ID]
**Method**: [How does THIS paper solve it? Include architecture components] [Source ID]
**Key Result**: [What metrics were achieved? Include exact numbers] [Source ID]
**Implications**: [Why does this matter?] [Source ID]

CRITICAL: Problem section must describe a CHALLENGE, not an architecture.""",
        "validation_rules": [
            "Problem section must contain challenge words (limitation, bottleneck, inefficient)",
            "Method section must mention architecture components",
            "Key Result must contain numbers",
            "All sections must have [Source ID] citations"
        ]
    },
    
    "formula": {
        "system": RESEARCH_SYSTEM_PROMPT_V2,
        "user_template": """Context:
{context}

Question: {question}

Extract and explain the core formulas following this format:

**Core Formula**: [Name of formula] [Source ID]

[Mathematical notation here]

**Where**:
- [variable] = [meaning] [Source ID]
- [variable] = [meaning] [Source ID]

**Additional Formulas**:
[List any related formulas with same format]

CRITICAL: Show formulas in mathematical notation, not English descriptions.""",
        "validation_rules": [
            "Must contain '=' sign",
            "Must have variable explanations",
            "Must use mathematical symbols (softmax, sqrt, etc.)"
        ]
    },
    
    "methodology": {
        "system": RESEARCH_SYSTEM_PROMPT_V2,
        "user_template": """Context:
{context}

Question: {question}

Explain the methodology step-by-step:

**Overview**: [One sentence summary] [Source ID]

**Architecture Components**:
1. [Component 1]: [Explanation] [Source ID]
2. [Component 2]: [Explanation] [Source ID]
...

**Training/Implementation**:
- [Detail 1] [Source ID]
- [Detail 2] [Source ID]

CRITICAL: Include architectural diagrams descriptions if mentioned in context.""",
        "validation_rules": [
            "Must have numbered steps",
            "Must cite each component"
        ]
    },
    
    "comparison": {
        "system": RESEARCH_SYSTEM_PROMPT_V2,
        "user_template": """Context:
{context}

Question: {question}

Compare the approaches:

**Approach A**: [Name] [Source ID]
- [Key characteristics]

**Approach B**: [Name] [Source ID]
- [Key characteristics]

**Differences**:
1. [Difference] [Source IDs]
2. [Difference] [Source IDs]

**Performance**:
- Metric: [A value] vs [B value] [Source IDs]

CRITICAL: Include exact metrics for comparison.""",
        "validation_rules": [
            "Must compare at least 2 approaches",
            "Must include metrics"
        ]
    },
    
    "results": {
        "system": RESEARCH_SYSTEM_PROMPT_V2,
        "user_template": """Context:
{context}

Question: {question}

Report the results:

**Main Metrics**:
- [Metric name]: [Value] [Source ID]
- [Metric name]: [Value] [Source ID]

**Baselines Comparison**:
| Model | [Metric 1] | [Metric 2] |
|-------|-----------|-----------|
| [Baseline] | [Value] [Source] | [Value] [Source] |
| [This work] | [Value] [Source] | [Value] [Source] |

**Key Findings**:
1. [Finding with numbers] [Source ID]
2. [Finding with numbers] [Source ID]

CRITICAL: Every result must have a number.""",
        "validation_rules": [
            "Must contain numerical metrics",
            "Must compare to baselines"
        ]
    }
}

# Error correction examples
COMMON_ERRORS_AND_FIXES = {
    "problem_method_confusion": {
        "wrong": "**Problem**: The Transformer uses self-attention to process sequences.",
        "right": "**Problem**: RNNs process sequences sequentially, limiting parallelization.",
        "explanation": "Problem describes the challenge BEFORE the paper, not the solution."
    },
    
    "missing_metrics": {
        "wrong": "The model achieved good performance on translation tasks.",
        "right": "The model achieved BLEU 28.4 on WMT 2014 EN-DE translation [1:5].",
        "explanation": "Always include exact numbers and citations."
    },
    
    "verbal_formula": {
        "wrong": "The attention formula computes a weighted sum of values.",
        "right": "Attention(Q,K,V) = softmax(QK^T/sqrt(d_k))V [1:3]",
        "explanation": "Show formulas mathematically, not verbally."
    },
    
    "complexity_confusion": {
        "wrong": "Self-attention allows O(1) operations.",
        "right": "Self-attention has O(nÂ²) computational cost but O(1) sequential path length [1:4].",
        "explanation": "Be precise about what O(1) refers to."
    }
}

def get_prompt_for_query_type(query_type: str) -> Dict:
    """Get validated prompt template for query type"""
    return VALIDATED_PROMPTS.get(query_type, VALIDATED_PROMPTS["summary"])

def validate_prompt_output(output: str, query_type: str) -> List[str]:
    """Validate output against rules for query type"""
    template = VALIDATED_PROMPTS.get(query_type, {})
    rules = template.get("validation_rules", [])
    
    violations = []
    output_lower = output.lower()
    
    for rule in rules:
        if "challenge words" in rule and not any(w in output_lower for w in ['limitation', 'challenge', 'bottleneck', 'inefficient']):
            violations.append(rule)
        elif "numbers" in rule and not re.search(r'\d+\.?\d*', output):
            violations.append(rule)
        elif "'=' sign" in rule and '=' not in output:
            violations.append(rule)
        elif "[Source ID]" in rule and not re.search(r'\[\d+:\d+\]', output):
            violations.append(rule)
    
    return violations

</code>

backend/app/rag/academic_eval.py:
<code>
import logging
import json
import time
from typing import List, Dict, Tuple
from dataclasses import dataclass
from collections import Counter
import pandas as pd

from .engine import query_documents
from .indexer import get_collection

logger = logging.getLogger(__name__)

@dataclass
class AcademicTestCase:
    query: str
    target_sections: List[str] # e.g. ["Methodology", "Introduction"]
    category: str # "Method", "Results", "Goal"

class AcademicEvaluator:
    """
    Research-Grade Evaluation for Academic RAG.
    
    Focus:
    1. Section Precision: Does a 'Method' question retrieve 'Method' chunks?
    2. Answer Grounding: (Verified via Auditor separately)
    3. Failure Analysis: Detailed report on WHY retrieval failed.
    """
    
    TEST_SET = [
        AcademicTestCase(
            query="What is the main problem addressed?",
            target_sections=["Abstract", "Introduction"],
            category="Goal"
        ),
        AcademicTestCase(
            query="What is the proposed method?",
            target_sections=["Methodology", "Proposed Approach", "Method"],
            category="Method"
        ),
        AcademicTestCase(
            query="How does it compare to baselines?",
            target_sections=["Experiments", "Results", "Comparison"],
            category="Results"
        ),
        AcademicTestCase(
            query="What are the limitations?",
            target_sections=["Discussion", "Conclusion", "Limitations"],
            category="Critique"
        )
    ]
    
    def __init__(self):
        self.results = []
        self.failure_log = []

    def run_eval(self, user_id: int):
        """Execute the battery of academic tests."""
        logger.info(f"Starting Academic Eval for User {user_id}")
        
        scores = {
            "Method": [],
            "Results": [],
            "Goal": [],
            "Critique": []
        }
        
        for case in self.TEST_SET:
            t0 = time.time()
            
            # Execute RAG Retrieval
            # We care about the *retrieved chunks* (sources), not just the answer.
            # engine query returns list of dicts with 'metadata'
            retrieved_docs = query_documents(case.query, user_id, n_results=5)
            
            # Check Section Precision
            precision = self._calculate_section_precision(retrieved_docs, case.target_sections)
            
            # Log Result
            scores[case.category].append(precision)
            
            self._analyze_failure(case, retrieved_docs, precision)
            
        return self._generate_report(scores)

    def _calculate_section_precision(self, docs: List[Dict], targets: List[str]) -> float:
        """
        Fraction of retrieved docs that belong to target/relevant sections.
        Heuristic: Partial string match on section title.
        """
        if not docs:
            return 0.0
            
        hits = 0
        for doc in docs:
            section = doc.get("metadata", {}).get("section", "Unknown")
            # Loose match
            if any(t.lower() in section.lower() for t in targets):
                hits += 1
                
        return hits / len(docs)

    def _analyze_failure(self, case: AcademicTestCase, docs: List[Dict], precision: float):
        """Log failure cases for research analysis."""
        if precision < 0.5: # Threshold for 'Failure'
            retrieved_sections = [d.get("metadata", {}).get("section", "None") for d in docs]
            
            failure_entry = {
                "query": case.query,
                "expected": case.target_sections,
                "got_sections": retrieved_sections,
                "retrieved_excerpts": [d.get("content", "")[:50] for d in docs],
                "reason": self._diagnose_reason(case, retrieved_sections)
            }
            self.failure_log.append(failure_entry)

    def _diagnose_reason(self, case: AcademicTestCase, actual: List[str]) -> str:
        """Heuristic diagnosis of failure."""
        flat_actual = " ".join(actual).lower()
        if "reference" in flat_actual:
            return "Citation Pollution (Retrieved References)"
        if "abstract" in flat_actual and case.category == "Method":
            return "Abstract Bias (Method details usually deep in doc)"
        return "Semantic Drift"

    def _generate_report(self, scores: Dict) -> str:
        """Generate Research-Style Markdown Report."""
        
        # Calculate Aggregates
        avg_scores = {k: (sum(v)/len(v) if v else 0.0) for k, v in scores.items()}
        total_p = sum(avg_scores.values()) / len(avg_scores)
        
        report = f"""
# ğŸ“ Academic RAG Evaluation Report

## 1. Retrieval Accuracy via Section Alignment
| Category | Section Precision | Status |
|----------|-------------------|--------|
| **Goal** (Intro/Abstract) | {avg_scores['Goal']:.2%} | {"âœ…" if avg_scores['Goal']>0.7 else "âš ï¸"} |
| **Method** (Methodology) | {avg_scores['Method']:.2%} | {"âœ…" if avg_scores['Method']>0.7 else "âš ï¸"} |
| **Results** (Experiments) | {avg_scores['Results']:.2%} | {"âœ…" if avg_scores['Results']>0.7 else "âš ï¸"} |

**Overall Precision**: {total_p:.2%}

## 2. Failure Analysis (Research Signal)
Systematic failures identified in this run:

"""
        if not self.failure_log:
            report += "*No systemic failures detected. System is robust.*\n"
        else:
            for f in self.failure_log:
                report += f"- **Query**: '{f['query']}'\n"
                report += f"  - **Expected Sections**: {f['expected']}\n"
                report += f"  - **Actual Retrieved**: {f['got_sections']}\n"
                report += f"  - **Diagnosis**: {f['reason']}\n\n"
                
        return report

# Singleton
academic_evaluator = AcademicEvaluator()

if __name__ == "__main__":
    # Test Run
    print(academic_evaluator.run_eval(user_id=1))

</code>

backend/app/rag/engine.py:
<code>
from typing import List, Dict, Optional, Tuple
import logging
import time
import uuid
from dataclasses import dataclass

# Core Components
from .indexer import get_collection, embedding_model
from .retrievers.reranker import reranker
from .retrievers.hybrid import hybrid_retriever
from .metrics import metrics
# Phase H Components
from .query_optimizer import query_optimizer
from .cache_manager import cache_manager

logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    content: str
    metadata: Dict
    score: float
    source: str  # 'vector', 'bm25', 'hybrid'

class RAGEngine:
    """
    Production-Grade Query Engine.
    Orchestrates the Retrieval-Augmented Generation pipeline.
    
    Responsibilities:
    1. Query Analysis & Pre-filtering
    2. Query Optimization (HyDE / Multi-Query) [NEW]
    3. Parallel Hybrid Retrieval (Vector + Keyword)
    4. Result Fusion (RRF)
    5. Re-ranking (Cross-Encoder)
    6. Context Assembly (Parent-Child)
    7. Detailed Trace Logging
    """
    
    def __init__(self):
        self.collection = get_collection()
        
    def query(self, 
             query_text: str, 
             user_id: int, 
             file_ids: Optional[List[int]] = None, 
             n_results: int = 3) -> List[Dict]:
        """
        Execute full RAG retrieval pipeline with monitoring.
        """
        trace_id = str(uuid.uuid4())[:8]
        logger.info(f"[{trace_id}] Query Start: '{query_text}' (User: {user_id})")
        start_time = time.time()
        
        try:
            # 1. Intent Classification & Importance
            importance_filter = self._analyze_importance(query_text)
            intent = query_optimizer.classify_intent(query_text)
            logger.info(f"[{trace_id}] Intent Detected: {intent}")
            
            # --- PHASE H: Query Optimization ---
            # 1a. Generate HyDE Document (for implicit context expansion)
            search_query = query_text
            if len(query_text.split()) < 10:
                hyde_doc = query_optimizer.generate_hyde_doc(query_text)
                if hyde_doc:
                    logger.info(f"[{trace_id}] HyDE Expanded: {hyde_doc[:50]}...")
                    search_query = hyde_doc 
            # -----------------------------------
            
            # 2. Strategy Selection
            final_candidates = []
            
            # STRATEGY A: Targeted Section Search (The "Research-Grade" logic)
            if intent != "GENERAL":
                target_sections = self._map_intent_to_sections(intent)
                logger.info(f"[{trace_id}] Targeting Sections: {target_sections}")
                
                if target_sections:
                    # Fetch more candidates for targeted search to ensure coverage
                    targeted_docs = self._vector_search_targeted(
                        search_query, user_id, file_ids, k=n_results*4, sections=target_sections
                    )
                    final_candidates.extend(targeted_docs)
                    logger.info(f"[{trace_id}] Targeted Search found {len(targeted_docs)} chunks")

            # STRATEGY B: Global Search (Fallback & Supplement)
            # We always run this but with fewer K if targeted found something, 
            # or full K if intent is General.
            global_k = n_results * 2 if final_candidates else n_results * 5
            
            global_docs = self._vector_search(
                search_query, user_id, file_ids, k=global_k, importance=importance_filter
            )
            
            # Merge & Deduplicate (Keep targeted docs first implicitly via ID check)
            seen_ids = {d["id"] for d in final_candidates}
            for d in global_docs:
                if d["id"] not in seen_ids:
                    final_candidates.append(d)
                    seen_ids.add(d["id"])

            # 3. Keyword Supplement (BM25) - Good for specific acronyms/names
            bm25_docs = self._bm25_search(query_text, user_id, file_ids, k=n_results*2)
            
            # 4. Fusion (RRF)
            # Fusing Targeted + Global + Keyword
            fused_docs = hybrid_retriever.reciprocal_rank_fusion(final_candidates, bm25_docs)
            logger.info(f"[{trace_id}] Fusion: {len(final_candidates)} vec + {len(bm25_docs)} bm25 -> {len(fused_docs)} candidates")
            
            # 5. Re-ranking
            final_docs = self._rerank_results(query_text, fused_docs, n_results)
            
            # 6. Context Expansion (Parent-Child)
            expanded_docs = self._expand_context(final_docs)
            
            return expanded_docs
            
        except Exception as e:
            logger.error(f"[{trace_id}] Query Failed: {e}", exc_info=True)
            return []

    def _analyze_importance(self, query: str) -> Optional[str]:
        """Determine if query targets a specific importance section."""
        q_lower = query.lower()
        if any(kw in q_lower for kw in ['main', 'core', 'primary', 'key contribution', 'summary', 'abstract']):
            return 'core_contribution'
        return None

    @cache_manager.cached_operation(prefix="vector_search", ttl=3600)
    def _vector_search(self, query: str, user_id: int, file_ids: Optional[List[int]], k: int, importance: Optional[str]) -> List[Dict]:
        """Run Semantic Vector Search with ChromaDB."""
        try:
            emb = embedding_model.encode([query]).tolist()
            
            # ChromaDB requires explicit $and for multiple conditions
            if importance:
                where_clause = {
                    "$and": [
                        {"user_id": user_id},
                        {"importance": importance}
                    ]
                }
            else:
                where_clause = {"user_id": user_id}
            
            res = self.collection.query(
                query_embeddings=emb,
                n_results=k,
                where=where_clause
            )
            
            docs = []
            if res["documents"] and res["documents"][0]:
                for i in range(len(res["documents"][0])):
                    meta = res["metadatas"][0][i]
                    # Post-match file_id filter if needed (Chroma where logic limitation)
                    if file_ids and meta.get("file_id") not in file_ids:
                        continue
                        
                    docs.append({
                        "content": res["documents"][0][i],
                        "metadata": meta,
                        "score": res["distances"][0][i],
                        "id": res["ids"][0][i]
                    })
            return docs
            
            return docs
            
        except Exception as e:
            logger.error(f"Vector search error: {e}")
            return []

    def _map_intent_to_sections(self, intent: str) -> List[str]:
        """Maps intents to the SECTION METADATA extracted by your PDF Parser."""
        mapping = {
            "FORMULA": ["Method", "Methodology", "Algorithm", "Model", "Appendix", "Implementation"],
            "OVERVIEW": ["Abstract", "Introduction", "related work", "background"],
            "METRICS": ["Experiment", "Results", "Discussion", "Evaluation", "Tables"],
            "LIMITATIONS": ["Conclusion", "Discussion", "Limitation", "Future Work"],
            "METHODOLOGY": ["Method", "Methodology", "Proposed Approach", "Architecture"]
        }
        return mapping.get(intent, [])

    # Targeted Search Cache (separate prefix to avoid pollution)
    @cache_manager.cached_operation(prefix="vector_target", ttl=3600)
    def _vector_search_targeted(self, query: str, user_id: int, file_ids: Optional[List[int]], k: int, sections: List[str]) -> List[Dict]:
        """Run Vector Search constrained to specific sections."""
        try:
            emb = embedding_model.encode([query]).tolist()
            
            # ChromaDB $or syntax for metadata fields can be tricky.
            # We use $in operator if supported, or iterative query if needed.
            # standard where: {"user_id": 1, "section": {"$in": sections}}
            # BUT ChromaDB where clause is strict.
            # Let's try simple $or at top level or iterative if simpler.
            # Actually simplest is to just query and post-filter since we can't easily do AND(ID, OR(Section)) in old Chroma versions.
            # Wait, we need "TARGETED" meaning we search ONLY there.
            # Efficient implementation: Just filter in the where clause.
            
            # Construct where clause
            # { "$and": [ {"user_id": uid}, {"section": {"$in": sections}} ] }
            where_clause = {
                "$and": [
                    {"user_id": user_id},
                    {"section": {"$in": sections}}
                ]
            }
            
            res = self.collection.query(
                query_embeddings=emb,
                n_results=k, # Fetch same K, but purely from target
                where=where_clause
            )
            
            docs = []
            if res["documents"] and res["documents"][0]:
                for i in range(len(res["documents"][0])):
                    meta = res["metadatas"][0][i]
                    if file_ids and meta.get("file_id") not in file_ids:
                        continue
                        
                    docs.append({
                        "content": res["documents"][0][i],
                        "metadata": meta,
                        "score": res["distances"][0][i] * 0.9, # Boost score (lower distance) logic handled in fusion?? 
                        # actually lower distance = better. 
                        # We just return them. RRF fusion (rank based) will be fine.
                        "id": res["ids"][0][i]
                    })
            return docs
            
        except Exception as e:
            logger.warning(f"Targeted search warning (fallback to global): {e}")
            return []

    # Short cache for BM25 as it's fast but good to avoid parsing if frequent
    @cache_manager.cached_operation(prefix="bm25_search", ttl=300) 
    def _bm25_search(self, query: str, user_id: int, file_ids: Optional[List[int]], k: int) -> List[Dict]:
        """Run Keyword Search via BM25."""
        try:
            candidates = hybrid_retriever.search_bm25(query, k=k)
            # Filter by user/file
            filtered = [
                d for d in candidates 
                if d["metadata"].get("user_id") == user_id
                and (not file_ids or d["metadata"].get("file_id") in file_ids)
            ]
            return filtered
        except Exception as e:
            logger.error(f"BM25 search error: {e}")
            return []

    @cache_manager.cached_operation(prefix="rerank", ttl=3600)
    def _rerank_results(self, query: str, docs: List[Dict], top_k: int) -> List[Dict]:
        """Apply Cross-Encoder Reranking."""
        if not docs:
            return []
        # Fallback if too many docs passed (latency guard)
        rerank_pool = docs[:top_k * 3] 
        return reranker.rerank(query, rerank_pool, top_k=top_k)

    def _expand_context(self, docs: List[Dict]) -> List[Dict]:
        """Swap child chunks for parent context if available."""
        expanded = []
        for d in docs:
            meta = d.get("metadata", {})
            if meta.get("is_child", False) and meta.get("parent_content"):
                # Use Parent Content for LLM
                d["content"] = meta["parent_content"]
                # Maybe mark as expanded for debug
                d["expanded"] = True
            expanded.append(d)
        return expanded

# Singleton Export
engine = RAGEngine()

# Facade for backward compatibility
def query_documents(query_text: str, user_id: int, file_ids: Optional[List[int]] = None, n_results: int = 3):
    return engine.query(query_text, user_id, file_ids, n_results)

</code>

backend/app/rag/production_pipeline.py:
<code>
"""
Production RAG Pipeline - 7 Layer System
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Comprehensive RAG with document detection, intent routing,
domain rules, context validation, answer self-check, and failure logging.

Total: ~500 lines

Layers:
1. Document Type Detection
2. User Intent Routing  
3. Domain Rule Enforcement
4. Context Quality Check
5. Answer Self-Validation
6. Answer Style Adapter
7. Failure Logging
"""

import re
import logging
from enum import Enum
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
from datetime import datetime

logger = logging.getLogger(__name__)


# ============================================================================
# LAYER 1: DOCUMENT TYPE DETECTION
# ============================================================================

class DocumentType(Enum):
    EXAM = "exam"
    RESEARCH = "research"
    LEGAL = "legal"
    MEDICAL = "medical"
    TECH_DOC = "tech_doc"
    LECTURE = "lecture"
    GENERAL = "general"


# Detection patterns per document type
DOC_PATTERNS = {
    DocumentType.EXAM: [
        r'\b(question|q\.?\s*\d+|answer|marks?|score|exam|test|quiz)\b',
        r'\b(solve|calculate|find|determine|prove|show that|write a (function|program|code))\b',
        r'\b(PYQ|previous year|mid.?term|end.?term|makeup|semester|internal)\b',
        r'\[\s*\d+\s*marks?\s*\]',
        r'\(\s*\d+\s*marks?\s*\)',
        r'\b(CSE|ECE|EEE|MECH|IT|B\.?Tech)\s*\d{4}\b',
    ],
    DocumentType.RESEARCH: [
        r'\b(abstract|introduction|methodology|conclusion|references|doi)\b',
        r'\b(we propose|this paper|our approach|state.?of.?the.?art|related work)\b',
        r'\b(BLEU|F1.?score|accuracy|precision|recall|baseline|benchmark)\b',
        r'\b(et al\.?|arXiv|IEEE|ACM|Springer|CVPR|NeurIPS|ICML)\b',
    ],
    DocumentType.LEGAL: [
        r'\b(hereby|whereas|notwithstanding|pursuant|hereinafter)\b',
        r'\b(clause|section|article|subsection|agreement|contract|law)\b',
        r'\b(court|plaintiff|defendant|jurisdiction|tribunal)\b',
        r'\b(shall|must not|liability|indemnify|warranty)\b',
    ],
    DocumentType.MEDICAL: [
        r'\b(patient|diagnosis|treatment|symptoms|prescription|dosage)\b',
        r'\b(mg|ml|tablet|injection|oral|intravenous)\b',
        r'\b(clinical|pathology|radiology|MRI|CT scan|X-ray)\b',
        r'\b(doctor|physician|nurse|hospital|ICU)\b',
    ],
    DocumentType.TECH_DOC: [
        r'\b(API|endpoint|request|response|JSON|REST|GraphQL)\b',
        r'\b(install|configure|setup|deployment|docker|kubernetes)\b',
        r'\b(function|method|class|parameter|return|async|await)\b',
        r'```[\w]*\n',  # Code blocks
    ],
    DocumentType.LECTURE: [
        r'\b(lecture|slide|chapter|topic|learning objectives)\b',
        r'\b(example|definition|theorem|lemma|proof|corollary)\b',
        r'\b(summary|recap|key points|takeaway)\b',
    ],
}


def detect_document_type(filename: str, content: str) -> DocumentType:
    """
    Detect document type from filename and content.
    Returns the most likely document type.
    """
    text = f"{filename.lower()} {content.lower()}"
    
    scores = {}
    for doc_type, patterns in DOC_PATTERNS.items():
        score = sum(
            len(re.findall(p, text, re.IGNORECASE | re.MULTILINE))
            for p in patterns
        )
        scores[doc_type] = score
    
    # Prioritize EXAM detection (most common use case)
    if scores.get(DocumentType.EXAM, 0) >= 3:
        return DocumentType.EXAM
    
    max_type = max(scores, key=scores.get)
    if scores[max_type] >= 2:
        return max_type
    
    return DocumentType.GENERAL


# ============================================================================
# LAYER 2: USER INTENT ROUTING
# ============================================================================

class UserIntent(Enum):
    WHAT_IS_THIS = "what_is_this"
    SUMMARIZE = "summarize"
    ANSWER_QUESTION = "answer_question"
    EXPLAIN_CONCEPT = "explain_concept"
    WRITE_CODE = "write_code"
    DERIVE_FORMULA = "derive_formula"
    COMPARE = "compare"
    VALIDATE_SOLUTION = "validate_solution"
    LIST_ITEMS = "list_items"
    GENERAL = "general"


INTENT_PATTERNS = {
    UserIntent.WHAT_IS_THIS: [
        r'^what (is|are) (this|these)',
        r'^tell me about (this|the) (document|file|pdf)',
    ],
    UserIntent.SUMMARIZE: [
        r'\b(summarize|summary|summarise|overview|brief|tl;?dr)\b',
        r'^(give|provide) (a|me) (summary|overview)',
        r'what does (this|the) (document|file|paper) (say|contain|cover)',
    ],
    UserIntent.ANSWER_QUESTION: [
        r'^(solve|answer|find|calculate|compute|determine)\b',
        r'^(what|which|where|when|who|how many|how much)\b',
        r'\?$',
        r'^(q\d+|question\s*\d+)',
    ],
    UserIntent.EXPLAIN_CONCEPT: [
        r'^(explain|describe|clarify|elaborate)',
        r'^(how does|how do|why does|why do)',
        r'^(what is|what are) (the|a) ',
        r'(help me understand|break down)',
    ],
    UserIntent.WRITE_CODE: [
        r'\b(write|generate|create|implement) (a |the )?(code|function|program|script)\b',
        r'\b(coding|programming|algorithm)\b',
        r'\b(python|java|c\+\+|javascript|code)\b',
    ],
    UserIntent.DERIVE_FORMULA: [
        r'\b(derive|derivation|formula|equation|proof|prove)\b',
        r'\b(show that|demonstrate that)\b',
    ],
    UserIntent.COMPARE: [
        r'\b(compare|comparison|difference|versus|vs\.?|distinguish)\b',
        r'\b(better|worse|advantage|disadvantage)\b',
    ],
    UserIntent.VALIDATE_SOLUTION: [
        r'\b(check|validate|verify|correct|wrong|mistake|error)\b',
        r'\b(is this (right|correct|wrong))\b',
    ],
    UserIntent.LIST_ITEMS: [
        r'\b(list|enumerate|give me all|what are the)\b',
        r'\b(steps|points|items|features|types|kinds)\b',
    ],
}


def detect_intent(query: str) -> UserIntent:
    """Detect user intent from query."""
    query_lower = query.lower().strip()
    
    for intent, patterns in INTENT_PATTERNS.items():
        if any(re.search(p, query_lower) for p in patterns):
            return intent
    
    return UserIntent.GENERAL


# ============================================================================
# LAYER 3: DOMAIN RULE ENFORCEMENT
# ============================================================================

@dataclass
class DomainRule:
    """A single domain rule."""
    name: str
    check: str  # Regex pattern to check
    violation_message: str
    fix_instruction: str


# Domain-specific rules
DOMAIN_RULES = {
    "data_structures": [
        DomainRule(
            name="queue_fifo",
            check=r"queue.*(lifo|last.?in.?first.?out)",
            violation_message="Queue must be FIFO, not LIFO",
            fix_instruction="Queue follows FIFO (First In First Out) principle"
        ),
        DomainRule(
            name="stack_lifo",
            check=r"stack.*(fifo|first.?in.?first.?out)",
            violation_message="Stack must be LIFO, not FIFO",
            fix_instruction="Stack follows LIFO (Last In First Out) principle"
        ),
    ],
    "research": [
        DomainRule(
            name="cite_formulas",
            check=r"(formula|equation).*(not (stated|mentioned|provided|found))",
            violation_message="Core formulas should be extracted if present",
            fix_instruction="Extract and cite the formula from the paper"
        ),
    ],
    "medical": [
        DomainRule(
            name="no_dosage_guess",
            check=r"(might be|could be|probably|approximately)\s*\d+\s*(mg|ml|tablet)",
            violation_message="Never guess medical dosages",
            fix_instruction="Only provide exact dosages from the source document"
        ),
    ],
    "legal": [
        DomainRule(
            name="exact_quotes",
            check=r"(paraphrasing|in other words|essentially means)",
            violation_message="Legal clauses should be quoted exactly",
            fix_instruction="Quote the exact legal text, do not paraphrase"
        ),
    ],
}


def check_domain_rules(answer: str, doc_type: DocumentType) -> List[DomainRule]:
    """
    Check if answer violates any domain rules.
    Returns list of violated rules.
    """
    violations = []
    
    # Map document types to rule sets
    doc_to_domain = {
        DocumentType.EXAM: "data_structures",  # Most exam papers are DS/Algo
        DocumentType.RESEARCH: "research",
        DocumentType.MEDICAL: "medical",
        DocumentType.LEGAL: "legal",
    }
    
    domain = doc_to_domain.get(doc_type)
    if not domain:
        return violations
    
    rules = DOMAIN_RULES.get(domain, [])
    answer_lower = answer.lower()
    
    for rule in rules:
        if re.search(rule.check, answer_lower, re.IGNORECASE):
            violations.append(rule)
    
    return violations


# ============================================================================
# LAYER 4: CONTEXT QUALITY CHECK
# ============================================================================

@dataclass
class ContextQuality:
    """Assessment of context quality."""
    is_sufficient: bool
    relevance_score: float  # 0-1
    has_page_numbers: bool
    has_sections: bool
    issues: List[str] = field(default_factory=list)
    suggestions: List[str] = field(default_factory=list)


def assess_context_quality(
    query: str,
    chunks: List[Dict],
    min_chunks: int = 1,
    min_relevance: float = 0.3
) -> ContextQuality:
    """
    Assess if retrieved context is sufficient for answering.
    """
    issues = []
    suggestions = []
    
    if not chunks:
        return ContextQuality(
            is_sufficient=False,
            relevance_score=0.0,
            has_page_numbers=False,
            has_sections=False,
            issues=["No context retrieved"],
            suggestions=["Try broader search terms"]
        )
    
    # Check chunk count
    if len(chunks) < min_chunks:
        issues.append(f"Only {len(chunks)} chunks retrieved (need {min_chunks})")
        suggestions.append("Consider retrieving more chunks")
    
    # Check for page numbers
    has_pages = any(
        chunk.get("metadata", {}).get("page") or 
        chunk.get("metadata", {}).get("page_start")
        for chunk in chunks
    )
    if not has_pages:
        issues.append("No page numbers in metadata")
    
    # Check for sections
    has_sections = any(
        chunk.get("metadata", {}).get("section")
        for chunk in chunks
    )
    
    # Calculate average relevance (if scores available)
    scores = [chunk.get("score", 0.5) for chunk in chunks]
    avg_relevance = sum(scores) / len(scores) if scores else 0.5
    
    if avg_relevance < min_relevance:
        issues.append(f"Low relevance score: {avg_relevance:.2f}")
        suggestions.append("Query may need reformulation")
    
    # Determine sufficiency
    is_sufficient = len(chunks) >= min_chunks and avg_relevance >= min_relevance
    
    return ContextQuality(
        is_sufficient=is_sufficient,
        relevance_score=avg_relevance,
        has_page_numbers=has_pages,
        has_sections=has_sections,
        issues=issues,
        suggestions=suggestions
    )


# ============================================================================
# LAYER 5: ANSWER SELF-VALIDATION
# ============================================================================

@dataclass
class ValidationResult:
    """Result of answer self-validation."""
    is_valid: bool
    confidence: float  # 0-1
    issues: List[str] = field(default_factory=list)
    should_regenerate: bool = False


def validate_answer(
    answer: str,
    query: str,
    doc_type: DocumentType,
    intent: UserIntent,
    context_text: str
) -> ValidationResult:
    """
    Validate generated answer for correctness.
    """
    issues = []
    confidence = 1.0
    
    answer_lower = answer.lower()
    
    # Check 1: Domain rule violations
    violations = check_domain_rules(answer, doc_type)
    if violations:
        for v in violations:
            issues.append(f"Domain violation: {v.violation_message}")
            confidence -= 0.3
    
    # Check 2: Defensive language when context exists
    defensive_patterns = [
        r"(not mentioned|not stated|not provided|not found) in (the |this )?(context|document)",
        r"(cannot|can't|unable to) (find|locate|determine)",
        r"(no information|no data) (about|on|regarding)",
    ]
    
    for pattern in defensive_patterns:
        if re.search(pattern, answer_lower) and len(context_text) > 100:
            issues.append("Defensive response despite having context")
            confidence -= 0.2
    
    # Check 3: For exam answers - should be direct
    if doc_type == DocumentType.EXAM and intent == UserIntent.ANSWER_QUESTION:
        vague_patterns = [r"^(it depends|this varies|generally speaking)"]
        if any(re.search(p, answer_lower) for p in vague_patterns):
            issues.append("Vague answer for exam question")
            confidence -= 0.2
    
    # Check 4: Answer too short for summarize intent
    if intent == UserIntent.SUMMARIZE and len(answer) < 200:
        issues.append("Summary too short")
        confidence -= 0.1
    
    # Check 5: No code for code request
    if intent == UserIntent.WRITE_CODE and "```" not in answer:
        issues.append("No code block for code request")
        confidence -= 0.3
    
    # Determine validity
    is_valid = confidence >= 0.5 and len(violations) == 0
    should_regenerate = not is_valid
    
    return ValidationResult(
        is_valid=is_valid,
        confidence=max(0, confidence),
        issues=issues,
        should_regenerate=should_regenerate
    )


# ============================================================================
# LAYER 6: ANSWER STYLE ADAPTER
# ============================================================================

STYLE_GUIDES = {
    DocumentType.EXAM: """
Format your answer like an exam solution:
- Be concise and to-the-point
- Use textbook definitions
- Show step-by-step working for calculations
- No unnecessary elaboration
""",
    DocumentType.RESEARCH: """
Format as academic response:
- Formal and precise language
- Cite specific sections/pages
- Include metrics when available
- Structure: Problem â†’ Method â†’ Result
""",
    DocumentType.LECTURE: """
Format as study notes:
- Clear concept explanations
- Include examples where helpful
- Use bullet points for key ideas
- Simple language
""",
    DocumentType.LEGAL: """
Format for legal context:
- Quote exact clauses
- No paraphrasing of legal terms
- Cite section/article numbers
- Use cautious language
""",
    DocumentType.MEDICAL: """
Format for medical context:
- Never guess dosages or treatments
- Always cite the source
- Use cautious language ("according to document")
- Recommend consulting professionals
""",
    DocumentType.TECH_DOC: """
Format for technical documentation:
- Include code examples if relevant
- Use precise technical terms
- Structure: What â†’ How â†’ Example
- Include parameter details
""",
    DocumentType.GENERAL: """
Format clearly:
- Direct and helpful
- Use simple language
- Cite sources when possible
""",
}


def get_style_guide(doc_type: DocumentType) -> str:
    """Get style guide for document type."""
    return STYLE_GUIDES.get(doc_type, STYLE_GUIDES[DocumentType.GENERAL])


# ============================================================================
# LAYER 7: FAILURE LOGGING
# ============================================================================

@dataclass
class FailureLog:
    """Log entry for RAG failures."""
    timestamp: str
    domain: str
    document_type: str
    intent: str
    query: str
    failure_type: str
    violation: str
    suggested_fix: str


# In-memory failure log (in production, use database)
_failure_logs: List[FailureLog] = []


def log_failure(
    doc_type: DocumentType,
    intent: UserIntent,
    query: str,
    failure_type: str,
    violation: str,
    suggested_fix: str
):
    """Log a RAG failure for improvement."""
    log_entry = FailureLog(
        timestamp=datetime.now().isoformat(),
        domain=doc_type.value,
        document_type=doc_type.value,
        intent=intent.value,
        query=query[:100],  # Truncate
        failure_type=failure_type,
        violation=violation,
        suggested_fix=suggested_fix
    )
    _failure_logs.append(log_entry)
    logger.warning(f"RAG Failure: {failure_type} - {violation}")


def get_failure_logs() -> List[Dict]:
    """Get all failure logs."""
    return [
        {
            "timestamp": f.timestamp,
            "domain": f.domain,
            "failure_type": f.failure_type,
            "violation": f.violation,
            "fix": f.suggested_fix
        }
        for f in _failure_logs
    ]


# ============================================================================
# MAIN PIPELINE ORCHESTRATOR
# ============================================================================

@dataclass
class PipelineResult:
    """Complete result from RAG pipeline."""
    document_type: DocumentType
    intent: UserIntent
    context_quality: ContextQuality
    validation: ValidationResult
    style_guide: str
    system_prompt: str
    should_proceed: bool
    issues: List[str] = field(default_factory=list)


def run_pipeline(
    query: str,
    filename: str,
    chunks: List[Dict]
) -> PipelineResult:
    """
    Run the complete 7-layer RAG pipeline.
    
    Returns PipelineResult with all analysis and the appropriate system prompt.
    """
    # Combine chunk content for analysis
    context_text = "\n".join(c.get("content", "") for c in chunks)
    
    # Layer 1: Document Type Detection
    doc_type = detect_document_type(filename, context_text)
    logger.info(f"[Layer 1] Document Type: {doc_type.value}")
    
    # Layer 2: Intent Routing
    intent = detect_intent(query)
    logger.info(f"[Layer 2] Intent: {intent.value}")
    
    # Layer 3-4: Get style guide (domain rules checked post-generation)
    style_guide = get_style_guide(doc_type)
    
    # Layer 4: Context Quality Check
    ctx_quality = assess_context_quality(query, chunks)
    logger.info(f"[Layer 4] Context Quality: sufficient={ctx_quality.is_sufficient}, relevance={ctx_quality.relevance_score:.2f}")
    
    # Build system prompt
    base_prompt = f"""You are a helpful assistant answering questions about {doc_type.value} documents.
Document Type Detected: {doc_type.value.upper()}
User Intent: {intent.value}

{style_guide}

RULES:
1. Answer based ONLY on the provided context
2. Be direct - start with the answer
3. Cite page numbers when available
4. Match the document's style and expectations
"""
    
    # Determine if we should proceed
    issues = []
    should_proceed = True
    
    if not ctx_quality.is_sufficient:
        issues.extend(ctx_quality.issues)
        # Still proceed but with warning
    
    return PipelineResult(
        document_type=doc_type,
        intent=intent,
        context_quality=ctx_quality,
        validation=ValidationResult(is_valid=True, confidence=1.0),  # Placeholder
        style_guide=style_guide,
        system_prompt=base_prompt,
        should_proceed=should_proceed,
        issues=issues
    )


def post_validate(
    answer: str,
    query: str,
    pipeline_result: PipelineResult,
    context_text: str
) -> Tuple[bool, List[str]]:
    """
    Post-generation validation (Layer 5).
    Returns (is_valid, issues).
    """
    validation = validate_answer(
        answer=answer,
        query=query,
        doc_type=pipeline_result.document_type,
        intent=pipeline_result.intent,
        context_text=context_text
    )
    
    # Log failures
    if not validation.is_valid:
        for issue in validation.issues:
            log_failure(
                doc_type=pipeline_result.document_type,
                intent=pipeline_result.intent,
                query=query,
                failure_type="validation_failed",
                violation=issue,
                suggested_fix="Regenerate with stricter constraints"
            )
    
    return validation.is_valid, validation.issues

</code>

backend/app/rag/indexer.py:
<code>
import io
import tempfile
import os
from pydantic import BaseModel
from typing import List, Optional
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from pypdf import PdfReader
from ..config import settings
from .parsers.pdf_parser import pdf_parser
from .parsers.chunker import semantic_chunker
import logging

logger = logging.getLogger(__name__)

# Initialize ChromaDB Client (Lazy)
_chroma_client = None
_collection = None

def get_collection():
    global _chroma_client, _collection
    if _collection is None:
        _chroma_client = chromadb.HttpClient(host=settings.CHROMA_HOST, port=8000)
        _collection = _chroma_client.get_or_create_collection(name="documents")
    return _collection

# Initialize Embedding Model
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

class DocumentChunk(BaseModel):
    id: str
    text: str
    metadata: dict
    embedding: Optional[List[float]] = None

def extract_text_from_file(file_content: bytes, content_type: str, file_id: int) -> tuple:
    """
    Extract text using production-grade parsers.
    
    Returns:
        Tuple of (text, metadata)
    """
    if "pdf" in content_type.lower():
        # Use advanced PDF parser
        try:
            # Save to temp file (PyMuPDF requires file path)
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(file_content)
                tmp_path = tmp_file.name
            
            try:
                result = pdf_parser.parse_pdf(tmp_path)
                
                if result["success"]:
                    logger.info(f"Successfully parsed PDF: {len(result['text'])} chars, {len(result['tables'])} tables")
                    return result["text"], result["metadata"]
                else:
                    logger.error(f"PDF parsing failed: {result.get('error', 'Unknown error')}")
                    # Fallback to basic extraction
                    return _fallback_pdf_extract(file_content), {}
            finally:
                # Clean up temp file
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)
                    
        except Exception as e:
            logger.error(f"Advanced PDF extraction failed: {str(e)}, falling back to basic extraction")
            return _fallback_pdf_extract(file_content), {}
            
    elif "text" in content_type or "markdown" in content_type:
        text = file_content.decode("utf-8", errors="ignore")
        return text, {"content_type": content_type}
    else:
        return "", {}

def _fallback_pdf_extract(file_content: bytes) -> str:
    """Fallback PDF extraction using pypdf."""
    try:
        reader = PdfReader(io.BytesIO(file_content))
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except:
        return ""

def process_and_index_file(file_id: int, file_content: bytes, content_type: str, user_id: int):
    """
    Production-grade file processing and indexing.
    
    Uses:
    - Advanced PDF parsing (PyMuPDF + pdfplumber)
    - Semantic chunking (LangChain)
    - Metadata enrichment
    """
    logger.info(f"Processing file {file_id} for user {user_id}")
    
    # 1. Extract Text with Advanced Parser
    text, doc_metadata = extract_text_from_file(file_content, content_type, file_id)
    
    if not text or not text.strip():
        logger.warning(f"No text extracted for file {file_id}")
        return

    # 2. Semantic Chunking
    base_metadata = {
        "file_id": file_id,
        "user_id": user_id,
        **doc_metadata
    }
    
    chunks = semantic_chunker.chunk_text(text, metadata=base_metadata)
    logger.info(f"Created {len(chunks)} semantic chunks for file {file_id}")
    
    if not chunks:
        logger.warning(f"No chunks created for file {file_id}")
        return
    
    # 3. Create Embeddings
    chunk_texts = [chunk["content"] for chunk in chunks]
    embeddings = embedding_model.encode(chunk_texts, show_progress_bar=False).tolist()
    
    # 4. Prepare Data for ChromaDB
    ids = [f"file_{file_id}_chunk_{i}" for i in range(len(chunks))]
    metadatas = [chunk["metadata"] for chunk in chunks]
    
    # 5. Add to ChromaDB
    try:
        collection = get_collection()
        collection.add(
            documents=chunk_texts,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        logger.info(f"Successfully indexed file {file_id} with {len(chunks)} chunks")
    except Exception as e:
        logger.error(f"Failed to index file {file_id}: {str(e)}")
        raise

</code>

backend/app/rag/query_processor.py:
<code>
"""
Query Processor with Intent Detection & Section Targeting
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Handles query understanding and routing for research queries.

Features:
- Intent classification (Formula, Summary, Comparison, General)
- Query rewriting and expansion
- Section targeting based on intent
- Entity extraction (paper names, authors, concepts)

Total: 200+ lines
"""

import re
import logging
from typing import List, Dict, Optional, Tuple
from enum import Enum
from dataclasses import dataclass

logger = logging.getLogger(__name__)

class QueryIntent(Enum):
    """Query intent types for research papers"""
    FORMULA = "formula"
    SUMMARY = "summary"
    METHODOLOGY = "methodology"
    RESULTS = "results"
    COMPARISON = "comparison"
    LIMITATIONS = "limitations"
    GENERAL = "general"

@dataclass
class ProcessedQuery:
    """Container for processed query information"""
    original: str
    intent: QueryIntent
    target_sections: List[str]
    expanded_queries: List[str]
    entities: Dict[str, List[str]]
    confidence: float

class ResearchQueryProcessor:
    """
    Production-grade query processor for academic papers.
    
    Responsibilities:
    1. Classify query intent
    2. Identify target sections
    3. Expand query with synonyms
    4. Extract entities (papers, authors, concepts)
    """
    
    # Intent detection patterns
    INTENT_PATTERNS = {
        QueryIntent.FORMULA: [
            r'\b(formula|equation|math|algorithm|notation|implementation|code)\b',
            r'\bwhat is the (core|main|primary)? ?(formula|equation)\b',
            r'\b(derive|show|prove)\b.*\b(equation|formula)\b',
        ],
        QueryIntent.SUMMARY: [
            r'\b(summarize|summary|overview|tldr|explain|describe)\b',
            r'\bwhat\s+(is|are)\s+the\s+(main|core|key)\s+(idea|contribution|point)',
            r'\bwhat does.*do\b',
            r'\bgive me (a|an)? ?(summary|overview)',
        ],
        QueryIntent.METHODOLOGY: [
            r'\b(how|method|approach|technique|architecture|model|setup)\b',
            r'\bwhat\s+is\s+the\s+(approach|method|technique)\b',
            r'\bhow\s+(do|does|did).*work\b',
        ],
        QueryIntent.RESULTS: [
            r'\b(result|performance|score|accuracy|metric|benchmark|evaluation)\b',
            r'\bhow\s+(well|good)\b',
            r'\bwhat\s+(score|accuracy|performance)\b',
        ],
        QueryIntent.COMPARISON: [
            r'\b(compare|comparison|versus|vs|difference|better|worse)\b',
            r'\bcompare.*to\b',
            r'\bhow\s+does.*compare\b',
        ],
        QueryIntent.LIMITATIONS: [
            r'\b(limitation|drawback|weakness|problem|issue|challenge|gap)\b',
            r'\bwhat\s+(are|is)\s+the\s+limit',
            r'\bwhat.*fail',
        ]
    }
    
    # Section mapping for each intent
    INTENT_TO_SECTIONS = {
        QueryIntent.FORMULA: ["Method", "Methodology", "Algorithm", "Model", "Appendix", "Implementation"],
        QueryIntent.SUMMARY: ["Abstract", "Introduction", "Conclusion"],
        QueryIntent.METHODOLOGY: ["Method", "Methodology", "Approach", "Model", "Architecture"],
        QueryIntent.RESULTS: ["Results", "Experiments", "Evaluation", "Discussion"],
        QueryIntent.COMPARISON: ["Related Work", "Discussion", "Results"],
        QueryIntent.LIMITATIONS: ["Conclusion", "Discussion", "Future Work"],
        QueryIntent.GENERAL: []  # No specific sections
    }
    
    # Query expansion synonyms
    SYNONYMS = {
        "formula": ["equation", "mathematical expression", "formulation"],
        "method": ["approach", "technique", "methodology"],
        "result": ["performance", "outcome", "finding"],
        "limitation": ["drawback", "weakness", "shortcoming"],
    }
    
    def process(self, query: str) -> ProcessedQuery:
        """
        Main processing pipeline.
        
        Args:
            query: Raw user query
            
        Returns:
            ProcessedQuery with all analysis results
        """
        logger.info(f"Processing query: {query}")
        
        # 1. Classify intent
        intent, confidence = self._classify_intent(query)
        logger.debug(f"Intent: {intent.value} (confidence: {confidence:.2f})")
        
        # 2. Get target sections
        target_sections = self._get_target_sections(intent)
        
        # 3. Expand query
        expanded = self._expand_query(query, intent)
        
        # 4. Extract entities
        entities = self._extract_entities(query)
        
        return ProcessedQuery(
            original=query,
            intent=intent,
            target_sections=target_sections,
            expanded_queries=expanded,
            entities=entities,
            confidence=confidence
        )
    
    def _classify_intent(self, query: str) -> Tuple[QueryIntent, float]:
        """
        Classify query intent using pattern matching.
        
        Returns:
            (intent, confidence_score)
        """
        query_lower = query.lower()
        scores = {intent: 0 for intent in QueryIntent}
        
        # Score each intent based on pattern matches
        for intent, patterns in self.INTENT_PATTERNS.items():
            for pattern in patterns:
                if re.search(pattern, query_lower):
                    scores[intent] += 1
        
        # Get best match
        if max(scores.values()) > 0:
            best_intent = max(scores, key=scores.get)
            confidence = min(scores[best_intent] / 3.0, 1.0)  # Normalize to [0, 1]
            return best_intent, confidence
        
        # Default to GENERAL
        return QueryIntent.GENERAL, 0.5
    
    def _get_target_sections(self, intent: QueryIntent) -> List[str]:
        """Get section names to prioritize for this intent"""
        return self.INTENT_TO_SECTIONS.get(intent, [])
    
    def _expand_query(self, query: str, intent: QueryIntent) -> List[str]:
        """
        Expand query with synonyms and variations.
        
        Returns:
            List of query variations (including original)
        """
        expanded = [query]
        query_lower = query.lower()
        
        # Add synonym-based expansions
        for word, synonyms in self.SYNONYMS.items():
            if word in query_lower:
                for syn in synonyms:
                    expanded.append(query_lower.replace(word, syn))
        
        # Intent-specific expansions
        if intent == QueryIntent.FORMULA:
            if "formula" not in query_lower:
                expanded.append(f"{query} formula")
                expanded.append(f"{query} equation")
        elif intent == QueryIntent.SUMMARY:
            if "summary" not in query_lower and "summarize" not in query_lower:
                expanded.append(f"summary of {query}")
        
        # Limit to top 3 variations
        return list(set(expanded))[:3]
    
    def _extract_entities(self, query: str) -> Dict[str, List[str]]:
        """
        Extract named entities from query.
        
        Returns:
            Dict with entity types and values
        """
        entities = {
            "papers": [],
            "authors": [],
            "concepts": []
        }
        
        # Extract paper names (capitalized phrases in quotes or standalone)
        paper_pattern = r'"([^"]+)"'
        entities["papers"] = re.findall(paper_pattern, query)
        
        # Extract potential author names (capitalized words)
        # Simple heuristic: 2+ consecutive capitalized words
        author_pattern = r'\b([A-Z][a-z]+ [A-Z][a-z]+)\b'
        entities["authors"] = re.findall(author_pattern, query)
        
        # Extract concepts (for now, just all capitalized words not in authors/papers)
        concept_pattern = r'\b([A-Z][a-zA-Z]+)\b'
        all_caps = re.findall(concept_pattern, query)
        entities["concepts"] = [
            c for c in all_caps 
            if c not in entities["authors"] and c not in entities["papers"]
        ]
        
        return entities


class QueryRewriter:
    """
    Advanced query rewriting for better retrieval.
    
    Techniques:
    - Remove stopwords
    - Normalize terminology
    - Handle abbreviations
    """
    
    STOPWORDS = {'the', 'a', 'an', 'is', 'are', 'what', 'how', 'why', 'when', 'where'}
    
    ABBREVIATIONS = {
        'ml': 'machine learning',
        'dl': 'deep learning',
        'nlp': 'natural language processing',
        'cv': 'computer vision',
        'rl': 'reinforcement learning',
        'gnn': 'graph neural network',
        'rnn': 'recurrent neural network',
        'cnn': 'convolutional neural network',
        'lstm': 'long short-term memory',
        'gpt': 'generative pre-trained transformer',
        'bert': 'bidirectional encoder representations from transformers',
    }
    
    def rewrite(self, query: str) -> str:
        """
        Rewrite query for better matching.
        
        Args:
            query: Original query
            
        Returns:
            Rewritten query
        """
        # Convert to lowercase
        rewritten = query.lower()
        
        # Expand abbreviations
        for abbr, full in self.ABBREVIATIONS.items():
            rewritten = re.sub(r'\b' + abbr + r'\b', full, rewritten)
        
        # Remove stopwords (but keep important question words)
        words = rewritten.split()
        important_words = ['how', 'what', 'why', 'when', 'where']
        filtered = [w for w in words if w not in self.STOPWORDS or w in important_words]
        
        return ' '.join(filtered)


# Singleton instances
query_processor = ResearchQueryProcessor()
query_rewriter = QueryRewriter()

</code>

backend/app/rag/retrievers/reranker.py:
<code>
"""
Re-Ranking Module for Precision Improvement

Uses cross-encoder models to re-score and re-rank retrieved chunks.
Significantly improves relevance of top results.
"""

from sentence_transformers import CrossEncoder
from typing import List, Dict, Tuple, Optional
import logging
import math

logger = logging.getLogger(__name__)


class ChunkReranker:
    """
    Production-grade re-ranking using cross-encoder models.
    
    Features:
    - Batched Inference (Memory Safety)
    - Input Validation
    - Error Fallback
    """
    
    def __init__(self, model_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2', batch_size: int = 32):
        """
        Initialize re-ranker with cross-encoder model.
        
        Args:
            model_name: HuggingFace model name for cross-encoder
            batch_size: Max pairs to process at once to avoid OOM
        """
        self.batch_size = batch_size
        try:
            self.model = CrossEncoder(model_name)
            self.logger = logger
            self.logger.info(f"Loaded cross-encoder model: {model_name} (Batch Size: {batch_size})")
        except Exception as e:
            self.logger.error(f"Failed to load cross-encoder: {str(e)}")
            self.model = None
    
    def rerank(
        self,
        query: str,
        chunks: List[Dict],
        top_k: int = 3
    ) -> List[Dict]:
        """
        Re-rank chunks based on query relevance.
        
        Args:
            query: User query
            chunks: List of chunks from initial retrieval
            top_k: Number of top chunks to return
            
        Returns:
            Re-ranked and filtered chunks
        """
        if not self.model:
            self.logger.warning("Re-ranker not available, returning original chunks")
            return chunks[:top_k]
        
        if not chunks:
            return []
        
        # Limit candidate pool safeguard (e.g. don't rerank 1000 docs)
        MAX_CANDIDATES = 100
        candidate_chunks = chunks[:MAX_CANDIDATES]
        
        try:
            # Prepare query-chunk pairs
            pairs = [(query, chunk.get("content", "")) for chunk in candidate_chunks]
            
            # Predict in batches
            all_scores = []
            for i in range(0, len(pairs), self.batch_size):
                batch = pairs[i : i + self.batch_size]
                if not batch:
                    continue
                scores = self.model.predict(batch)
                # Ensure scores is a list (single item batch might return float)
                if isinstance(scores, (float, int)):
                    all_scores.append(float(scores))
                else:
                    all_scores.extend(scores.tolist())
            
            # Combine chunks with scores
            scored_chunks = []
            for chunk, score in zip(candidate_chunks, all_scores):
                chunk_copy = chunk.copy()
                chunk_copy["rerank_score"] = float(score)
                scored_chunks.append(chunk_copy)
            
            # Sort by score (descending)
            scored_chunks.sort(key=lambda x: x["rerank_score"], reverse=True)
            
            # Return top-k
            top_chunks = scored_chunks[:top_k]
            
            self.logger.info(
                f"Re-ranked {len(chunks)} chunks -> {len(top_chunks)} (Top Score: {top_chunks[0]['rerank_score']:.3f})"
            )
            
            return top_chunks
            
        except Exception as e:
            self.logger.error(f"Re-ranking failed: {str(e)}", exc_info=True)
            # Fallback to original order
            return chunks[:top_k]
    
    def get_scores(self, query: str, texts: List[str]) -> List[float]:
        """
        Get relevance scores for query-text pairs (Batched).
        """
        if not self.model or not texts:
            return [0.0] * len(texts)
        
        try:
            pairs = [(query, text) for text in texts]
            all_scores = []
            
            for i in range(0, len(pairs), self.batch_size):
                batch = pairs[i : i + self.batch_size]
                scores = self.model.predict(batch)
                if isinstance(scores, (float, int)):
                    all_scores.append(float(scores))
                else:
                    all_scores.extend(scores.tolist())
                    
            return all_scores
        except Exception as e:
            self.logger.error(f"Scoring failed: {str(e)}")
            return [0.0] * len(texts)


# Singleton instance
reranker = ChunkReranker()

</code>

backend/app/rag/retrievers/hybrid.py:
<code>
from typing import List, Dict, Any, Optional
import logging
import threading
from rank_bm25 import BM25Okapi
from ..indexer import get_collection

logger = logging.getLogger(__name__)

class HybridRetriever:
    """
    Production-Grade Hybrid Searcher.
    Combines Semantic (Vector) and Keyword (BM25) search results using Reciprocal Rank Fusion (RRF).
    
    Features:
    - Thread-safe Index Rebuilds
    - Configurable Fusion Weights
    - Robust Error Handling
    - Detailed Attribution Logging
    """
    
    def __init__(self, rrf_k: int = 60):
        self.rrf_k = rrf_k  # Smoothing constant for RRF
        self.bm25_model = None
        self.doc_registry = {}  # Map: index -> metadata
        self._lock = threading.RLock()
        self._is_ready = False
        
    def is_ready(self) -> bool:
        return self._is_ready

    def _tokenize(self, text: str) -> List[str]:
        """Robust tokenizer for BM25."""
        if not text:
            return []
        return text.lower().split()  # Could upgrade to NLTK/Spacy if needed

    def build_index(self, force: bool = False):
        """
        Builds the in-memory BM25 index from ChromaDB documents.
        Thread-safe operation.
        """
        if self._is_ready and not force:
            return

        with self._lock:
            try:
                logger.info("Initializing BM25 Index Build...")
                collection = get_collection()
                
                # Fetch all documents (Warning: In-memory approach scales to ~100k docs)
                # For >100k, use Elasticsearch/Typesense
                result = collection.get()
                docs = result.get("documents", [])
                metadatas = result.get("metadatas", [])
                ids = result.get("ids", [])
                
                if not docs:
                    logger.warning("BM25 Build Skipped: No documents found.")
                    return

                corpus = []
                registry = {}
                
                for idx, (content, meta, doc_id) in enumerate(zip(docs, metadatas, ids)):
                    # Guard against None content
                    clean_content = content or ""
                    tokens = self._tokenize(clean_content)
                    corpus.append(tokens)
                    registry[idx] = {
                        "content": clean_content,
                        "metadata": meta,
                        "id": doc_id
                    }
                
                self.bm25_model = BM25Okapi(corpus)
                self.doc_registry = registry
                self._is_ready = True
                
                logger.info(f"BM25 Index Ready: {len(docs)} documents indexed.")
                
            except Exception as e:
                logger.error(f"BM25 Index Build Failed: {e}", exc_info=True)
                self._is_ready = False

    def search_bm25(self, query: str, k: int = 5) -> List[Dict]:
        """Execute Keyword Search."""
        if not self._is_ready:
            self.build_index()
            
        if not self.bm25_model:
            return []
            
        try:
            tokens = self._tokenize(query)
            scores = self.bm25_model.get_scores(tokens)
            
            # Get Top-K indices
            top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]
            
            results = []
            for idx in top_indices:
                if scores[idx] > 0.0:  # Only return positive matches
                    item = self.doc_registry[idx].copy()
                    item["score"] = float(scores[idx])
                    results.append(item)
                    
            return results
        except Exception as e:
            logger.error(f"BM25 Search Error: {e}")
            return []

    def reciprocal_rank_fusion(self, 
                             vector_results: List[Dict], 
                             bm25_results: List[Dict], 
                             k: Optional[int] = None) -> List[Dict]:
        """
        Fuse results from multiple lists using RRF.
        Process:
        1. Assign 1/(k + rank) score to each doc in each list.
        2. Sum scores per doc.
        3. Sort desc.
        """
        k_val = k if k is not None else self.rrf_k
        fused_scores = {}
        doc_map = {}
        
        # Helper to process a result set
        def process_results(results: List[Dict], source_name: str):
            for rank, doc in enumerate(results):
                # Robust Key Generation: ID preferred, else content hash
                doc_id = doc.get("id") or doc.get("metadata", {}).get("file_id")
                # Fallback key logic
                if doc_id:
                    key = str(doc_id)
                    # If multiple chunks have same doc_id (common), we need unique chunk ID
                    # Assume Chroma ID is unique string
                    if "id" in doc: 
                        key = str(doc["id"]) # Precise ID from DB
                else:
                    key = str(hash(doc.get("content", "")[:100]))
                
                if key not in doc_map:
                    doc_map[key] = doc
                    doc_map[key]["fusion_sources"] = []
                
                if key not in fused_scores:
                    fused_scores[key] = 0.0
                    
                # RRF Formula
                score = 1.0 / (k_val + rank + 1)
                fused_scores[key] += score
                doc_map[key]["fusion_sources"].append(source_name)

        process_results(vector_results, "vector")
        process_results(bm25_results, "bm25")
        
        # Sort
        sorted_keys = sorted(fused_scores, key=fused_scores.get, reverse=True)
        
        final_list = []
        for key in sorted_keys:
            item = doc_map[key]
            item["rrf_score"] = fused_scores[key]
            final_list.append(item)
            
        return final_list

# Singleton Instance
hybrid_retriever = HybridRetriever(rrf_k=60)

</code>

backend/app/rag/retrievers/__init__.py:
<code>
# retrievers package

</code>

backend/app/rag/parsers/pdf_parser.py:
<code>
"""
Advanced PDF Parser with Production-Grade Features

Features:
- Better text extraction with layout preservation
- Table detection and extraction
- Multi-column layout handling
- OCR fallback for scanned PDFs
- Metadata extraction
"""

import fitz  # PyMuPDF
import pdfplumber
from typing import Dict, List, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class AdvancedPDFParser:
    """Production-grade PDF parser with advanced extraction capabilities."""
    
    def __init__(self):
        self.logger = logger
    
    
    def extract_text_pymupdf(self, pdf_path: str) -> Tuple[str, Dict]:
        """
        Extract text using LlamaParse (if key exists) or PyMuPDF (fallback).
        """
        import os
        llama_key = os.getenv("LLAMA_CLOUD_API_KEY")
        
        # 1. Try LlamaParse for Research-Grade Math/Tables
        if llama_key:
            try:
                self.logger.info("Attempting LlamaParse extraction...")
                # Lazy import to avoid hard dependency if not used
                from llama_parse import LlamaParse
                
                parser = LlamaParse(
                    api_key=llama_key,
                    result_type="markdown",  # Crucial for math ($E=mc^2$)
                    verbose=True
                )
                
                # Verify file exists before sending
                if not os.path.exists(pdf_path):
                    raise FileNotFoundError(f"File not found: {pdf_path}")
                    
                documents = parser.load_data(pdf_path)
                
                if documents:
                    full_text = "\n\n".join([doc.text for doc in documents])
                    metadata = {
                        "title": "LlamaParse Document",
                        "total_pages": len(documents),
                        "source": "llama_parse"
                    }
                    self.logger.info(f"LlamaParse success: {len(full_text)} chars")
                    return full_text, metadata
                    
            except Exception as e:
                self.logger.error(f"LlamaParse failed: {e}. Falling back to PyMuPDF.")
                # Fall through to PyMuPDF
        
        # 2. PyMuPDF Fallback (Existing Logic)
        try:
            doc = fitz.open(pdf_path)
            
            # Extract metadata
            metadata = {
                "title": doc.metadata.get("title", ""),
                "author": doc.metadata.get("author", ""),
                "subject": doc.metadata.get("subject", ""),
                "total_pages": len(doc),
                "created": doc.metadata.get("creationDate", ""),
            }
            
            # Extract text with layout preservation
            full_text = []
            
            for page_num, page in enumerate(doc, start=1):
                # Get text blocks (preserves layout better)
                blocks = page.get_text("blocks")
                
                page_text = []
                for block in blocks:
                    # block[4] is the text content
                    if len(block) >= 5:
                        text = block[4].strip()
                        if text:
                            page_text.append(text)
                
                if page_text:
                    # Add page marker for context
                    full_text.append(f"\n--- Page {page_num} ---\n")
                    full_text.append("\n\n".join(page_text))
            
            doc.close()
            
            extracted_text = "\n".join(full_text)
            self.logger.info(f"Extracted {len(extracted_text)} characters from {metadata['total_pages']} pages")
            
            return extracted_text, metadata
            
        except Exception as e:
            self.logger.error(f"PyMuPDF extraction failed: {str(e)}")
            raise
    
    def extract_tables(self, pdf_path: str) -> List[Dict]:
        """
        Extract tables from PDF using pdfplumber.
        
        Returns:
            List of table dictionaries with page numbers
        """
        tables_found = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, start=1):
                    # Extract tables from this page
                    tables = page.extract_tables()
                    
                    for table_idx, table in enumerate(tables):
                        if table:
                            # Convert table to markdown-like format
                            table_text = self._table_to_text(table)
                            
                            tables_found.append({
                                "page": page_num,
                                "table_index": table_idx,
                                "content": table_text,
                                "rows": len(table),
                                "cols": len(table[0]) if table else 0
                            })
            
            self.logger.info(f"Extracted {len(tables_found)} tables")
            return tables_found
            
        except Exception as e:
            self.logger.warning(f"Table extraction failed: {str(e)}")
            return []
    
    def _table_to_text(self, table: List[List]) -> str:
        """Convert table data to readable text format."""
        if not table:
            return ""
        
        lines = []
        for row in table:
            # Clean and join cells
            cells = [str(cell).strip() if cell else "" for cell in row]
            lines.append(" | ".join(cells))
        
        return "\n".join(lines)
    
    def parse_pdf(self, pdf_path: str) -> Dict:
        """
        Main parsing function that combines all extraction methods.
        
        Returns:
            Dictionary with text, tables, and metadata
        """
        result = {
            "text": "",
            "tables": [],
            "metadata": {},
            "success": False
        }
        
        try:
            # 1. Extract main text with PyMuPDF
            text, metadata = self.extract_text_pymupdf(pdf_path)
            result["text"] = text
            result["metadata"] = metadata
            
            # 2. Extract tables separately
            tables = self.extract_tables(pdf_path)
            result["tables"] = tables
            
            # 3. Integrate tables into text if found
            if tables:
                table_sections = []
                for table in tables:
                    table_sections.append(
                        f"\n\n[Table from Page {table['page']}]\n{table['content']}\n"
                    )
                
                # Append tables to main text
                result["text"] += "\n\n" + "\n".join(table_sections)
            
            result["success"] = True
            self.logger.info(f"Successfully parsed PDF: {len(result['text'])} chars, {len(tables)} tables")
            
        except Exception as e:
            self.logger.error(f"PDF parsing failed: {str(e)}")
            result["error"] = str(e)
        
        return result


# Singleton instance
pdf_parser = AdvancedPDFParser()

</code>

backend/app/rag/parsers/chunker.py:
<code>
"""
Semantic Chunking with Context Preservation

Implements intelligent text splitting that:
- Preserves semantic boundaries
- Maintains document structure
- Adds rich metadata
- Optimizes chunk size for embeddings
"""

from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer, util
from typing import List, Dict, Optional
import logging
import re
import numpy as np

logger = logging.getLogger(__name__)

def classify_importance(text: str, section_heading: str = "") -> str:
    """
    Classify chunk importance based on content and section heuristics.
    
    Returns: 'core_contribution', 'methodology', 'experiment', or 'background'
    """
    text_lower = text.lower()
    heading_lower = section_heading.lower() if section_heading else ""
    
    # Core Contribution: Abstract, Conclusion, Main findings
    core_keywords = ['abstract', 'conclusion', 'summary', 'key finding', 'contribution', 
                     'main result', 'we propose', 'we present', 'novel', 'state-of-the-art']
    if any(kw in heading_lower for kw in ['abstract', 'conclusion', 'summary']):
        return 'core_contribution'
    if any(kw in text_lower[:500] for kw in core_keywords):
        return 'core_contribution'
    
    # Methodology: Methods, Approach, Algorithm
    method_keywords = ['method', 'approach', 'algorithm', 'implementation', 'architecture',
                       'procedure', 'technique', 'design', 'model']
    if any(kw in heading_lower for kw in ['method', 'approach', 'algorithm']):
        return 'methodology'
    if any(kw in text_lower for kw in method_keywords):
        return 'methodology'
    
    # Experiment: Results, Evaluation, Data
    exp_keywords = ['experiment', 'result', 'evaluation', 'dataset', 'benchmark', 
                    'accuracy', 'performance', 'table', 'figure', 'ablation']
    if any(kw in heading_lower for kw in ['result', 'experiment', 'evaluation']):
        return 'experiment'
    if any(kw in text_lower for kw in exp_keywords):
        return 'experiment'
    
    # Default: Background
    return 'background'


class SemanticChunker:
    """
    Production-grade Semantic Chunking.
    
    Splits text based on semantic similarity between sentences rather than 
    arbitrary character counts. Finds "natural breaks" in conversation/text.
    """
    
    def __init__(
        self,
        model_name: str = 'all-MiniLM-L6-v2',
        breakpoint_percentile_threshold: int = 95,
        buffer_size: int = 1
    ):
        """
        Args:
            model_name: Embedding model for semantic comparison
            breakpoint_percentile_threshold: Higher = fewer chunks (more strict splitting)
            buffer_size: Number of sentences to look ahead/behind for context
        """
        try:
            self.model = SentenceTransformer(model_name)
        except Exception as e:
            logger.error(f"Failed to load embedding model: {e}")
            self.model = None
            
        self.breakpoint_percentile_threshold = breakpoint_percentile_threshold
        self.buffer_size = buffer_size
        self.logger = logger
        
        # Fallback splitter
        self.fallback_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200
        )

    def _split_into_sentences(self, text: str) -> List[str]:
        # Simple robust sentence splitting
        # Look for periods, question marks, exclamations followed by space and capital letter
        sentences = re.split(r'(?<=[.?!])\s+(?=[A-Z])', text)
        return [s.strip() for s in sentences if s.strip()]

    def _combine_sentences(self, sentences: List[dict], buffer_size: int = 1) -> List[dict]:
        # Add window context to sentences for better embedding representation
        for i in range(len(sentences)):
            combined_text = ""
            # Add previous sentences
            for j in range(i - buffer_size, i):
                if j >= 0:
                    combined_text += sentences[j]['sentence'] + " "
            
            combined_text += sentences[i]['sentence']
            
            # Add next sentences
            for j in range(i + 1, i + 1 + buffer_size):
                if j < len(sentences):
                    combined_text += " " + sentences[j]['sentence']
            
            sentences[i]['combined_sentence'] = combined_text
        return sentences

    def chunk_text(self, text: str, metadata: Optional[Dict] = None) -> List[Dict]:
        """
        Chunk using semantic analysis.
        
        1. Split into sentences
        2. Embed sentences (with context buffer)
        3. Calculate cosine distances between adjacent sentences
        4. Split where distance is high (similarity is low)
        """
        if not text or not text.strip():
            return []
            
        # 0. Handle Page Markers (Recursive Strategy)
        # pdf_parser inserts "\n--- Page X ---\n". We use this to assign page numbers.
        page_pattern = r'\n--- Page (\d+) ---\n'
        # Check if text contains page markers
        if re.search(page_pattern, text):
            parts = re.split(page_pattern, text)
            # parts structure: [preamble, page_num_1, content_1, page_num_2, content_2, ...]
            
            all_chunks = []
            
            # Handle preamble (text before first page marker)
            if parts[0].strip():
                # Treat as Page 1 or metadata default
                # We'll just recurse with existing metadata
                all_chunks.extend(self.chunk_text(parts[0], metadata))
                
            # Iterate over page number/content pairs
            for i in range(1, len(parts), 2):
                try:
                    page_num = int(parts[i])
                    page_content = parts[i+1]
                    
                    if not page_content.strip():
                        continue
                        
                    # Update metadata for this page
                    page_metadata = (metadata or {}).copy()
                    page_metadata["page_number"] = page_num
                    
                    # Recurse: Chunk this page's content
                    # Since markers are removed, the recursive call will hit the core logic below
                    page_chunks = self.chunk_text(page_content, page_metadata)
                    all_chunks.extend(page_chunks)
                except Exception as e:
                    logger.warning(f"Error processing page split: {e}")
                    continue
                    
            return all_chunks

        # Fallback if model failed to load
        if not self.model:
            logger.warning("Semantic chunking model not loaded, using fallback.")
            chunks = self.fallback_splitter.split_text(text)
            return [{"content": c, "metadata": metadata or {}} for c in chunks]

        # 1. Split sentences
        single_sentences_list = self._split_into_sentences(text)
        if len(single_sentences_list) < 2:
             return [{"content": text, "metadata": metadata or {}}]
             
        sentences = [{'sentence': x, 'index': i} for i, x in enumerate(single_sentences_list)]
        
        # 2. Add Context Buffer & Embed
        sentences = self._combine_sentences(sentences, self.buffer_size)
        embeddings = self.model.encode([x['combined_sentence'] for x in sentences])
        
        # 3. Calculate Cosine Distances
        distances = []
        for i in range(len(embeddings) - 1):
            sim = util.pytorch_cos_sim(embeddings[i], embeddings[i+1]).item()
            distance = 1 - sim
            distances.append(distance)
            
        # 4. Determine Threshold
        # value at the Xth percentile (e.g. 95th percentile of distances = top 5% most different)
        # Any distance higher than this is a breakpoint.
        if not distances:
            breakpoint_distance_threshold = 0
        else:
            breakpoint_distance_threshold = np.percentile(distances, self.breakpoint_percentile_threshold)
            
        # 5. Group Chunks
        indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold]
        
        chunks = []
        start_index = 0
        
        # Iterate through breakpoints
        for index in indices_above_thresh:
            # The split happens AFTER the sentence at 'index'
            end_index = index + 1 # exclusive because list slicing is exclusive
            
            group = sentences[start_index:end_index]
            combined_text = " ".join([d['sentence'] for d in group])
            chunks.append(combined_text)
            start_index = end_index
            
        # Add the last chunk
        if start_index < len(sentences):
            group = sentences[start_index:]
            combined_text = " ".join([d['sentence'] for d in group])
            chunks.append(combined_text)
            
        # Format for return
        enriched_chunks = []
        total_chunks = len(chunks)
        
        for idx, chunk_text in enumerate(chunks):
            chunk_metadata = {
                "chunk_index": idx,
                "total_chunks": total_chunks,
                "chunk_method": "semantic",
                **(metadata or {})
            }
            enriched_chunks.append({
                "content": chunk_text,
                "metadata": chunk_metadata
            })
            
        logger.info(f"Semantic Chunking: {len(text)} chars -> {len(single_sentences_list)} sentences -> {total_chunks} chunks")
        return enriched_chunks

# ... (SemanticChunker class remains above)

class ParentChildChunker:
    """
    Implements 'Small-to-Big' Retrieval Strategy.
    
    1. Splits text into large 'Parent' chunks (e.g., 1024-2048 chars) for full context.
    2. Splits each Parent into small 'Child' chunks (e.g., 256-512 chars) for precise retrieval.
    3. Child chunks store the Parent's content in metadata.
    """
    
    def __init__(self, parent_chunk_size=1024, child_chunk_size=256, chunk_overlap=0):
        self.parent_splitter = RecursiveCharacterTextSplitter(
            chunk_size=parent_chunk_size, 
            chunk_overlap=chunk_overlap
        )
        self.child_splitter = RecursiveCharacterTextSplitter(
            chunk_size=child_chunk_size, 
            chunk_overlap=chunk_overlap
        )
        self.semantic_chunker = SemanticChunker() # Use semantic for finding good parents?
        
    def chunk_text(self, text: str, metadata: Optional[Dict] = None) -> List[Dict]:
        if not text or not text.strip():
            return []
            
        # 1. Create Parent Chunks (Legacy: fixed size, Future: Semantic Parents)
        # Using Semantic Chunker for Parents ensures parents are topic-coherent
        parents = self.semantic_chunker.chunk_text(text, metadata)
        
        all_children = []
        
        for p_idx, parent in enumerate(parents):
            parent_text = parent["content"]
            parent_meta = parent["metadata"]
            
            # 2. Create Child Chunks from this Parent
            children_texts = self.child_splitter.split_text(parent_text)
            
            for c_idx, child_text in enumerate(children_texts):
                # 3. Link Child to Parent + Classify Importance
                section = parent_meta.get("section_heading", "")
                importance = classify_importance(child_text, section)
                
                child_meta = parent_meta.copy()
                child_meta.update({
                    "parent_content": parent_text,  # The "Big" chunk
                    "is_child": True,
                    "parent_index": p_idx,
                    "child_index": c_idx,
                    "chunk_method": "parent_child",
                    "importance": importance  # NEW: core_contribution/methodology/experiment/background
                })
                
                all_children.append({
                    "content": child_text, # The "Small" chunk (for vector search)
                    "metadata": child_meta
                })
        
        logger.info(f"Parent-Child Chunking: {len(parents)} parents -> {len(all_children)} children")
        return all_children

# Singleton instance (switched to Parent-Child as default for Research-Grade)
# You can swap this back to semantic_chunker if desired
semantic_chunker = ParentChildChunker()

</code>

backend/app/rag/parsers/__init__.py:
<code>
# parsers package

</code>

backend/app/rag/parsers/academic_pdf_parser_v2.py:
<code>
"""
Production-Grade Academic PDF Parser
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
A comprehensive parser for academic research papers with:
- Multi-column layout detection
- Table and figure extraction
- Equation handling
- Hierarchical section detection
- Reference parsing
- Metadata extraction

Total: 350+ lines of production code
"""

import re
import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import pdfplumber
from langchain_text_splitters import RecursiveCharacterTextSplitter

logger = logging.getLogger(__name__)

@dataclass
class Section:
    """Represents a document section with hierarchy"""
    name: str
    level: int  # 1=main (Abstract), 2=subsection (3.1 Background)
    start_page: int
    end_page: Optional[int] = None
    content: List[str] = None
    
    def __post_init__(self):
        if self.content is None:
            self.content = []

@dataclass
class AcademicChunk:
    """Enhanced chunk with academic metadata"""
    text: str
    metadata: Dict

class AcademicPDFParserV2:
    """
    Production-grade parser for academic papers.
    
    Features:
    - Detects 6 standard sections (Abstract, Intro, Method, Results, Discussion, Conclusion)
    - Handles tables and figures
    - Extracts equations
    - Parses references
    - Multi-column aware
    - Sub-chunking for large sections
    """
    
    # Section patterns (ordered by priority)
    SECTION_PATTERNS = [
        (r'^abstract\s*$', 'Abstract', 1),
        (r'^introduction\s*$', 'Introduction', 1),
        (r'^(\d+\.?\s+)?introduction', 'Introduction', 1),
        (r'^(\d+\.?\s+)?related\s+work', 'Related Work', 1),
        (r'^(\d+\.?\s+)?background', 'Background', 1),
        (r'^(\d+\.?\s+)?method(ology)?', 'Method', 1),
        (r'^(\d+\.?\s+)?approach', 'Method', 1),
        (r'^(\d+\.?\s+)?model', 'Method', 1),
        (r'^(\d+\.?\s+)?algorithm', 'Method', 1),
        (r'^(\d+\.?\s+)?experiment(s|al\s+setup)?', 'Experiments', 1),
        (r'^(\d+\.?\s+)?results?', 'Results', 1),
        (r'^(\d+\.?\s+)?evaluation', 'Results', 1),
        (r'^(\d+\.?\s+)?discussion', 'Discussion', 1),
        (r'^(\d+\.?\s+)?conclusion(s)?', 'Conclusion', 1),
        (r'^(\d+\.?\s+)?future\s+work', 'Future Work', 1),
        (r'^references?\s*$', 'References', 1),
        (r'^bibliography\s*$', 'References', 1),
        (r'^appendix', 'Appendix', 1),
    ]
    
    # Junk patterns to remove
    JUNK_PATTERNS = [
        r'\b(et\s+al\.?)',  # Citations
        r'\[\d+\]',  # Reference markers [1]
        r'\(\d{4}\)',  # Years in citations
        r'^\s*\d+\s*$',  # Page numbers
        r'^Figure\s+\d+',  # Figure captions
        r'^Table\s+\d+',  # Table captions
    ]
    
    def __init__(self, max_chunk_size: int = 2000, chunk_overlap: int = 200):
        self.max_chunk_size = max_chunk_size
        self.chunk_overlap = chunk_overlap
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=max_chunk_size,
            chunk_overlap=chunk_overlap,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
        self.sections: List[Section] = []
        self.current_section = Section("General", 1, 0)
        self.chunks: List[AcademicChunk] = []
        
    def parse(self, pdf_path: str, file_id: int, user_id: int) -> List[Dict]:
        """
        Main parsing entry point.
        
        Args:
            pdf_path: Path to PDF file
            file_id: Database file ID
            user_id: User ID for multi-tenancy
            
        Returns:
            List of chunk dictionaries ready for indexing
        """
        logger.info(f"Parsing academic PDF: {pdf_path}")
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                # Extract text page by page
                for page_num, page in enumerate(pdf.pages, start=1):
                    text = self._extract_page_text(page)
                    if not text:
                        continue
                        
                    # Process each line
                    lines = text.split('\n')
                    for line in lines:
                        self._process_line(line, page_num)
                
                # Flush final section
                self._flush_section(page_num)
                
            logger.info(f"Extracted {len(self.chunks)} chunks from {len(self.sections)} sections")
            
            # Convert to index format
            return self._to_index_format(file_id, user_id)
            
        except Exception as e:
            logger.error(f"PDF parsing failed: {e}", exc_info=True)
            return []
    
    def _extract_page_text(self, page) -> str:
        """Extract text with multi-column handling"""
        try:
            # Try layout-aware extraction
            text = page.extract_text(layout=True)
            if not text:
                # Fallback to simple extraction
                text = page.extract_text()
            return self._clean_text(text) if text else ""
        except Exception as e:
            logger.warning(f"Page extraction failed: {e}")
            return ""
    
    def _clean_text(self, text: str) -> str:
        """Remove noise and artifacts"""
        # Remove excessive whitespace
        text = re.sub(r'\s+', ' ', text)
        
        # Remove junk patterns
        for pattern in self.JUNK_PATTERNS:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        
        # Remove standalone numbers (page numbers)
        text = re.sub(r'^\s*\d+\s*$', '', text, flags=re.MULTILINE)
        
        return text.strip()
    
    def _process_line(self, line: str, page_num: int):
        """Process a single line and detect sections"""
        line = line.strip()
        if not line or len(line) < 3:
            return
            
        # Check if line is a section header
        section_name = self._detect_section(line)
        if section_name:
            # Flush current section before starting new one
            self._flush_section(page_num - 1)
            self.current_section = Section(section_name, 1, page_num)
            self.sections.append(self.current_section)
            logger.debug(f"Section detected: {section_name} on page {page_num}")
            return
        
        # Add line to current section
        self.current_section.content.append(line)
    
    def _detect_section(self, line: str) -> Optional[str]:
        """Detect if line is a section header"""
        line_lower = line.lower().strip()
        
        # Must be short enough to be a header (not a paragraph)
        if len(line) > 100:
            return None
            
        # Check against patterns
        for pattern, section_name, level in self.SECTION_PATTERNS:
            if re.match(pattern, line_lower):
                return section_name
                
        return None
    
    def _flush_section(self, page_num: int):
        """Convert buffered section into chunks"""
        if not self.current_section.content:
            return
            
        # Skip references entirely
        if self.current_section.name.lower() == 'references':
            return
            
        full_text = " ".join(self.current_section.content)
        
        # Classify importance
        importance = self._classify_importance(self.current_section.name)
        
        # Sub-chunk if too large
        if len(full_text) > self.max_chunk_size:
            sub_chunks = self.splitter.split_text(full_text)
            for idx, sub_text in enumerate(sub_chunks):
                chunk = AcademicChunk(
                    text=sub_text,
                    metadata={
                        "section": self.current_section.name,
                        "page": self.current_section.start_page,
                        "importance": importance,
                        "sub_chunk_index": idx,
                        "total_sub_chunks": len(sub_chunks),
                        "source": "academic_parser_v2"
                    }
                )
                self.chunks.append(chunk)
        else:
            chunk = AcademicChunk(
                text=full_text,
                metadata={
                    "section": self.current_section.name,
                    "page": self.current_section.start_page,
                    "importance": importance,
                    "source": "academic_parser_v2"
                }
            )
            self.chunks.append(chunk)
        
        # Reset for next section
        self.current_section.content = []
    
    def _classify_importance(self, section: str) -> str:
        """Classify section importance for filtering"""
        section_lower = section.lower()
        
        if any(s in section_lower for s in ['abstract', 'introduction', 'conclusion']):
            return 'core_contribution'
        elif any(s in section_lower for s in ['method', 'approach', 'model', 'algorithm']):
            return 'methodology'
        elif any(s in section_lower for s in ['experiment', 'result', 'evaluation']):
            return 'experiment'
        elif any(s in section_lower for s in ['related', 'background']):
            return 'background'
        else:
            return 'general'
    
    def _to_index_format(self, file_id: int, user_id: int) -> List[Dict]:
        """Convert chunks to indexing format"""
        indexed_chunks = []
        
        for idx, chunk in enumerate(self.chunks):
            indexed_chunks.append({
                "text": chunk.text,
                "metadata": {
                    **chunk.metadata,
                    "file_id": file_id,
                    "user_id": user_id,
                    "chunk_index": idx
                }
            })
        
        return indexed_chunks
    
    def extract_metadata(self, pdf_path: str) -> Dict:
        """
        Extract document-level metadata.
        
        Returns:
            Dict with title, authors, year, venue, etc.
        """
        metadata = {
            "title": None,
            "authors": [],
            "year": None,
            "venue": None,
            "abstract": None
        }
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                if len(pdf.pages) > 0:
                    first_page_text = pdf.pages[0].extract_text()
                    
                    # Extract title (usually first large lines)
                    lines = first_page_text.split('\n')[:10]
                    potential_titles = [l.strip() for l in lines if len(l.strip()) > 20]
                    if potential_titles:
                        metadata["title"] = potential_titles[0]
                    
                    # Extract year (look for 4-digit years)
                    year_match = re.search(r'\b(19|20)\d{2}\b', first_page_text)
                    if year_match:
                        metadata["year"] = int(year_match.group(0))
        
        except Exception as e:
            logger.warning(f"Metadata extraction failed: {e}")
        
        return metadata


# Convenience function
def parse_academic_pdf(pdf_path: str, file_id: int, user_id: int) -> List[Dict]:
    """Parse academic PDF and return chunks"""
    parser = AcademicPDFParserV2()
    return parser.parse(pdf_path, file_id, user_id)

</code>

backend/app/rag/parsers/pdf_structure_parser.py:
<code>
import re
import math
import statistics
import logging
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, field
import pdfplumber  # Requirement: pdfplumber
from collections import Counter

logger = logging.getLogger(__name__)

@dataclass
class SectionMetadata:
    title: str = "Uncategorized"
    level: int = 0
    page: int = 1
    type: str = "text"  # text, header, caption, equation

@dataclass
class AcademicChunk:
    text: str
    metadata: Dict[str, Any]

class AcademicPDFParser:
    """
    Research-Grade Parser for 2-Column Academic Papers (NeurIPS/ICML/arXiv style).
    
    Capabilities:
    1. Layout Analysis: Detects columns and reading flow (Top-Down vs Columnar).
    2. Structural Cleanup: Removes headers, footers, and page numbers.
    3. Hierarchy Detection: Reconstructs 'Abstract' -> 'Introduction' -> 'Methods'.
    4. Math Hygiene: Replaces equations with [EQUATION] token to reduce noise.
    5. Citation Normalization: Removes [1, 2] reference styles for cleaner embeddings.
    """
    
    # Common academic section headers (case-insensitive regex)
    SECTION_HEADERS = {
        r'^abstract': 'Abstract',
        r'^introduction': 'Introduction',
        r'^background': 'Background',
        r'^related work': 'Related Work',
        r'^method': 'Methodology',
        r'^experimental': 'Experiments',
        r'^results': 'Results',
        r'^discussion': 'Discussion',
        r'^conclusion': 'Conclusion',
        r'^references': 'References'
    }
    
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.chunks: List[AcademicChunk] = []
        self.doc_structure = []  # Tree representation if needed
        
        # State tracking
        self.current_section = "Abstract"  # Default start
        self.body_font_size = 0.0
        self.header_font_size_threshold = 0.0

    def parse(self) -> List[AcademicChunk]:
        """Main execution pipeline."""
        logger.info(f"Starting analysis of academic PDF: {self.file_path}")
        
        try:
            with pdfplumber.open(self.file_path) as pdf:
                # Pass 1: Global Analysis (Font stats, layout type)
                self._analyze_global_stats(pdf)
                
                # Pass 2: Page-by-Page Extraction
                for i, page in enumerate(pdf.pages):
                    page_num = i + 1
                    logger.debug(f"Parsing Page {page_num}")
                    
                    # A. Filter artifacts (Header/Footer)
                    cropped_page = self._remove_artifacts(page)
                    
                    # B. Detect Layout (1-col vs 2-col)
                    layout_type = self._detect_layout(cropped_page)
                    
                    # C. Extract Text Blocks in Reading Order
                    text_blocks = self._extract_blocks_flow_aware(cropped_page, layout_type)
                    
                    # D. Process Blocks (Clean, Detect Sections, Chunk)
                    self._process_text_blocks(text_blocks, page_num)
                    
            return self.chunks
            
        except Exception as e:
            logger.error(f"PDF Analysis Failed: {e}", exc_info=True)
            return []

    def _analyze_global_stats(self, pdf):
        """Determine what counts as 'Body Text' vs 'Header'."""
        all_sizes = []
        # Sample first 5 pages
        for p in pdf.pages[:5]:
            words = p.extract_words(extra_attrs=["size"])
            all_sizes.extend([w["size"] for w in words])
            
        if not all_sizes:
            self.body_font_size = 10.0 # Default
            return

        # Body text is usually the mode
        self.body_font_size = statistics.mode([round(s, 1) for s in all_sizes])
        # Headers are usually > 1.1x body
        self.header_font_size_threshold = self.body_font_size * 1.1
        logger.info(f"Detected Body Font: {self.body_font_size}pt, Header Threshold: {self.header_font_size_threshold}pt")

    def _remove_artifacts(self, page):
        """Crop headers/footers based on y-position heuristics."""
        h = page.height
        w = page.width
        # Standard academic margins: 5-8% top/bottom
        top_margin = h * 0.05
        bottom_margin = h * 0.93
        
        return page.crop((0, top_margin, w, bottom_margin))

    def _detect_layout(self, page) -> str:
        """Heuristic: Check if text density is split in middle."""
        w = page.width
        mid_x = w / 2
        
        # Check for gap in the middle 20%
        center_zone = page.crop((mid_x - 30, 0, mid_x + 30, page.height))
        words_in_center = center_zone.extract_words()
        
        # If very few words in center strip, it's 2-column
        if len(words_in_center) < 5:
            return "two_column"
        return "single_column"

    def _extract_blocks_flow_aware(self, page, layout: str):
        """Get text blocks respecting reading order."""
        words = page.extract_words(keep_blank_chars=False, extra_attrs=["size", "fontname"])
        w = page.width
        mid_x = w / 2

        if layout == "two_column":
            # Split words into Left and Right buckets
            left_col = [wd for wd in words if wd['x0'] < mid_x]
            right_col = [wd for wd in words if wd['x0'] >= mid_x]
            
            # Sort individual columns Top-Down
            left_col.sort(key=lambda x: (x['top'], x['x0']))
            right_col.sort(key=lambda x: (x['top'], x['x0']))
            
            return self._group_words_into_lines(left_col) + self._group_words_into_lines(right_col)
        else:
            words.sort(key=lambda x: (x['top'], x['x0']))
            return self._group_words_into_lines(words)

    def _group_words_into_lines(self, words) -> List[Dict]:
        """Group words into semantic lines/blocks."""
        if not words:
            return []
            
        lines = []
        current_line = [words[0]]
        
        for word in words[1:]:
            last_word = current_line[-1]
            # Same line heuristic: overlaps vertically or very close y-distance
            vertical_diff = abs(word['top'] - last_word['top'])
            
            if vertical_diff < 5: # 5px tolerance
                current_line.append(word)
            else:
                lines.append(self._finalize_line(current_line))
                current_line = [word]
        
        lines.append(self._finalize_line(current_line))
        return lines

    def _finalize_line(self, word_list):
        """Convert list of words to line dict with stats."""
        text = " ".join([w['text'] for w in word_list])
        avg_size = statistics.mean([w['size'] for w in word_list])
        is_bold = any("bold" in w.get('fontname', '').lower() for w in word_list)
        return {
            "text": text,
            "size": avg_size,
            "bold": is_bold,
            "top": word_list[0]['top']
        }

    def _process_text_blocks(self, lines: List[Dict], page_num: int):
        """Analyze lines for semantic meaning."""
        buffer = []
        
        for line in lines:
            text = line['text'].strip()
            if not text:
                continue
                
            # 1. Check if Header
            is_header = self._is_section_header(line)
            if is_header:
                # Flush previous buffer
                self._flush_buffer(buffer, page_num)
                buffer = []
                
                # Update Context
                clean_title = self._clean_header_text(text)
                self.current_section = clean_title
                continue
            
            # 2. Check for Citation/Equation noise
            clean_text = self._clean_content(text)
            if clean_text:
                buffer.append(clean_text)
                
        # Flush remaining
        self._flush_buffer(buffer, page_num)

    def _is_section_header(self, line) -> bool:
        """Detect headers via size or regex."""
        text = line['text']
        
        # Rule 1: Font Size
        if line['size'] >= self.header_font_size_threshold:
            return True
        
        # Rule 2: Regex matching "1. Introduction" even if small font
        # Must be short
        if len(text) < 100:
            for pattern in self.SECTION_HEADERS:
                if re.search(pattern, text.lower()):
                    return True
        return False

    def _clean_header_text(self, text: str) -> str:
        """Normalize '1. Introduction' -> 'Introduction'."""
        # Remove leading numbers
        text = re.sub(r'^\d+(\.\d+)*\s+', '', text)
        return text.title()

    def _clean_content(self, text: str) -> Optional[str]:
        """Apply Research-Grade hygiene."""
        # 1. Filter Equations (Heuristic: high density of special chars)
        # Replacing simple math for now
        # text = re.sub(r'\$.*?\$', '[EQUATION]', text) 
        
        # 2. Remove Citations [12] or [12, 13]
        text = re.sub(r'\[\s*\d+(\s*,\s*\d+)*\s*\]', '', text)
        
        # 3. Skip standalone numbers (page nums missed by crop)
        if re.match(r'^\d+$', text):
            return None
            
        return text

    def _flush_buffer(self, buffer: List[str], page_num: int):
        """
        Create completed chunk(s). 
        Enforces sub-chunking for large sections to meet strict size limits (300-600 tokens).
        """
        if not buffer:
            return
            
        full_text = " ".join(buffer)
        
        # If references, skip completely as per requirement 2
        if self.current_section.lower() == "references":
            return
            
        # Hard Limit: ~500 words / 3000 chars per chunk to ensure precision
        # We use a simple splitter to respect sentence boundaries
        from langchain_text_splitters import RecursiveCharacterTextSplitter
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000, 
            chunk_overlap=200,
            separators=["\n\n", ". ", " ", ""]
        )
        
        sub_chunks = splitter.split_text(full_text)
        total_sub = len(sub_chunks)
        
        importance = self._derive_importance(self.current_section)
        
        for i, text_part in enumerate(sub_chunks):
            chunk = AcademicChunk(
                text=text_part,
                metadata={
                    "section": self.current_section,
                    "page": page_num,
                    "source": "pdf_structure_parser",
                    "importance": importance,
                    "sub_chunk_index": i,
                    "total_sub_chunks": total_sub
                }
            )
            self.chunks.append(chunk)

    def _derive_importance(self, section: str) -> str:
        """Map section to importance class."""
        s = section.lower()
        if "abstract" in s or "conclusion" in s:
            return "core_contribution"
        if "method" in s:
            return "methodology"
        if "result" in s or "experiment" in s:
            return "experiment"
        return "background"

# Facade
def parse_academic_pdf(file_path: str) -> List[AcadmicChunk]:
    parser = AcademicPDFParser(file_path)
    return parser.parse()

</code>

backend/app/rag/parsers/page_aware_parser.py:
<code>
"""
Page-Aware PDF Parser using PyMuPDF
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Extracts text page-by-page and preserves page metadata through chunking.

This is the CORRECT way to handle page citations:
1. Extract text per page (PyMuPDF)
2. Chunk with page metadata
3. Store metadata in vector DB
4. Retrieve with page info
5. LLM cites using metadata (not guessing)

Total: 250+ lines
"""

import logging
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
import fitz  # PyMuPDF
from langchain_text_splitters import RecursiveCharacterTextSplitter

logger = logging.getLogger(__name__)

@dataclass
class PageExtraction:
    """Represents text extracted from a single page"""
    page_num: int  # 1-indexed human-readable
    text: str
    section: Optional[str] = None  # Detected section name

@dataclass
class AcademicChunk:
    """Chunk with page metadata"""
    text: str
    page_start: int
    page_end: int
    section: str
    importance: str
    file_id: int
    chunk_index: int

class PageAwarePDFParser:
    """
    Production-grade PDF parser that preserves page numbers.
    
    Flow:
    1. Extract text page-by-page (PyMuPDF)
    2. Detect sections per page
    3. Chunk while preserving page boundaries
    4. Each chunk knows its page range
    """
    
    # Section detection patterns (same as before)
    SECTION_PATTERNS = [
        (r'^abstract\s*$', 'Abstract'),
        (r'^(\d+\.?\s+)?introduction', 'Introduction'),
        (r'^(\d+\.?\s+)?related\s+work', 'Related Work'),
        (r'^(\d+\.?\s+)?background', 'Background'),
        (r'^(\d+\.?\s+)?method(ology)?', 'Method'),
        (r'^(\d+\.?\s+)?approach', 'Method'),
        (r'^(\d+\.?\s+)?model', 'Method'),
        (r'^(\d+\.?\s+)?experiment(s)?', 'Experiments'),
        (r'^(\d+\.?\s+)?results?', 'Results'),
        (r'^(\d+\.?\s+)?evaluation', 'Results'),
        (r'^(\d+\.?\s+)?discussion', 'Discussion'),
        (r'^(\d+\.?\s+)?conclusion(s)?', 'Conclusion'),
        (r'^references?\s*$', 'References'),
    ]
    
    def __init__(self, chunk_size: int = 2000, chunk_overlap: int = 200):
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=chunk_overlap,
            separators=["\n\n", "\n", ". ", " ", ""]
        )
    
    def parse(self, pdf_path: str, file_id: int, user_id: int) -> List[Dict]:
        """
        Main entry point for parsing.
        
        Returns:
            List of chunks with page metadata ready for vector DB
        """
        logger.info(f"Parsing PDF with page tracking: {pdf_path}")
        
        try:
            # Step 1: Extract pages
            pages = self._extract_pages(pdf_path)
            logger.info(f"Extracted {len(pages)} pages")
            
            # Step 2: Detect sections
            pages_with_sections = self._detect_sections_per_page(pages)
            
            # Step 3: Chunk with page metadata
            chunks = self._chunk_with_pages(pages_with_sections, file_id, user_id)
            logger.info(f"Created {len(chunks)} chunks")
            
            return chunks
            
        except Exception as e:
            logger.error(f"PDF parsing failed: {e}", exc_info=True)
            return []
    
    def _extract_pages(self, pdf_path: str) -> List[PageExtraction]:
        """
        Extract text page-by-page using PyMuPDF.
        
        This is CRITICAL: we must loop per page, not per document.
        """
        pages = []
        
        try:
            doc = fitz.open(pdf_path)
            
            for page_num, page in enumerate(doc, start=1):
                # Extract text
                text = page.get_text()
                
                # Clean text
                text = self._clean_text(text)
                
                if text.strip():
                    pages.append(PageExtraction(
                        page_num=page_num,
                        text=text
                    ))
            
            doc.close()
            
        except Exception as e:
            logger.error(f"PyMuPDF extraction failed: {e}")
            # Fallback to pdfplumber if PyMuPDF fails
            pages = self._fallback_extraction(pdf_path)
        
        return pages
    
    def _fallback_extraction(self, pdf_path: str) -> List[PageExtraction]:
        """Fallback to pdfplumber if PyMuPDF fails"""
        import pdfplumber
        pages = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, start=1):
                    text = page.extract_text()
                    if text:
                        pages.append(PageExtraction(
                            page_num=page_num,
                            text=self._clean_text(text)
                        ))
        except Exception as e:
            logger.error(f"Fallback extraction also failed: {e}")
        
        return pages
    
    def _clean_text(self, text: str) -> str:
        """Remove noise"""
        import re
        # Remove excessive whitespace
        text = re.sub(r'\s+', ' ', text)
        # Remove standalone page numbers
        text = re.sub(r'^\s*\d+\s*$', '', text, flags=re.MULTILINE)
        return text.strip()
    
    def _detect_sections_per_page(self, pages: List[PageExtraction]) -> List[PageExtraction]:
        """
        Detect which section each page belongs to.
        
        Strategy: Scan for section headers, track current section
        """
        import re
        current_section = "General"
        
        for page in pages:
            # Check if this page starts a new section
            lines = page.text.split('\n')
            for line in lines[:10]:  # Check first 10 lines
                line_clean = line.strip().lower()
                if len(line_clean) > 100:  # Too long to be a header
                    continue
                
                for pattern, section_name in self.SECTION_PATTERNS:
                    if re.match(pattern, line_clean):
                        current_section = section_name
                        logger.debug(f"Page {page.page_num}: Section = {section_name}")
                        break
            
            page.section = current_section
        
        return pages
    
    def _chunk_with_pages(
        self, 
        pages: List[PageExtraction], 
        file_id: int, 
        user_id: int
    ) -> List[Dict]:
        """
        Chunk text while preserving page information.
        
        CRITICAL: Each chunk must know its page range.
        """
        chunks = []
        chunk_index = 0
        
        # Process pages in groups by section for better chunk boundaries
        current_section_pages = []
        current_section = None
        
        for page in pages:
            if page.section != current_section and current_section_pages:
                # Section changed, flush accumulated pages
                section_chunks = self._chunk_section(
                    current_section_pages, 
                    file_id, 
                    user_id, 
                    chunk_index
                )
                chunks.extend(section_chunks)
                chunk_index += len(section_chunks)
                current_section_pages = []
            
            current_section = page.section
            current_section_pages.append(page)
        
        # Flush final section
        if current_section_pages:
            section_chunks = self._chunk_section(
                current_section_pages, 
                file_id, 
                user_id, 
                chunk_index
            )
            chunks.extend(section_chunks)
        
        return chunks
    
    def _chunk_section(
        self, 
        section_pages: List[PageExtraction], 
        file_id: int, 
        user_id: int, 
        start_index: int
    ) -> List[Dict]:
        """
        Chunk a group of pages from same section.
        """
        # Concatenate all text from these pages
        full_text = " ".join(p.text for p in section_pages)
        section_name = section_pages[0].section if section_pages else "General"
        
        # Get page range
        page_start = section_pages[0].page_num
        page_end = section_pages[-1].page_num
        
        # Classify importance
        importance = self._classify_importance(section_name)
        
        # Split into chunks
        if len(full_text) > self.chunk_size:
            text_chunks = self.splitter.split_text(full_text)
        else:
            text_chunks = [full_text]
        
        # Build chunk objects
        chunks = []
        for idx, text_chunk in enumerate(text_chunks):
            # Calculate page range for this chunk
            # Simple heuristic: distribute pages across chunks
            chars_per_page = len(full_text) / len(section_pages)
            chunk_start_char = sum(len(text_chunks[i]) for i in range(idx))
            chunk_end_char = chunk_start_char + len(text_chunk)
            
            chunk_page_start = page_start + int(chunk_start_char / chars_per_page)
            chunk_page_end = page_start + int(chunk_end_char / chars_per_page)
            
            # Clamp to actual range
            chunk_page_start = max(page_start, min(chunk_page_start, page_end))
            chunk_page_end = max(page_start, min(chunk_page_end, page_end))
            
            chunks.append({
                "text": text_chunk,
                "metadata": {
                    "file_id": file_id,
                    "user_id": user_id,
                    "chunk_index": start_index + idx,
                    "page_start": chunk_page_start,
                    "page_end": chunk_page_end,
                    "section": section_name,
                    "importance": importance,
                    "source": "page_aware_parser"
                }
            })
        
        return chunks
    
    def _classify_importance(self, section: str) -> str:
        """Classify section importance"""
        section_lower = section.lower()
        
        if any(s in section_lower for s in ['abstract', 'introduction', 'conclusion']):
            return 'core_contribution'
        elif any(s in section_lower for s in ['method', 'approach', 'model']):
            return 'methodology'
        elif any(s in section_lower for s in ['experiment', 'result', 'evaluation']):
            return 'experiment'
        else:
            return 'general'


# Convenience function
def parse_pdf_with_pages(pdf_path: str, file_id: int, user_id: int) -> List[Dict]:
    """Parse PDF and return chunks with page metadata"""
    parser = PageAwarePDFParser()
    return parser.parse(pdf_path, file_id, user_id)

</code>

backend/app/storage/__init__.py:
<code>
# Storage package

</code>

backend/app/storage/minio_client.py:
<code>
from minio import Minio
from minio.error import S3Error
from ..config import settings
import io
import time
import logging
import functools
from typing import Union, Optional, BinaryIO
import urllib3

logger = logging.getLogger(__name__)

def retry_operation(max_retries=3, delay=1.0, backoff=2.0):
    """
    Decorator for robust retry logic with exponential backoff.
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            retries = 0
            current_delay = delay
            last_exception = None
            
            while retries < max_retries:
                try:
                    return func(*args, **kwargs)
                except (S3Error, urllib3.exceptions.HTTPError) as e:
                    retries += 1
                    last_exception = e
                    if retries == max_retries:
                        break
                    
                    logger.warning(
                        f"MinIO Op Failed ({func.__name__}): {e}. "
                        f"Retrying {retries}/{max_retries} in {current_delay}s..."
                    )
                    time.sleep(current_delay)
                    current_delay *= backoff
            
            logger.error(f"MinIO Op Permanently Failed ({func.__name__}): {last_exception}")
            raise last_exception
        return wrapper
    return decorator

class MinioClient:
    """
    Production-Grade Object Storage Client.
    Wrapper around MinIO S3 SDK with robust error handling and retries.
    """
    
    def __init__(self):
        try:
            # Custom HTTP client for connection pooling
            http_client = urllib3.PoolManager(
                timeout=settings.MINIO_TIMEOUT if hasattr(settings, 'MINIO_TIMEOUT') else 5.0,
                retries=urllib3.Retry(
                    total=3,
                    backoff_factor=0.2,
                    status_forcelist=[500, 502, 503, 504]
                )
            )
            
            self.client = Minio(
                settings.MINIO_ENDPOINT,
                access_key=settings.MINIO_ACCESS_KEY,
                secret_key=settings.MINIO_SECRET_KEY,
                secure=False,  # Set to True in Prod with SSL
                http_client=http_client
            )
            self.bucket_name = "ai-cloud-drive"
            self._ensure_bucket_exists()
            logger.info(f"MinIO Client initialized for bucket: {self.bucket_name}")
            
        except Exception as e:
            logger.critical(f"MinIO Initialization Failed: {e}")
            raise

    @retry_operation(max_retries=3)
    def _ensure_bucket_exists(self):
        if not self.client.bucket_exists(self.bucket_name):
            self.client.make_bucket(self.bucket_name)

    @retry_operation(max_retries=3)
    def upload_file(self, 
                   file_data: Union[bytes, BinaryIO], 
                   file_name: str, 
                   content_type: str, 
                   user_id: int) -> str:
        """
        Securely upload file to user-scoped path.
        Returns: object_name
        """
        object_name = f"user_{user_id}/{file_name}"
        
        # Prepare stream
        if isinstance(file_data, bytes):
            data = io.BytesIO(file_data)
            length = len(file_data)
        else:
            data = file_data
            file_data.seek(0, 2)
            length = file_data.tell()
            file_data.seek(0)
            
        self.client.put_object(
            self.bucket_name,
            object_name,
            data,
            length,
            content_type=content_type,
            metadata={
                "user_id": str(user_id),
                "original_name": file_name
            }
        )
        logger.info(f"Uploaded {length} bytes to {object_name}")
        return object_name

    @retry_operation(max_retries=2)
    def get_file_url(self, object_name: str, expiry_hours: int = 1) -> str:
        """Generate presigned URL for secure frontend access."""
        from datetime import timedelta
        return self.client.presigned_get_object(
            self.bucket_name, 
            object_name,
            expires=timedelta(hours=expiry_hours)
        )

    @retry_operation(max_retries=3)
    def get_file_content(self, object_name: str):
        """Stream file content for processing."""
        return self.client.get_object(self.bucket_name, object_name)

    @retry_operation(max_retries=3)
    def delete_file(self, object_name: str):
        """Remove file permanently."""
        self.client.remove_object(self.bucket_name, object_name)
        logger.info(f"Deleted object: {object_name}")

# Singleton
minio_client = MinioClient()

</code>

backend/app/routes/auth.py:
<code>
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from fastapi.security import OAuth2PasswordRequestForm
from datetime import datetime, timedelta
from .. import schemas, models, database, auth
from ..validators import validate_password_strength, validate_email_domain
from ..logging_config import logger
from pydantic import BaseModel

router = APIRouter(
    prefix="/auth",
    tags=["auth"]
)

@router.post("/register", response_model=schemas.User)
def register(user: schemas.UserCreate, db: Session = Depends(database.get_db)):
    # Validate password strength
    try:
        validate_password_strength(user.password)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # Check for disposable emails
    try:
        validate_email_domain(user.email)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # Check if email exists
    db_user = db.query(models.User).filter(models.User.email == user.email).first()
    if db_user:
        raise HTTPException(status_code=400, detail="Email already registered")
    
    hashed_password = auth.get_password_hash(user.password)
    
    # Create user with verification token if email verification is enabled
    from ..config import settings
    if settings.REQUIRE_EMAIL_VERIFICATION:
        import secrets
        verification_token = secrets.token_urlsafe(32)
        db_user = models.User(
            email=user.email,
            hashed_password=hashed_password,
            is_verified=False,
            verification_token=verification_token,
            verification_sent_at=datetime.utcnow()
        )
        
        # Send verification email
        from ..email.service import email_service
        verification_link = f"http://localhost:3000/verify-email?token={verification_token}"
        
        if settings.SMTP_USERNAME and settings.SMTP_PASSWORD:
            email_service.send_verification_email(user.email, verification_link)
            logger.info(f"Verification email sent to: {user.email}")
        else:
            logger.warning(f"Email not configured. Verification link: {verification_link}")
    else:
        # Auto-verify if email verification is disabled
        db_user = models.User(
            email=user.email,
            hashed_password=hashed_password,
            is_verified=True
        )
    
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    
    logger.info(f"New user registered: {user.email}")
    return db_user

@router.post("/login", response_model=schemas.Token)
def login(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(database.get_db)):
    user = db.query(models.User).filter(models.User.email == form_data.username).first()
    if not user or not auth.verify_password(form_data.password, user.hashed_password):
        logger.warning(f"Failed login attempt for: {form_data.username}")
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    if not user.is_active:
        raise HTTPException(status_code=400, detail="Account is deactivated")
    
    # Check email verification if required
    from ..config import settings
    if settings.REQUIRE_EMAIL_VERIFICATION and not user.is_verified:
        raise HTTPException(
            status_code=403, 
            detail="ğŸ“§ Please verify your email first! Check your inbox for a verification link from Cloud Drive. Can't find it? Check spam folder or request a new link."
        )
    
    # Update last login
    user.last_login = datetime.utcnow()
    db.commit()

    access_token_expires = timedelta(minutes=auth.settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": user.email, "user_id": user.id}, 
        expires_delta=access_token_expires
    )
    
    logger.info(f"User logged in: {user.email}")
    return {"access_token": access_token, "token_type": "bearer"}

@router.get("/me", response_model=schemas.User)
def get_current_user_info(current_user: models.User = Depends(auth.get_current_user)):
    """Get current user information"""
    return current_user

# Admin Auth
class AdminLogin(BaseModel):
    username: str
    password: str

@router.post("/admin/login")
def admin_login(creds: AdminLogin):
    if creds.username != auth.settings.ADMIN_USERNAME or creds.password != auth.settings.ADMIN_PASSWORD:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect admin credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # Create token with admin scope/flag (for now just a separate token key or subject prefix)
    access_token_expires = timedelta(minutes=auth.settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": f"admin:{creds.username}", "role": "admin"}, 
        expires_delta=access_token_expires
    )
    return {"access_token": access_token, "token_type": "bearer"}

# Email Verification
@router.get("/verify-email")
def verify_email(token: str, db: Session = Depends(database.get_db)):
    """Verify user email with token."""
    user = db.query(models.User).filter(
        models.User.verification_token == token
    ).first()
    
    if not user:
        raise HTTPException(status_code=400, detail="Invalid verification token")
    
    # Check token expiration (24 hours)
    from ..config import settings
    if user.verification_sent_at:
        expiry_hours = settings.VERIFICATION_TOKEN_EXPIRE_HOURS
        token_age = datetime.utcnow() - user.verification_sent_at
        if token_age.total_seconds() > expiry_hours * 3600:
            raise HTTPException(status_code=400, detail="Verification token expired")
    
    # Verify user
    user.is_verified = True
    user.verification_token = None
    user.verification_sent_at = None
    db.commit()
    
    logger.info(f"User verified: {user.email}")

    # Auto-login: Generate access token
    access_token_expires = timedelta(minutes=auth.settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": user.email, "user_id": user.id}, 
        expires_delta=access_token_expires
    )
    
    return {
        "message": "Email verified successfully!",
        "access_token": access_token, 
        "token_type": "bearer"
    }

@router.post("/resend-verification")
def resend_verification(email: str, db: Session = Depends(database.get_db)):
    """Resend verification email."""
    user = db.query(models.User).filter(models.User.email == email).first()
    
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    if user.is_verified:
        raise HTTPException(status_code=400, detail="Email already verified")
    
    # Generate new token
    import secrets
    user.verification_token = secrets.token_urlsafe(32)
    user.verification_sent_at = datetime.utcnow()
    db.commit()
    
    # Send email
    from ..email.service import email_service
    from ..config import settings
    verification_link = f"http://localhost:3000/verify-email?token={user.verification_token}"
    
    if settings.SMTP_USERNAME and settings.SMTP_PASSWORD:
        email_service.send_verification_email(email, verification_link)
        logger.info(f"Verification email resent to: {email}")
        return {"message": "Verification email sent!"}
    else:
        logger.warning(f"Email not configured. Verification link: {verification_link}")
        return {"message": "Email not configured", "link": verification_link}

@router.get("/me")
def read_users_me(current_user: models.User = Depends(auth.get_current_user), db: Session = Depends(database.get_db)):
    """Get current user profile."""
    # Count files efficiently
    file_count = db.query(models.File).filter(models.File.owner_id == current_user.id).count()
    
    return {
        "id": current_user.id,
        "email": current_user.email,
        "is_verified": current_user.is_verified,
        "created_at": current_user.created_at,
        "role": "admin" if current_user.id == 0 else "user",
        "file_count": file_count
    }

</code>

backend/app/routes/google_auth.py:
<code>
"""
Google OAuth Authentication Routes

Provides endpoints for Google Sign-In authentication.
"""

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import RedirectResponse
from pydantic import BaseModel
from sqlalchemy.orm import Session
from authlib.integrations.starlette_client import OAuth
from authlib.jose import jwt
from datetime import datetime, timedelta
import httpx

from .. import database, models, auth
from ..config import settings

router = APIRouter(prefix="/auth/google", tags=["google-auth"])

# Initialize OAuth
oauth = OAuth()
oauth.register(
    name='google',
    client_id=settings.GOOGLE_CLIENT_ID,
    client_secret=settings.GOOGLE_CLIENT_SECRET,
    server_metadata_url='https://accounts.google.com/.well-known/openid-configuration',
    client_kwargs={'scope': 'openid email profile'}
)


class GoogleAuthRequest(BaseModel):
    """Request model for Google credential verification."""
    credential: str  # Google JWT token


@router.get("/login")
async def google_login():
    """
    Initiate Google OAuth flow.
    Redirects user to Google sign-in page.
    """
    if not settings.GOOGLE_CLIENT_ID or not settings.GOOGLE_CLIENT_SECRET:
        raise HTTPException(
            status_code=500,
            detail="Google OAuth not configured. Please set GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET."
        )
    
    redirect_uri = settings.GOOGLE_REDIRECT_URI
    return await oauth.google.authorize_redirect(redirect_uri)


@router.get("/callback")
async def google_callback(code: str, db: Session = Depends(database.get_db)):
    """
    Handle OAuth callback from Google.
    Exchanges code for user info and creates/updates user.
    """
    try:
        # Exchange code for token
        token = await oauth.google.authorize_access_token(code=code)
        
        # Get user info from Google
        user_info = token.get('userinfo')
        if not user_info:
            raise HTTPException(status_code=400, detail="Failed to get user info from Google")
        
        # Extract user data
        google_id = user_info.get('sub')
        email = user_info.get('email')
        name = user_info.get('name')
        picture = user_info.get('picture')
        
        if not google_id or not email:
            raise HTTPException(status_code=400, detail="Invalid user data from Google")
        
        # Find or create user
        user = db.query(models.User).filter(models.User.google_id == google_id).first()
        
        if not user:
            # Check if user exists with this email (from old auth)
            user = db.query(models.User).filter(models.User.email == email).first()
            if user:
                # Link Google account to existing user
                user.google_id = google_id
                user.is_verified = True
            else:
                # Create new user
                user = models.User(
                    email=email,
                    google_id=google_id,
                    name=name,
                    is_verified=True,  # Auto-verified via Google
                    is_active=True
                )
                db.add(user)
        
        # Update user info
        if name and not user.name:
            user.name = name
        user.last_login = datetime.utcnow()
        
        db.commit()
        db.refresh(user)
        
        # Create access token
        access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
        access_token = auth.create_access_token(
            data={"sub": user.email},
            expires_delta=access_token_expires
        )
        
        # Redirect to frontend with token
        return RedirectResponse(
            url=f"http://localhost:3000?token={access_token}"
        )
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"OAuth failed: {str(e)}")


@router.post("/verify")
async def verify_google_token(
    request: GoogleAuthRequest,
    db: Session = Depends(database.get_db)
):
    """
    Verify Google JWT token (for frontend direct integration).
    This is used when using Google Sign-In JavaScript library.
    """
    try:
        # Verify the Google JWT token
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"https://oauth2.googleapis.com/tokeninfo?id_token={request.credential}"
            )
            
            if response.status_code != 200:
                raise HTTPException(status_code=401, detail="Invalid Google token")
            
            user_info = response.json()
            
            # Verify token is for our app
            if user_info.get('aud') != settings.GOOGLE_CLIENT_ID:
                raise HTTPException(status_code=401, detail="Token not for this application")
            
            # Extract user data
            google_id = user_info.get('sub')
            email = user_info.get('email')
            name = user_info.get('name')
            picture = user_info.get('picture')
            email_verified = user_info.get('email_verified', False)
            
            if not google_id or not email:
                raise HTTPException(status_code=400, detail="Invalid user data")
            
            # Find or create user
            user = db.query(models.User).filter(models.User.google_id == google_id).first()
            
            if not user:
                # Check if email exists
                user = db.query(models.User).filter(models.User.email == email).first()
                if user:
                    # Link Google account
                    user.google_id = google_id
                    user.is_verified = True
                else:
                    # Create new user
                    user = models.User(
                        email=email,
                        google_id=google_id,
                        name=name,
                        is_verified=True,
                        is_active=True
                    )
                    db.add(user)
            
            # Update info
            if name and not user.name:
                user.name = name
            user.last_login = datetime.utcnow()
            
            db.commit()
            db.refresh(user)
            
            # Create our access token
            access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
            access_token = auth.create_access_token(
                data={"sub": user.email},
                expires_delta=access_token_expires
            )
            
            return {
                "access_token": access_token,
                "token_type": "bearer",
                "user": {
                    "email": user.email,
                    "name": user.name
                }
            }
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Verification failed: {str(e)}")

</code>

backend/app/routes/files.py:
<code>
from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File as FastAPIFile, Response
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import List
from .. import schemas, models, database, auth
from ..storage.minio_client import minio_client
from ..tasks.celery_app import process_file_task
import mimetypes

router = APIRouter(
    prefix="/api",
    tags=["files"]
)

@router.post("/upload", response_model=schemas.File)
async def upload_file(
    file: UploadFile = FastAPIFile(...),
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    # Permissions Check
    if not current_user.can_upload:
        raise HTTPException(status_code=403, detail="Uploads are disabled for your account")

    # Rate Limit: File Count
    MAX_FILES_COUNT = 50
    current_file_count = db.query(models.File).filter(models.File.owner_id == current_user.id).count()
    if current_file_count >= MAX_FILES_COUNT:
        raise HTTPException(status_code=400, detail=f"File limit reached ({MAX_FILES_COUNT} files). Please delete some files.")

    # Constants
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    ALLOWED_TYPES = ["application/pdf", "text/plain", "text/markdown", "text/x-markdown"]
    ALLOWED_EXTENSIONS = [".pdf", ".txt", ".md"]
    
    # Validate file extension
    file_ext = "." + file.filename.split(".")[-1].lower() if "." in file.filename else ""
    if file_ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(status_code=400, detail=f"File type not allowed. Allowed: {', '.join(ALLOWED_EXTENSIONS)}")

    # Read file content
    file_content = await file.read()
    file_size = len(file_content)
    
    # Validate file size
    if file_size > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail=f"File too large. Maximum size: 50MB")
    
    if file_size == 0:
        raise HTTPException(status_code=400, detail="Cannot upload empty file")

    # Upload to MinIO
    try:
        object_name = minio_client.upload_file(
            file_data=file_content,
            file_name=file.filename,
            content_type=file.content_type,
            user_id=current_user.id
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to upload to storage: {str(e)}")

    # Save metadata to DB
    db_file = models.File(
        filename=file.filename,
        file_path=object_name,
        content_type=file.content_type,
        size=file_size,
        owner_id=current_user.id,
        is_indexed=False 
    )
    db.add(db_file)
    db.commit()
    db.refresh(db_file)

    # Trigger Async Task (Phase 5)
    process_file_task.delay(db_file.id, object_name, file.content_type, current_user.id)

    return db_file

@router.get("/files", response_model=List[schemas.File])
def get_files(
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    files = db.query(models.File).filter(models.File.owner_id == current_user.id).all()
    return files

@router.get("/download/{file_id}")
def download_file(
    file_id: int,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    # Admin can download any file, regular users can only download their own
    file = db.query(models.File).filter(models.File.id == file_id).first()
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    # Check if user is admin or file owner
    # Admin users have email format "admin:username"
    from ..config import settings
    is_admin = (
        current_user.email == settings.ADMIN_USERNAME or
        current_user.email == f"admin:{settings.ADMIN_USERNAME}" or
        current_user.email.startswith("admin:")
    )
    
    if not is_admin and file.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="Not authorized to download this file")


    try:
        response = minio_client.get_file_content(file.file_path)
        
        # Determine media type using standard library or fallback to application/octet-stream
        media_type = file.content_type or "application/octet-stream"
        
        return StreamingResponse(
            response, 
            media_type=media_type,
            headers={"Content-Disposition": f'attachment; filename="{file.filename}"'}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to download file: {str(e)}")

@router.delete("/delete/{file_id}")
def delete_file(
    file_id: int,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    file = db.query(models.File).filter(models.File.id == file_id, models.File.owner_id == current_user.id).first()
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    # Delete from MinIO
    try:
        minio_client.delete_file(file.file_path)
    except Exception as e:
        print(f"Warning: Failed to delete from MinIO: {e}")
        # Continue to delete from DB even if MinIO fails (orphaned check later?)
    
    # Delete from DB
    db.delete(file)
    db.commit()
    
    return {"message": "File deleted successfully"}

</code>

backend/app/routes/query.py:
<code>
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
import datetime
import logging
from .. import database, models, auth
from ..rag import engine
from ..rag.llm import generate_response

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/api",
    tags=["query"]
)

class QueryRequest(BaseModel):
    query: str
    file_ids: Optional[List[int]] = None  # Optional list of file IDs to search

class Citation(BaseModel):
    source_id: str
    text: str
    page: int
    section: str
    file_id: int
    score: float

class QueryResponse(BaseModel):
    answer: str
    citations: List[Citation]
    latency_ms: float
    trace_id: str
    contexts: List[str] # Legacy for audit
    metadata: Optional[Dict[str, Any]] = None

@router.post("/query", response_model=QueryResponse)
def query_documents(
    request: QueryRequest,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    import time
    import re
    import uuid
    from ..rag.conversational_handler import conversational_handler
    
    start_time = time.time()
    trace_id = str(uuid.uuid4())
    
    try:
        # 0. Check if query is conversational (greetings, help, etc.)
        if conversational_handler.is_conversational(request.query):
            conversational_response = conversational_handler.get_response(request.query)
            if conversational_response:
                # Return direct response without retrieval
                latency = (time.time() - start_time) * 1000  # Convert to ms
                return QueryResponse(
                    answer=conversational_response,
                    citations=[],
                    contexts=[],
                    trace_id=trace_id,
                    latency_ms=latency
                )
        
        # 1. Retrieve relevant chunks
        t0 = time.time()
        results = engine.query_documents(
            request.query, 
            user_id=current_user.id,
            file_ids=request.file_ids
        )
        t_retrieval = time.time() - t0
        
        citations = []
        citation_map = {}
        
        if not results:
            answer = "I could not find any relevant information in your documents."
        else:
            # Prepare Citation Map for Lookup
            for i, doc in enumerate(results):
                meta = doc.get("metadata", {})
                fid = meta.get("file_id", 0)
                # Try sub_chunk_index first, else chunk_index, else fallback
                cid = meta.get("sub_chunk_index", meta.get("chunk_index", i+1))
                source_id = f"{fid}:{cid}"
                
                c_obj = Citation(
                    source_id=source_id,
                    text=doc["content"],
                    page=meta.get("page", meta.get("page_number", 1)),
                    section=meta.get("section", "General"),
                    file_id=fid,
                    score=doc.get("score", 0.0)
                )
                citation_map[source_id] = c_obj
                # Add to all candidates (we filter later or send all)
                # For now, we'll send ALL retrieved as candidates, so UI can show "Sources Found"
                # BUT the answer will only link to specific ones.
            
            # 2. Generate answer (The formatting is handled in llm.py)
            t1 = time.time()
            # We pass the raw results, llm.generate_response handles the [Source ID] formatting/context
            answer = generate_response(request.query, results)
            t_generation = time.time() - t1
            
            # 3. Parse Used Citations from Answer
            # Regex for [fid:cid]
            used_ids = set(re.findall(r'\[(\d+:\d+)\]', answer))
            
            # If citations found, prioritize them at the top of the list
            # We will send ALL retrieved citations, but maybe mark them?
            # User wants "Evidence Schema".
            # Let's populate 'citations' with everything retrieved, but sorted by usage?
            # actually, let's just send everything retrieved so the UI has context.
            # Convert map to list
            citations = list(citation_map.values())
            
            # Optional: Start Log Verification
            # (Audit logic remains same)

        total_time = time.time() - start_time
        
        # Log Metrics
        from ..rag.metrics import metrics
        unsupported = 1 if "not stated" in answer.lower() else 0
        metrics.log_query(total_time, success=bool(results), unsupported_claims=unsupported)
        
        # **SAVE CHAT TO DATABASE**
        try:
            chat_entry = models.ChatHistory(
                user_id=current_user.id,
                query=request.query,
                answer=answer,
                timestamp=datetime.datetime.now(datetime.timezone.utc)
            )
            db.add(chat_entry)
            db.commit()
        except Exception as log_err:
            logger.error(f"Failed to log chat: {log_err}")
            # Don't fail the entire request if logging fails
        
        return {
            "answer": answer,
            "citations": citations,
            "latency_ms": total_time * 1000,
            "trace_id": trace_id,
            "contexts": [r["content"] for r in results],
            "metadata": {
                "retrieval_time": t_retrieval if results else 0,
                "generation_time": t_generation if results else 0,
                "total_time": total_time
            }
        }
    except Exception as e:
        # Log Failure
        from ..rag.metrics import metrics
        metrics.log_query(time.time() - start_time, success=False, unsupported_claims=0)
        raise HTTPException(status_code=500, detail=f"Query failed: {str(e)}")

class EvaluateRequest(BaseModel):
    question: str
    answer: str
    contexts: List[str]

@router.post("/evaluate")
def evaluate_response(req: EvaluateRequest):
    """
    Run RAGAS Faithfulness check on a specific Q&A pair.
    """
    try:
        import os
        from ragas import evaluate
        from ragas.metrics import faithfulness
        from datasets import Dataset
        from langchain_groq import ChatGroq
        
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            raise HTTPException(status_code=500, detail="GROQ_API_KEY not set")
            
        # 1. Configure LLM
        # Ragas needs an LLM    # Use smaller model to save tokens/latency
        llm = ChatGroq(model="llama-3.1-8b-instant", api_key=api_key)
        
        # 2. Format data
        data = {
            'question': [req.question],
            'answer': [req.answer],
            'contexts': [req.contexts], 
            # Ground truth optional for faithfulness
        }
        dataset = Dataset.from_dict(data)
        
        # 3. Optimized Audit: Generate Score AND Explanation in one pass (Latency < 3s)
        audit_prompt = f"""
You are a critical RAG Auditor. Your job is to find flaws, not excuse them.

CONTEXTS:
{req.contexts}

ANSWER:
{req.answer}

INSTRUCTIONS (Follow Step-by-Step):
1. **Find at least ONE flaw**. Look for:
   - Claims not in context (hallucination)
   - Stating "not provided" when context HAS the info (negative hallucination)
   - Technical errors (e.g., Input vs Output confusion)
   - Overly vague summaries that add no value
2. **If truly perfect (rare)**, explain why every claim is verified.
3. **Score conservatively**:
   - 0.9-1.0: Exceptional. Every claim verified, no flaws.
   - 0.7-0.8: Good. Minor omissions or rewording, but accurate.
   - 0.5-0.6: Acceptable. Some unverified claims or vagueness.
   - <0.5: Poor. Significant errors or hallucinations.

FORMAT AS JSON:
{{
    "flaws_found": ["<flaw1>", "<flaw2>"],
    "score": <float>,
    "explanation": "<brief reasoning>"
}}
"""
        
        # Invoke LLM
        response = llm.invoke(audit_prompt).content
        
        # Parse JSON output (Handle potential formatting noise)
        import json
        import re
        
        try:
            # Extract JSON block if wrapped in code fences
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                data = json.loads(json_match.group(0))
            else:
                data = json.loads(response)
                
            score = data.get("score", 0.0)
            flaws = data.get("flaws_found", [])
            explanation = data.get("explanation", "Could not parse explanation.")
            
            # Build comprehensive note
            if flaws:
                flaws_text = "Flaws Found: " + "; ".join(flaws) + ". "
            else:
                flaws_text = ""
            full_explanation = flaws_text + explanation
            
        except Exception as e:
            print(f"Audit Parse Error: {e} | Response: {response}")
            score = 0.5
            full_explanation = "Error parsing auditor response. Please try again."

        return {
            "faithfulness": score,
            "explanation": full_explanation
        }
        
    except Exception as e:
        print(f"Evaluation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

class CompareRequest(BaseModel):
    doc_a_id: int
    doc_b_id: int
    aspect: str # e.g. "Methodology", "Results"

@router.post("/compare")
def compare_documents_endpoint(
    req: CompareRequest,
    current_user: models.User = Depends(auth.get_current_user)
):
    """
    God-Level Feature: A vs B Comparison.
    Retrieves aspect-specific sections from both docs and synthesizes a contrastive report.
    """
    try:
        from ..rag.compare_engine import compare_engine
        
        # Verify ownership (mock check for now)
        if current_user.id == 0: pass 
        
        result = compare_engine.compare_documents(req.doc_a_id, req.doc_b_id, req.aspect)
        
        if "error" in result:
             raise HTTPException(status_code=404, detail=result["error"])
             
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


</code>

backend/app/routes/profile.py:
<code>
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from sqlalchemy.orm import Session
from .. import database, models, schemas, auth
from ..storage import minio_client
import uuid
import io

router = APIRouter(
    prefix="/api/profile",
    tags=["profile"]
)

@router.get("", response_model=schemas.User)
def get_profile(current_user: models.User = Depends(auth.get_current_user)):
    """Get current user profile"""
    return current_user

@router.put("", response_model=schemas.User)
def update_profile(
    profile: schemas.ProfileUpdate,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(database.get_db)
):
    """Update user profile name"""
    if profile.name is not None:
        current_user.name = profile.name
    
    db.commit()
    db.refresh(current_user)
    return current_user

@router.post("/photo")
async def upload_profile_photo(
    file: UploadFile = File(...),
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(database.get_db)
):
    """Upload user profile photo to MinIO"""
    # Validate file type
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="File must be an image")
    
    # Generate unique filename
    file_ext = file.filename.split('.')[-1] if '.' in file.filename else 'jpg'
    unique_filename = f"profiles/{current_user.id}/{uuid.uuid4()}.{file_ext}"
    
    try:
        # Delete old profile photo if exists
        if current_user.profile_photo:
            try:
                minio_client.remove_object("ai-drive", current_user.profile_photo)
            except:
                pass  # Ignore if old photo doesn't exist
        
        # Upload to MinIO
        file_content = await file.read()
        minio_client.put_object(
            "ai-drive",
            unique_filename,
            io.BytesIO(file_content),
            length=len(file_content),
            content_type=file.content_type
        )
        
        # Update user record
        current_user.profile_photo = unique_filename
        db.commit()
        
        return {"message": "Profile photo uploaded successfully", "photo_path": unique_filename}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

@router.delete("/photo")
def delete_profile_photo(
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(database.get_db)
):
    """Delete user profile photo"""
    if not current_user.profile_photo:
        raise HTTPException(status_code=404, detail="No profile photo to delete")
    
    try:
        # Delete from MinIO
        minio_client.remove_object("ai-drive", current_user.profile_photo)
        
        # Update user record
        current_user.profile_photo = None
        db.commit()
        
        return {"message": "Profile photo deleted successfully"}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Delete failed: {str(e)}")

@router.get("/photo/{user_id}")
def get_profile_photo(user_id: int, db: Session = Depends(database.get_db)):
    """Get profile photo URL for a user"""
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user or not user.profile_photo:
        raise HTTPException(status_code=404, detail="Profile photo not found")
    
    try:
        # Generate presigned URL (valid for 1 hour)
        url = minio_client.presigned_get_object("ai-drive", user.profile_photo, expires=3600)
        return {"photo_url": url}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get photo: {str(e)}")

</code>

backend/app/routes/__init__.py:
<code>
# Routes package

</code>

backend/app/routes/admin.py:
<code>

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
from datetime import datetime, timedelta
from .. import database, models, schemas, auth
from pydantic import BaseModel

router = APIRouter(
    prefix="/api/admin",
    tags=["admin"],
    dependencies=[Depends(auth.get_admin_user)]
)

# Admin Schemas (Internal use for now)
class AdminUserStats(schemas.User):
    files_count: int
    queries_total: int
    queries_24h: int
    storage_used: int
    failed_queries: int
    last_login: datetime | None
    created_at: datetime | None
    can_upload: bool
    is_verified: bool

    class Config:
        from_attributes = True

class AuditLogView(BaseModel):
    id: int
    timestamp: datetime
    actor_email: str
    action: str
    target_id: int | None
    target_type: str | None
    metadata_json: str | None

    class Config:
        from_attributes = True

class AdminFileView(BaseModel):
    id: int
    filename: str
    size: int
    upload_date: datetime
    content_type: str | None
    owner_email: str

    class Config:
        from_attributes = True

class AdminChatView(BaseModel):
    id: int
    query: str
    answer: str | None
    timestamp: datetime
    user_email: str

    class Config:
        from_attributes = True

# --- Helpers ---
def log_audit(db: Session, actor_id: int, action: str, target_id: int = None, target_type: str = None, meta: dict = None):
    import json
    log = models.AuditLog(
        actor_id=actor_id,
        action=action,
        target_id=target_id,
        target_type=target_type,
        metadata_json=json.dumps(meta) if meta else None
    )
    db.add(log)
    db.commit()

# --- Endpoints ---

@router.get("/users", response_model=List[AdminUserStats])
def get_all_users(
    skip: int = 0, 
    limit: int = 100, 
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_admin_user)
):
    users = db.query(models.User).order_by(models.User.created_at.desc()).offset(skip).limit(limit).all()
    
    # Enrichment
    results = []
    now = datetime.utcnow()
    day_ago = now - timedelta(days=1)

    for u in users:
        u_dict = u.__dict__
        u_dict['files_count'] = len(u.files)
        u_dict['storage_used'] = sum(f.size for f in u.files)
        u_dict['queries_total'] = len(u.chats)
        # Inefficient loop for 24h, but ok for small scale. 
        # For production, use optimized SQL query.
        u_dict['queries_24h'] = sum(1 for c in u.chats if c.timestamp > day_ago)
        u_dict['failed_queries'] = sum(1 for c in u.chats if c.answer and c.answer.startswith("Error"))
        results.append(u_dict)
        
    return results

@router.get("/files", response_model=List[AdminFileView])
def get_all_files(
    skip: int = 0, 
    limit: int = 100, 
    db: Session = Depends(database.get_db)
):
    files = db.query(models.File).order_by(models.File.upload_date.desc()).offset(skip).limit(limit).all()
    
    results = []
    for f in files:
        results.append({
            "id": f.id,
            "filename": f.filename,
            "size": f.size,
            "upload_date": f.upload_date,
            "content_type": f.content_type,
            "owner_email": f.owner.email if f.owner else "Unknown"
        })
    return results

@router.get("/chats", response_model=List[AdminChatView])
def get_all_chats(
    skip: int = 0, 
    limit: int = 100, 
    db: Session = Depends(database.get_db)
):
    chats = db.query(models.ChatHistory).order_by(models.ChatHistory.timestamp.desc()).offset(skip).limit(limit).all()
    
    results = []
    for c in chats:
        results.append({
            "id": c.id,
            "query": c.query,
            "answer": c.answer,
            "timestamp": c.timestamp,
            "user_email": c.user.email if c.user else "Unknown"
        })
    return results

@router.delete("/users/{user_id}")
def delete_user(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    from ..storage.minio_client import minio_client
    
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    user_email = user.email  # Save for audit log
    deleted_files_count = 0
    
    try:
        # 1. Delete user's files from MinIO and database
        user_files = db.query(models.File).filter(models.File.owner_id == user_id).all()
        for file in user_files:
            try:
                # Delete from MinIO storage
                if file.file_path:
                    minio_client.delete_file(file.file_path)
            except Exception as e:
                print(f"Warning: Could not delete file from MinIO: {file.file_path} - {e}")
            # Delete file record from DB
            db.delete(file)
            deleted_files_count += 1
        
        # 2. Delete user's chat history
        db.query(models.ChatHistory).filter(models.ChatHistory.user_id == user_id).delete()
        
        # 3. Delete the user
        db.delete(user)
        db.commit()
        
        # Log the action
        log_audit(db, admin.id, "delete_user", user_id, "user", {
            "email": user_email, 
            "files_deleted": deleted_files_count
        })
        
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=400, detail=f"Cannot delete user: {str(e)}")
        
    return {"message": f"User deleted along with {deleted_files_count} files"}

@router.post("/users/{user_id}/verify")
def verify_user_manually(user_id: int, db: Session = Depends(database.get_db)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    user.is_verified = True
    user.verification_token = None
    db.commit()
    log_audit(db, None, "verify_user", user.id, "user", {"email": user.email}) # Actor ID None (or fetch current user)
    return {"message": f"User {user.email} manually verified"}

@router.post("/users/{user_id}/suspend")
def suspend_user(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.is_active = False
    db.commit()
    log_audit(db, admin.id, "suspend_user", user.id, "user", {"email": user.email})
    return {"message": "User suspended"}

@router.post("/users/{user_id}/unsuspend")
def unsuspend_user(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.is_active = True
    db.commit()
    log_audit(db, admin.id, "unsuspend_user", user.id, "user", {"email": user.email})
    return {"message": "User unsuspended"}

@router.post("/users/{user_id}/disable-upload")
def disable_upload(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.can_upload = False
    db.commit()
    log_audit(db, admin.id, "disable_upload", user.id, "user", {"email": user.email})
    return {"message": "Uploads disabled for user"}

@router.post("/users/{user_id}/enable-upload")
def enable_upload(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.can_upload = True
    db.commit()
    log_audit(db, admin.id, "enable_upload", user.id, "user", {"email": user.email})
    return {"message": "Uploads enabled for user"}

@router.get("/audit-logs", response_model=List[AuditLogView])
def get_audit_logs(skip: int = 0, limit: int = 50, db: Session = Depends(database.get_db)):
    logs = db.query(models.AuditLog).order_by(models.AuditLog.timestamp.desc()).offset(skip).limit(limit).all()
    results = []
    for log in logs:
        results.append({
            "id": log.id,
            "timestamp": log.timestamp,
            "actor_email": log.actor.email if log.actor else "System",
            "action": log.action,
            "target_id": log.target_id,
            "target_type": log.target_type,
            "metadata_json": log.metadata_json
        })
    return results

</code>

backend/app/routes/magic_auth.py:
<code>
"""
Magic Link (Passwordless) Authentication Routes

Provides endpoints for passwordless email-based authentication.
Users receive a secure login link via email.
"""

from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.responses import RedirectResponse
from pydantic import BaseModel, EmailStr
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
import secrets
import logging

from .. import database, models, auth
from ..config import settings
from ..email.service import email_service

router = APIRouter(prefix="/auth/magic-link", tags=["magic-link-auth"])
logger = logging.getLogger(__name__)


class MagicLinkRequest(BaseModel):
    """Request model for magic link generation."""
    email: EmailStr


@router.post("/request")
async def request_magic_link(
    request: MagicLinkRequest,
    db: Session = Depends(database.get_db)
):
    """
    Request a magic link for passwordless login.
    Creates account if doesn't exist.
    """
    email = request.email.lower()
    
    # Find or create user
    user = db.query(models.User).filter(models.User.email == email).first()
    
    if not user:
        # Create new user (passwordless)
        user = models.User(
            email=email,
            is_verified=True,  # Auto-verified via magic link
            is_active=True
        )
        db.add(user)
    
    # Generate secure token
    token = secrets.token_urlsafe(32)
    expires = datetime.utcnow() + timedelta(minutes=15)
    
    # Store token
    user.magic_link_token = token
    user.magic_link_expires = expires
    
    db.commit()
    
    # Generate magic link URL
    # For development, use localhost; for production, use actual domain
    base_url = "http://localhost:3000"  # TODO: Make configurable
    magic_link = f"{base_url}/auth/magic-link/verify?token={token}"
    
    # Send email or log to console
    if settings.SMTP_USERNAME and settings.SMTP_PASSWORD:
        # Send real email
        success = email_service.send_magic_link_email(email, magic_link)
        if not success:
            logger.error(f"Failed to send magic link to {email}")
            # Still return success but log link for development
            logger.info(f"Magic link for {email}: {magic_link}")
    else:
        # Development mode: log to console
        logger.info(f"\n{'='*60}")
        logger.info(f"MAGIC LINK for {email}:")
        logger.info(f"{magic_link}")
        logger.info(f"Expires: {expires}")
        logger.info(f"{'='*60}\n")
    
    return {
        "success": True,
        "message": "Magic link sent! Check your email.",
        "email": email,
        # Include link in response for development (remove in production)
        "magic_link": magic_link if not (settings.SMTP_USERNAME and settings.SMTP_PASSWORD) else None
    }


@router.get("/verify")
async def verify_magic_link(
    token: str,
    db: Session = Depends(database.get_db)
):
    """
    Verify magic link token and log user in.
    Single-use token that expires after 15 minutes.
    """
    # Find user with this token
    user = db.query(models.User).filter(
        models.User.magic_link_token == token
    ).first()
    
    if not user:
        raise HTTPException(
            status_code=400,
            detail="Invalid or expired magic link"
        )
    
    # Check expiration
    if not user.magic_link_expires or user.magic_link_expires < datetime.utcnow():
        # Clear expired token
        user.magic_link_token = None
        user.magic_link_expires = None
        db.commit()
        
        raise HTTPException(
            status_code=400,
            detail="Magic link has expired. Please request a new one."
        )
    
    # Valid token - log user in
    # Clear token (single-use)
    user.magic_link_token = None
    user.magic_link_expires = None
    user.last_login = datetime.utcnow()
    user.is_verified = True
    
    db.commit()
    db.refresh(user)
    
    # Create access token
    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": user.email},
        expires_delta=access_token_expires
    )
    
    # Redirect to frontend with token
    return RedirectResponse(
        url=f"/?token={access_token}&email={user.email}"
    )

</code>

backend/app/routes/share.py:
<code>
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional
import secrets
from .. import models, database, auth
from ..storage.minio_client import minio_client
from fastapi.responses import StreamingResponse

router = APIRouter(
    prefix="/api",
    tags=["share"]
)

class ShareRequest(BaseModel):
    file_id: int
    
class ShareResponse(BaseModel):
    share_url: str
    share_token: str

@router.post("/share", response_model=ShareResponse)
def create_share_link(
    request: ShareRequest,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    """Create a public share link for a file"""
    file = db.query(models.File).filter(
        models.File.id == request.file_id,
        models.File.owner_id == current_user.id
    ).first()
    
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    # Generate or return existing token
    if not file.share_token:
        file.share_token = secrets.token_urlsafe(16)
        db.commit()
    
    return {
        "share_url": f"/api/shared/{file.share_token}",
        "share_token": file.share_token
    }

@router.delete("/share/{file_id}")
def revoke_share_link(
    file_id: int,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    """Revoke a share link"""
    file = db.query(models.File).filter(
        models.File.id == file_id,
        models.File.owner_id == current_user.id
    ).first()
    
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    file.share_token = None
    db.commit()
    
    return {"message": "Share link revoked"}

@router.get("/shared/{share_token}")
def download_shared_file(
    share_token: str,
    db: Session = Depends(database.get_db)
):
    """Download a file via share link (no auth required)"""
    file = db.query(models.File).filter(
        models.File.share_token == share_token
    ).first()
    
    if not file:
        raise HTTPException(status_code=404, detail="Shared file not found or link expired")
    
    try:
        response = minio_client.get_file_content(file.file_path)
        media_type = file.content_type or "application/octet-stream"
        
        return StreamingResponse(
            response,
            media_type=media_type,
            headers={"Content-Disposition": f'attachment; filename="{file.filename}"'}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to download: {str(e)}")

</code>

backend/app/email/service.py:
<code>
"""
Email Service for sending verification and notification emails.

Uses SMTP to send emails. Supports multiple providers (Gmail, SendGrid, etc.)
"""

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Optional
import logging
from ..config import settings

logger = logging.getLogger(__name__)


class EmailService:
    """Handles email sending operations."""
    
    def __init__(self):
        self.smtp_server = settings.SMTP_SERVER
        self.smtp_port = settings.SMTP_PORT
        self.username = settings.SMTP_USERNAME
        self.password = settings.SMTP_PASSWORD
        self.from_email = settings.EMAIL_FROM
    
    def send_email(
        self,
        to_email: str,
        subject: str,
        html_content: str,
        text_content: Optional[str] = None
    ) -> bool:
        """
        Send an email.
        
        Args:
            to_email: Recipient email address
            subject: Email subject
            html_content: HTML email body
            text_content: Plain text fallback (optional)
            
        Returns:
            True if sent successfully, False otherwise
        """
        try:
            # Create message
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.from_email
            msg['To'] = to_email
            
            # Add text and HTML parts
            if text_content:
                text_part = MIMEText(text_content, 'plain')
                msg.attach(text_part)
            
            html_part = MIMEText(html_content, 'html')
            msg.attach(html_part)
            
            # Send email
            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
                server.starttls()
                server.login(self.username, self.password)
                server.send_message(msg)
            
            logger.info(f"Email sent successfully to {to_email}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to send email to {to_email}: {str(e)}")
            return False
    
    def send_verification_email(self, to_email: str, verification_link: str) -> bool:
        """Send email verification link."""
        subject = "Verify Your Email - Cloud Drive"
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <body style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;">
            <div style="background: #f5f5f5; padding: 20px; border-radius: 8px;">
                <h2 style="color: #333;">Welcome to Cloud Drive!</h2>
                <p style="color: #666; line-height: 1.6;">
                    Thank you for signing up. Please verify your email address to activate your account.
                </p>
                <div style="margin: 30px 0;">
                    <a href="{verification_link}" 
                       style="background: #4285f4; color: white; padding: 12px 30px; 
                              text-decoration: none; border-radius: 4px; display: inline-block;">
                        Verify Email Address
                    </a>
                </div>
                <p style="color: #999; font-size: 14px;">
                    Or copy and paste this link into your browser:<br>
                    <span style="color: #4285f4;">{verification_link}</span>
                </p>
                <p style="color: #999; font-size: 12px; margin-top: 30px;">
                    This link will expire in 24 hours. If you didn't create an account, 
                    you can safely ignore this email.
                </p>
            </div>
        </body>
        </html>
        """
        
        text_content = f"""
        Welcome to Cloud Drive!
        
        Please verify your email address by clicking the link below:
        {verification_link}
        
        This link will expire in 24 hours.
        
        If you didn't create an account, you can safely ignore this email.
        """
        
        return self.send_email(to_email, subject, html_content, text_content)
    
    def send_lockout_notification(self, to_email: str, locked_until: str) -> bool:
        """Send account lockout notification."""
        subject = "Account Locked - Cloud Drive"
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <body style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;">
            <div style="background: #fff3cd; padding: 20px; border-radius: 8px; border-left: 4px solid #ffc107;">
                <h2 style="color: #856404;">Account Temporarily Locked</h2>
                <p style="color: #856404; line-height: 1.6;">
                    Your account has been temporarily locked due to multiple failed login attempts.
                </p>
                <p style="color: #856404;">
                    <strong>Locked until:</strong> {locked_until}
                </p>
                <p style="color: #856404; font-size: 14px; margin-top: 20px;">
                    If this wasn't you, please reset your password immediately.
                </p>
            </div>
        </body>
        </html>
        """
        
        return self.send_email(to_email, subject, html_content)
    
    def send_magic_link_email(self, to_email: str, magic_link: str) -> bool:
        """Send magic link for passwordless login."""
        subject = "Sign in to Cloud Drive"
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <body style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;">
            <div style="background: #f5f5f5; padding: 30px; border-radius: 8px;">
                <h2 style="color: #333;">Sign in to Cloud Drive</h2>
                <p style="color: #666; font-size: 16px; line-height: 1.6;">
                    Click the button below to securely sign in to your account.
                </p>
                <div style="margin: 30px 0;">
                    <a href="{magic_link}" 
                       style="background: #4285f4; color: white; padding: 14px 40px; 
                              text-decoration: none; border-radius: 4px; 
                              display: inline-block; font-size: 16px; font-weight: 500;">
                        Sign In to Cloud Drive
                    </a>
                </div>
                <p style="color: #999; font-size: 14px;">
                    This link will expire in 15 minutes.<br>
                    If you didn't request this, you can safely ignore this email.
                </p>
                <p style="color: #999; font-size: 12px; margin-top: 30px; word-break: break-all;">
                    Or copy and paste this link into your browser:<br>
                    <span style="color: #4285f4;">{magic_link}</span>
                </p>
            </div>
        </body>
        </html>
        """
        
        text_content = f"""
        Sign in to Cloud Drive
        
        Click the link below to sign in:
        {magic_link}
        
        This link will expire in 15 minutes.
        
        If you didn't request this, you can safely ignore this email.
        """
        
        return self.send_email(to_email, subject, html_content, text_content)


# Singleton instance
email_service = EmailService()

</code>

backend/app/email/__init__.py:
<code>
# email package

</code>

