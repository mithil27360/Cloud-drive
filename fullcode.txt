benchmark.py:
<code>
import os
import time
import requests
import pandas as pd
import json
from typing import List, Dict
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_recall
)
from langchain_groq import ChatGroq

# --- Configuration ---
BACKEND_URL = "http://localhost:8000/api/query"
AUTH_URL = "http://localhost:8000/auth/login"
USER_EMAIL = "qa_user@example.com" 
USER_PASS = "password123"

GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# --- Questions for "Attention Is All You Need" ---
QUESTIONS = [
    "What is the dominant sequence transduction model based on?",
    "Describe the Transformer architecture.",
    "What is Scaled Dot-Product Attention?",
    "Why use self-attention?",
    "What dataset was used for training?",
    "How does the attention mechanism compare to recurrent layers?",
    "What is the role of the encoder and decoder stacks?",
    "Explain the Positional Encoding used in the model.",
    "What optimizer was used for training the Transformer?",
    "What are the advantages of the Transformer model over RNNs?",
    "What is multi-head attention?",
    "Did the model use convolutional layers?",
    "What hardware was used for training?",
    "How is the output probability distribution generated?",
    "What is label smoothing?",
] + [f"Test Question {i}" for i in range(16, 51)]

def login():
    """Authenticates and returns a session token."""
    # Use standard form data login for regular users (or check if updated to JSON)
    # The auth.py login endpoint expects OAuth2PasswordRequestForm (form-data)
    response = requests.post(AUTH_URL, data={"username": USER_EMAIL, "password": USER_PASS})
    if response.status_code != 200:
        raise Exception(f"Login failed: {response.text}")
    return response.json()["access_token"]

def run_benchmark():
    print("üöÄ Starting Benchmark...")
    
    if not GROQ_API_KEY:
        print("‚ùå Error: GROQ_API_KEY environment variable not set.")
        return

    # 1. Setup RAGAS with Groq
    llm = ChatGroq(model="llama3-70b-8192", api_key=GROQ_API_KEY)
    
    print("üîë Authenticating...")
    try:
        token = login()
    except Exception as e:
        print(f"‚ùå Auth failed: {e}")
        return

    headers = {"Authorization": f"Bearer {token}"}
    
    results_data = []
    
    print(f"üìä Running {len(QUESTIONS)} questions...")
    
    for i, q in enumerate(QUESTIONS):
        print(f"[{i+1}/{len(QUESTIONS)}] Asking: {q}")
        
        try:
            # Call Backend
            payload = {"query": q}
            resp = requests.post(BACKEND_URL, json=payload, headers=headers)
            
            if resp.status_code != 200:
                print(f"  ‚ùå Request failed: {resp.status_code}")
                continue
                
            data = resp.json()
            answer = data.get("answer", "")
            sources = data.get("sources", [])
            metadata = data.get("metadata", {})
            
            # Extract contexts
            contexts = [s.get("page_content", "") for s in sources]
            
            # Prepare data for RAGAS
            results_data.append({
                "question": q,
                "answer": answer,
                "contexts": contexts,
                "ground_truth": "nan", # Placeholder for ground truth, required by some RAGAS metrics like context_recall
                "latency_retrieval": metadata.get("retrieval_time", 0),
                "latency_generation": metadata.get("generation_time", 0),
                "latency_total": metadata.get("total_time", 0)
            })
            
        except Exception as e:
            print(f"  ‚ùå Error: {e}")

    # 2. Convert to Dataset
    if not results_data:
        print("‚ùå No results collected.")
        return

    df = pd.DataFrame(results_data)
    dataset = Dataset.from_pandas(df)
    
    print("üß† Running RAGAS Evaluation (Faithfulness, Answer Relevancy, Context Recall)...")
    
    try:
        scores = evaluate(
            dataset,
            metrics=[faithfulness, answer_relevancy, context_recall], # Added context_recall
            llm=llm, 
        )
        
        print("\nüèÜ Benchmark Results:")
        print(scores)
        
        # Save results
        df_scores = scores.to_pandas()
        final_df = pd.concat([df, df_scores], axis=1)
        final_df.to_csv("benchmark_results.csv", index=False)
        print("\n‚úÖ Results saved to benchmark_results.csv")
        
    except Exception as e:
        print(f"‚ùå RAGAS Evaluation failed: {e}")
        print("Saving raw latency data anyway...")
        df.to_csv("benchmark_raw_latency.csv", index=False)

    # Calculate Latency Stats
    avg_retrieval = df["latency_retrieval"].mean()
    avg_gen = df["latency_generation"].mean()
    avg_total = df["latency_total"].mean()
    
    print(f"\n‚è±Ô∏è Latency Metrics:")
    print(f"  Average Retrieval: {avg_retrieval:.4f}s")
    print(f"  Average Generation: {avg_gen:.4f}s")
    print(f"  Average Total:      {avg_total:.4f}s")
    
if __name__ == "__main__":
    run_benchmark()

</code>

ingest_paper.py:
<code>
import requests
import os

# Config
BASE_URL = "http://localhost:8000"
FILE_PATH = "/Users/mithil/Desktop/cloud-drive/data/test source/attentionisallyouneed.pdf"
ADMIN_EMAIL = "mithil27360"
ADMIN_PASS = "expelliarmus@27"

def get_token():
    print("üîë Authenticating...")
    resp = requests.post(f"{BASE_URL}/auth/admin/login", json={
        "username": ADMIN_EMAIL, 
        "password": ADMIN_PASS
    })
    if resp.status_code != 200:
        raise Exception(f"Login failed: {resp.text}")
    return resp.json()["access_token"]

def upload_file(token):
    print(f"üì§ Uploading {os.path.basename(FILE_PATH)}...")
    
    if not os.path.exists(FILE_PATH):
        raise Exception("File not found!")
        
    headers = {"Authorization": f"Bearer {token}"}
    files = {"file": open(FILE_PATH, "rb")}
    
    resp = requests.post(f"{BASE_URL}/api/files/upload", headers=headers, files=files)
    
    if resp.status_code == 200:
        print("‚úÖ Upload successful!")
        print(resp.json())
    else:
        print(f"‚ùå Upload failed: {resp.status_code} - {resp.text}")

if __name__ == "__main__":
    try:
        token = get_token()
        upload_file(token)
    except Exception as e:
        print(f"Error: {e}")

</code>

README.md:
<code>
# AI Cloud Drive

Self hosted file storage with RAG search. Upload docs, ask questions, get answers from your files.

## What it does

- Upload PDFs, TXT, Markdown
- Ask questions in plain English
- Get answers with sources from your documents
- Admin dashboard for user management

## Architecture

```
Frontend (HTML/JS) ‚Üí Nginx ‚Üí FastAPI
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚Üì         ‚Üì         ‚Üì
               PostgreSQL   MinIO    Redis
                              ‚Üì
                         Celery Worker
                              ‚Üì
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚Üì         ‚Üì         ‚Üì
               ChromaDB    Groq API   Embeddings
```

## Tech Stack

- **Backend**: FastAPI, Celery, PostgreSQL
- **Storage**: MinIO (S3-compatible)
- **RAG**: ChromaDB + Sentence Transformers + Groq (Llama 3.3 70B)
- **Auth**: JWT with email verification
- **Deploy**: Docker Compose

## Quick Start

```bash
git clone https://github.com/mithil27360/Cloud-drive.git
cd Cloud-drive
cp .env.example .env
# add your Groq API key and SMTP settings

docker-compose up --build -d
```

- Frontend: http://localhost:3000
- API Docs: http://localhost:8000/docs
- Admin: http://localhost:3000/admin.html

## Project Structure

```
backend/
  app/
    routes/     # API endpoints
    rag/        # RAG engine
    storage/    # MinIO client
    tasks/      # Celery workers
  tests/        # pytest
frontend/
  index.html    # Main UI
  admin.html    # Admin panel
```

## How RAG works

1. Upload ‚Üí file goes to MinIO, metadata to Postgres
2. Celery extracts text, chunks it
3. Chunks embedded ‚Üí stored in ChromaDB
4. Query ‚Üí find similar chunks ‚Üí Groq generates answer

## Trade-offs

| Choice | Why |
|--------|-----|
| ChromaDB | Simple, local, no infra |
| Groq | Fast inference, free tier |
| MinIO | S3-compatible, runs locally |
| JWT | Stateless, simple |

## License

MIT

</code>

deploy.sh:
<code>
#!/bin/bash

# AI Cloud Drive - Deployment Script
set -e

echo "AI Cloud Drive Deployment Script"
echo "================================="

# Check for Docker
if ! command -v docker &> /dev/null; then
    echo "Error: Docker is not installed"
    exit 1
fi

# Check for Docker Compose
if ! command -v docker-compose &> /dev/null; then
    echo "Error: Docker Compose is not installed"
    exit 1
fi

# Environment
ENV=${1:-development}
echo "Deploying in $ENV mode"

# Create .env if not exists
if [ ! -f .env ]; then
    echo "Creating .env from .env.example"
    cp .env.example .env
    echo "Warning: Please update .env with production values!"
fi

# Create certs directory
mkdir -p certs

case $ENV in
    development)
        echo "Starting development environment..."
        docker-compose up --build -d
        ;;
    production)
        echo "Starting production environment..."
        docker-compose -f docker-compose.yml -f docker-compose.prod.yml up --build -d
        ;;
    *)
        echo "Error: Unknown environment: $ENV"
        echo "Usage: ./deploy.sh [development|production]"
        exit 1
        ;;
esac

echo ""
echo "Waiting for services to be healthy..."
sleep 10

# Check health
echo ""
echo "Service Health:"
docker-compose ps

echo ""
echo "Deployment complete!"
echo ""
echo "Access Points:"
echo "   - App:      http://localhost"
echo "   - API:      http://localhost:8000"
echo "   - Docs:     http://localhost:8000/docs"
echo "   - MinIO:    http://localhost:9001"
echo ""
echo "Logs: docker-compose logs -f [service]"
echo "Stop: docker-compose down"

</code>

docker-compose.yml:
<code>
services:
  backend:
    build: ./backend
    container_name: ai_drive_backend
    env_file:
      - .env
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
      - minio
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/aiclouddrive
      - SECRET_KEY=your-super-secret-key-change-this
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - CHROMA_HOST=chromadb
      - REDIS_URL=redis://redis:6379/0
      - GROQ_API_KEY=${GROQ_API_KEY}
      - ENVIRONMENT=development
      - DEBUG=True
      - CORS_ORIGINS=*
      - ADMIN_USERNAME=${ADMIN_USERNAME:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-admin}
    restart: always

  celery_worker:
    build: ./backend
    container_name: ai_drive_celery
    command: celery -A app.tasks.celery_app.celery worker --loglevel=info
    depends_on:
      - db
      - redis
      - minio
      - backend
    volumes:
      - ./backend:/app
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/aiclouddrive
      - SECRET_KEY=your-super-secret-key-change-this
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
      - CHROMA_HOST=chromadb
      - REDIS_URL=redis://redis:6379/0
      - GROQ_API_KEY=${GROQ_API_KEY}
    restart: always

  db:
    image: postgres:15-alpine
    container_name: ai_drive_db
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=aiclouddrive
    ports:
      - "5433:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always

  minio:
    image: minio/minio
    container_name: ai_drive_minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data
    restart: always

  redis:
    image: redis:7-alpine
    container_name: ai_drive_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: always

  chromadb:
    image: chromadb/chroma
    container_name: ai_drive_chroma
    ports:
      - "8001:8000"
    volumes:
      - chroma_data:/chroma/chroma
    restart: always

  frontend:
    build: ./frontend
    container_name: ai_drive_frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    restart: always

volumes:
  postgres_data:
  minio_data:
  redis_data:
  chroma_data:

</code>

docker-compose.prod.yml:
<code>
version: '3.8'

# Production configuration with scaling
# Use: docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

services:
  backend:
    environment:
      - ENVIRONMENT=production
      - DEBUG=False
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  celery_worker:
    command: celery -A app.tasks.celery_app.celery worker --loglevel=warning --concurrency=4
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 2G
          cpus: '1'
        reservations:
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3

  db:
    environment:
      - POSTGRES_PASSWORD=${DB_PASSWORD:-strongpassword}
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'

  redis:
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru --requirepass ${REDIS_PASSWORD:-redispassword}
    deploy:
      resources:
        limits:
          memory: 256M

  nginx:
    ports:
      - "80:80"
      - "443:443"
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'

</code>

frontend/index.html:
<code>
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Cloud Drive - AI Powered File Storage</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="styles.css?v=2">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='.9em' font-size='90'>‚òÅÔ∏è</text></svg>">
</head>

<body>
  <!-- Auth Container -->
  <div id="auth-container" class="auth-container">
    <div class="auth-card">
      <div class="auth-logo">
        <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2">
          <path d="M18 10h-1.26A8 8 0 1 0 9 20h9a5 5 0 0 0 0-10z"></path>
        </svg>
      </div>
      <h1 class="auth-title" id="auth-title">Welcome back</h1>
      <p class="auth-subtitle" id="auth-subtitle">Sign in to access your cloud drive</p>

      <div id="auth-error" class="alert alert-error" style="display: none;"></div>

      <form id="auth-form">
        <div class="form-group">
          <label class="form-label">Email</label>
          <div class="input-with-icon">
            <span class="input-icon">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path>
                <polyline points="22,6 12,13 2,6"></polyline>
              </svg>
            </span>
            <input type="email" id="email" class="form-input" placeholder="Enter your email" required>
          </div>
        </div>

        <div class="form-group">
          <label class="form-label">Password</label>
          <div class="input-with-icon">
            <span class="input-icon">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <rect x="3" y="11" width="18" height="11" rx="2" ry="2"></rect>
                <path d="M7 11V7a5 5 0 0 1 10 0v4"></path>
              </svg>
            </span>
            <input type="password" id="password" class="form-input" placeholder="Enter your password" required
              minlength="6">
          </div>
        </div>

        <button type="submit" class="btn btn-primary btn-full" id="auth-btn">
          Sign In
        </button>
      </form>

      <p class="auth-footer">
        <span id="auth-toggle-text">Don't have an account?</span>
        <a href="#" id="auth-toggle">Sign up</a>
      </p>
    </div>
  </div>

  <!-- Dashboard Container -->
  <div id="dashboard-container" class="app-container" style="display: none;">
    <!-- Navbar -->
    <nav class="navbar">
      <div class="navbar-brand">
        <div class="navbar-logo">
          <svg width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2">
            <path d="M18 10h-1.26A8 8 0 1 0 9 20h9a5 5 0 0 0 0-10z"></path>
          </svg>
        </div>
        <span>Cloud Drive</span>
      </div>
      <div class="navbar-actions">
        <div class="profile-dropdown">
          <button class="btn btn-secondary profile-toggle" id="profile-toggle">
            <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
              style="margin-right: 6px;">
              <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
              <circle cx="12" cy="7" r="4"></circle>
            </svg>
            Profile
            <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
              style="margin-left: 6px;">
              <polyline points="6 9 12 15 18 9"></polyline>
            </svg>
          </button>
          <div class="profile-menu" id="profile-menu">
            <button class="profile-menu-item" id="user-profile-btn">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path>
                <circle cx="12" cy="7" r="4"></circle>
              </svg>
              User Profile
            </button>
            <div class="profile-menu-divider"></div>
            <button class="profile-menu-item" id="logout-btn">
              <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M9 21H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h4"></path>
                <polyline points="16 17 21 12 16 7"></polyline>
                <line x1="21" y1="12" x2="9" y2="12"></line>
              </svg>
              Sign Out
            </button>
          </div>
        </div>
      </div>
    </nav>

    <!-- Main Layout -->
    <div class="dashboard">
      <!-- Sidebar -->
      <aside class="sidebar">
        <div class="sidebar-section">
          <button class="btn btn-primary btn-full" id="upload-btn" style="margin-bottom: 24px;">
            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
              <line x1="12" y1="5" x2="12" y2="19"></line>
              <line x1="5" y1="12" x2="19" y2="12"></line>
            </svg>
            New Upload
          </button>

          <nav class="sidebar-nav">
            <div class="sidebar-item active" data-tab="files">
              <svg class="sidebar-item-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path>
              </svg>
              My Files
            </div>
            <div class="sidebar-item" data-tab="chat">
              <svg class="sidebar-item-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
              </svg>
              AI Assistant
            </div>
          </nav>
        </div>

        <div class="sidebar-section">
          <div class="sidebar-title">Storage</div>
          <div style="padding: 0 12px;">
            <div class="storage-bar">
              <div class="storage-fill" id="storage-fill"></div>
            </div>
            <p class="storage-text"><span id="file-count">0</span> files uploaded</p>
          </div>
        </div>
      </aside>

      <!-- Main Content -->
      <main class="main-content">
        <!-- Files Tab -->
        <div id="files-tab">
          <!-- Upload Zone -->
          <div class="upload-zone" id="upload-zone">
            <input type="file" id="file-input" accept=".pdf,.txt,.md" style="display: none;">
            <div class="upload-icon">
              <svg width="28" height="28" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"></path>
                <polyline points="17 8 12 3 7 8"></polyline>
                <line x1="12" y1="3" x2="12" y2="15"></line>
              </svg>
            </div>
            <p class="upload-title">Drop files here or <span class="text-accent">browse</span></p>
            <p class="upload-subtitle">Supports PDF, TXT, Markdown ‚Ä¢ Max 50MB</p>
          </div>

          <!-- Upload Progress -->
          <div id="upload-progress" class="upload-progress" style="display: none;">
            <div class="upload-progress-bar">
              <div class="upload-progress-fill" id="progress-fill"></div>
            </div>
            <p class="upload-progress-text">Uploading... <span id="progress-percent">0</span>%</p>
          </div>

          <!-- Files Grid -->
          <div id="files-section" style="margin-top: 24px;">
            <div class="section-header">
              <h2 class="section-title">Recent Files</h2>
              <button class="btn btn-ghost" id="refresh-btn">
                <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                  <polyline points="23 4 23 10 17 10"></polyline>
                  <path d="M20.49 15a9 9 0 1 1-2.12-9.36L23 10"></path>
                </svg>
              </button>
            </div>
            <div id="files-grid" class="files-grid"></div>
            <div id="empty-state" class="empty-state">
              <div class="empty-icon">
                <svg width="40" height="40" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
                  <path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path>
                </svg>
              </div>
              <h3>No files yet</h3>
              <p>Upload your first file to get started</p>
            </div>
          </div>
        </div>

        <!-- Chat Tab -->
        <div id="chat-tab" style="display: none;">
          <div class="chat-container">
            <div class="chat-header">
              <div class="chat-header-content">
                <div class="chat-avatar">
                  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2">
                    <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
                  </svg>
                </div>
                <div>
                  <h3>AI Assistant</h3>
                  <p>Ask questions about your documents</p>
                </div>
              </div>
            </div>

            <!-- Document Selector -->
            <div class="doc-selector" id="doc-selector">
              <div class="doc-selector-header">
                <span class="doc-selector-title">üìÑ Search in: <span id="selected-count">All documents</span></span>
                <div class="doc-selector-actions">
                  <button class="btn-link" id="select-all-docs">Select All</button>
                  <button class="btn-link" id="clear-all-docs">Clear All</button>
                </div>
              </div>
              <div class="doc-selector-list" id="doc-list"></div>
            </div>

            <div class="chat-messages" id="chat-messages">
              <div class="chat-empty">
                <div class="chat-empty-icon">
                  <svg width="32" height="32" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1.5">
                    <circle cx="12" cy="12" r="10"></circle>
                    <path d="M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3"></path>
                    <line x1="12" y1="17" x2="12.01" y2="17"></line>
                  </svg>
                </div>
                <h3>How can I help you?</h3>
                <p>I can answer questions about your uploaded documents</p>
                <div class="chat-suggestions">
                  <button class="btn btn-secondary suggestion-btn">Summarize my files</button>
                  <button class="btn btn-secondary suggestion-btn">Find key points</button>
                  <button class="btn btn-secondary suggestion-btn">Search for topics</button>
                </div>
              </div>
            </div>

            <div class="chat-input-container">
              <form id="chat-form" class="chat-input-wrapper">
                <input type="text" id="chat-input" class="chat-input"
                  placeholder="Ask a question about your documents..." disabled>
                <button type="submit" class="btn btn-primary btn-icon chat-send-btn" disabled>
                  <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                    <line x1="22" y1="2" x2="11" y2="13"></line>
                    <polygon points="22 2 15 22 11 13 2 9 22 2"></polygon>
                  </svg>
                </button>
              </form>
            </div>
          </div>
        </div>


    </div>

    <!-- Mobile Navigation -->
    <nav class="mobile-nav">
      <div class="mobile-nav-item active" data-tab="files">
        <svg width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path>
        </svg>
        <span>Files</span>
      </div>
      <div class="mobile-nav-item" data-tab="chat">
        <svg width="22" height="22" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="M21 15a2 2 0 0 1-2 2H7l-4 4V5a2 2 0 0 1 2-2h14a2 2 0 0 1 2 2z"></path>
        </svg>
        <span>AI Chat</span>
      </div>
    </nav>
  </div>

  <!-- Toast -->
  <div id="toast" class="toast"></div>

  <!-- Profile Modal -->
  <div id="profile-modal" class="modal-overlay">
    <div class="modal-content">
      <div class="modal-header">
        <h2 class="modal-title">User Profile</h2>
        <button class="modal-close" onclick="closeProfileModal()">
          <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <line x1="18" y1="6" x2="6" y2="18"></line>
            <line x1="6" y1="6" x2="18" y2="18"></line>
          </svg>
        </button>
      </div>
      <div id="profile-details">
        <div style="text-align: center; margin-bottom: 24px;">
          <div class="chat-avatar" style="width: 80px; height: 80px; margin: 0 auto 16px; font-size: 32px;">
            üë§
          </div>
          <h3 id="profile-email" style="font-size: 1.125rem;">loading...</h3>
          <p id="profile-role" style="color: var(--text-muted); font-size: 0.875rem;">User</p>
        </div>
        <div style="background: var(--bg-tertiary); padding: 16px; border-radius: var(--radius-md);">
          <div style="display: flex; justify-content: space-between; margin-bottom: 8px;">
            <span style="color: var(--text-secondary);">Member since</span>
            <strong id="profile-date">-</strong>
          </div>
        </div>
      </div>
    </div>
  </div>

  <script src="app.js"></script>
</body>

</html>
</code>

frontend/admin.html:
<code>
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Admin Dashboard - AI Cloud Drive</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #F8FAFC;
            --bg-card: #FFFFFF;
            --border: #E5E7EB;
            --border-light: #F1F5F9;
            --text: #0F172A;
            --text-secondary: #374151;
            --text-muted: #64748B;
            --text-faint: #94A3B8;
            --accent: #2563EB;
            --success: #16A34A;
            --error: #DC2626;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, sans-serif;
            background: var(--bg);
            color: var(--text);
            font-size: 13px;
            line-height: 1.5;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            padding: 24px;
        }

        /* Header */
        .header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 24px;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--border);
        }

        .header h1 {
            font-size: 18px;
            font-weight: 600;
            margin-bottom: 2px;
        }

        .header-subtitle {
            font-size: 12px;
            color: var(--text-muted);
        }

        .btn {
            padding: 8px 16px;
            font-size: 12px;
            border: 1px solid var(--border);
            border-radius: 6px;
            background: var(--bg-card);
            color: var(--text-secondary);
            cursor: pointer;
            font-weight: 500;
            transition: all 0.2s;
        }

        .btn:hover {
            background: var(--bg);
        }

        .btn-primary {
            background: var(--accent);
            color: white;
            border-color: var(--accent);
        }

        .btn-primary:hover {
            background: #1d4ed8;
        }

        /* Login Container */
        .admin-login-container {
            display: flex;
            height: 100vh;
            align-items: center;
            justify-content: center;
            background: var(--bg);
        }

        .auth-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 12px;
            padding: 40px;
            width: 100%;
            max-width: 400px;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .auth-logo {
            text-align: center;
            margin-bottom: 24px;
        }

        .auth-title {
            font-size: 20px;
            font-weight: 600;
            text-align: center;
            margin-bottom: 8px;
        }

        .auth-subtitle {
            font-size: 13px;
            color: var(--text-muted);
            text-align: center;
            margin-bottom: 24px;
        }

        .form-group {
            margin-bottom: 16px;
        }

        .form-label {
            display: block;
            font-size: 12px;
            font-weight: 500;
            color: var(--text-secondary);
            margin-bottom: 6px;
        }

        .form-input {
            width: 100%;
            padding: 10px 12px;
            font-size: 13px;
            border: 1px solid var(--border);
            border-radius: 6px;
            background: var(--bg-card);
            color: var(--text);
        }

        .form-input:focus {
            outline: none;
            border-color: var(--accent);
        }

        .alert {
            padding: 10px 14px;
            border-radius: 6px;
            font-size: 12px;
            margin-bottom: 16px;
        }

        .alert-error {
            background: #FEF2F2;
            border: 1px solid #FECACA;
            color: #991B1B;
        }

        /* KPI Grid */
        .kpi-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 16px;
            margin-bottom: 24px;
        }

        .kpi-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 8px;
            padding: 20px;
        }

        .kpi-value {
            font-size: 32px;
            font-weight: 600;
            color: var(--text);
            line-height: 1;
        }

        .kpi-label {
            font-size: 12px;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.5px;
            margin-top: 8px;
        }

        /* Table */
        .table-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 8px;
            overflow: hidden;
        }

        .table-toolbar {
            padding: 14px 20px;
            border-bottom: 1px solid var(--border);
            display: flex;
            justify-content: space-between;
            align-items: center;
            background: var(--bg);
        }

        .table-title {
            font-size: 13px;
            font-weight: 600;
            color: var(--text-secondary);
        }

        table {
            width: 100%;
            border-collapse: collapse;
        }

        th {
            text-align: left;
            padding: 12px 20px;
            font-size: 11px;
            font-weight: 600;
            color: var(--text-muted);
            text-transform: uppercase;
            letter-spacing: 0.5px;
            background: var(--bg);
            border-bottom: 1px solid var(--border);
        }

        td {
            padding: 16px 20px;
            font-size: 13px;
            border-bottom: 1px solid var(--border-light);
            color: var(--text-secondary);
        }

        tr:last-child td {
            border-bottom: none;
        }

        tr:hover {
            background: var(--bg);
        }

        .file-badge {
            display: inline-block;
            padding: 4px 8px;
            font-size: 11px;
            background: var(--border-light);
            border-radius: 4px;
            margin: 2px;
            cursor: pointer;
            transition: all 0.2s;
        }

        .file-badge:hover {
            background: var(--accent);
            color: white;
        }

        .btn-small {
            padding: 6px 12px;
            font-size: 11px;
            border-radius: 4px;
        }

        /* Modal */
        .modal {
            display: none;
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.5);
            z-index: 1000;
            align-items: center;
            justify-content: center;
        }

        .modal-content {
            background: white;
            border-radius: 12px;
            width: 90%;
            max-width: 800px;
            max-height: 80vh;
            overflow-y: auto;
            padding: 24px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);
        }

        .modal-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 16px;
            border-bottom: 1px solid var(--border);
        }

        .modal-header h3 {
            font-size: 16px;
            font-weight: 600;
        }

        .close {
            cursor: pointer;
            font-size: 24px;
            color: var(--text-muted);
        }

        .close:hover {
            color: var(--text);
        }

        .chat-message {
            margin-bottom: 16px;
            padding: 12px;
            border-radius: 8px;
            border-left: 3px solid var(--accent);
            background: var(--bg);
        }

        .chat-query {
            font-weight: 500;
            color: var(--text);
            margin-bottom: 6px;
        }

        .chat-answer {
            color: var(--text-secondary);
            font-size: 12px;
        }

        .chat-time {
            font-size: 11px;
            color: var(--text-faint);
            margin-top: 6px;
        }

        .empty-state {
            text-align: center;
            padding: 40px;
            color: var(--text-faint);
            font-size: 13px;
        }

        .text-muted {
            color: var(--text-muted);
        }

        .toast {
            position: fixed;
            bottom: 24px;
            right: 24px;
            background: var(--text);
            color: white;
            padding: 12px 20px;
            border-radius: 8px;
            font-size: 13px;
            opacity: 0;
            transition: opacity 0.3s;
            z-index: 2000;
        }

        .toast.show {
            opacity: 1;
        }

        .toast.error {
            background: var(--error);
        }

        .badge {
            display: inline-block;
            padding: 2px 6px;
            border-radius: 4px;
            font-size: 10px;
            font-weight: 600;
            text-transform: uppercase;
        }

        .badge.success {
            background: #DCFCE7;
            color: #166534;
        }

        .badge.error {
            background: #FEF2F2;
            color: #991B1B;
        }

        .badge.warning {
            background: #FEF9C3;
            color: #854D0E;
        }
    </style>
</head>

<body>
    <!-- Login -->
    <div id="admin-login-container" class="admin-login-container">
        <div class="auth-card">
            <div class="auth-logo">
                <span style="font-size: 48px;">üõ°Ô∏è</span>
            </div>
            <h1 class="auth-title">Admin Access</h1>
            <p class="auth-subtitle">Restricted Area</p>
            <div id="auth-error" class="alert alert-error" style="display: none;"></div>
            <form id="admin-login-form">
                <div class="form-group">
                    <label class="form-label">Username</label>
                    <input type="text" id="admin-username" class="form-input" required>
                </div>
                <div class="form-group">
                    <label class="form-label">Password</label>
                    <input type="password" id="admin-password" class="form-input" required>
                </div>
                <button type="submit" class="btn btn-primary" style="width: 100%;">Login</button>
            </form>
        </div>
    </div>

    <!-- Dashboard -->
    <div id="admin-dashboard" style="display: none;">
        <div class="container">
            <header class="header">
                <div>
                    <h1>üõ°Ô∏è Admin Dashboard</h1>
                    <div class="header-subtitle">User Management & Analytics</div>
                </div>
                <button class="btn" id="logout-btn">Sign Out</button>
            </header>

            <!-- KPIs -->
            <div class="kpi-grid">
                <div class="kpi-card">
                    <div class="kpi-value" id="totalUsers">‚Äî</div>
                    <div class="kpi-label">Total Users</div>
                </div>
                <div class="kpi-card">
                    <div class="kpi-value" id="totalFiles">‚Äî</div>
                    <div class="kpi-label">Total Files</div>
                </div>
                <div class="kpi-card">
                    <div class="kpi-value" id="totalChats">‚Äî</div>
                    <div class="kpi-label">Total Queries</div>
                </div>
            </div>

            <!-- Users Table -->
            <div class="table-card">
                <div class="table-toolbar">
                    <span class="table-title">All Users</span>
                    <input type="text" id="searchUsers" placeholder="Search users..."
                        style="padding: 6px 12px; border: 1px solid var(--border); border-radius: 6px; font-size: 12px;"
                        oninput="filterUsers()">
                </div>
                <table>
                    <thead>
                        <tr>
                            <th>User</th>
                            <th>Status</th>
                            <th>Usage</th>
                            <th>Last Login</th>
                            <th>Actions</th>
                        </tr>
                    </thead>
                    <tbody id="usersTable">
                        <tr>
                            <td colspan="5" class="empty-state">Loading users...</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <!-- Files Table -->
            <div class="table-card" style="margin-top: 24px;">
                <div class="table-toolbar">
                    <span class="table-title">All Files</span>
                    <input type="text" id="searchFiles" placeholder="Search files..."
                        style="padding: 6px 12px; border: 1px solid var(--border); border-radius: 6px; font-size: 12px;"
                        oninput="filterFiles()">
                </div>
                <table>
                    <thead>
                        <tr>
                            <th>Filename</th>
                            <th>Owner</th>
                            <th>Size</th>
                            <th>Type</th>
                            <th>Uploaded</th>
                            <th>Actions</th>
                        </tr>
                    </thead>
                    <tbody id="filesTable">
                        <tr>
                            <td colspan="6" class="empty-state">Loading files...</td>
                        </tr>
                    </tbody>
                </table>
            </div>

            <!-- Audit Logs -->
            <div class="table-card" style="margin-top: 24px;">
                <div class="table-toolbar">
                    <span class="table-title">Audit Logs</span>
                </div>
                <table>
                    <thead>
                        <tr>
                            <th>Time</th>
                            <th>Actor</th>
                            <th>Action</th>
                            <th>Target</th>
                            <th>Details</th>
                        </tr>
                    </thead>
                    <tbody id="auditTable">
                        <tr>
                            <td colspan="5" class="empty-state">Loading logs...</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>
    </div>

    <!-- Chat Modal -->
    <div id="chatModal" class="modal">
        <div class="modal-content">
            <div class="modal-header">
                <h3 id="chatModalTitle">User Chats</h3>
                <span class="close" onclick="closeChatModal()">&times;</span>
            </div>
            <div id="chatModalContent">
                <div class="empty-state">Loading chats...</div>
            </div>
        </div>
    </div>

    <!-- Profile Modal -->
    <div id="profileModal" class="modal">
        <div class="modal-content" style="max-width: 600px;">
            <div class="modal-header">
                <h3 id="profileModalTitle">User Profile</h3>
                <span class="close" onclick="closeProfileModal()">&times;</span>
            </div>
            <div id="profileModalContent">
                <div class="empty-state">Loading profile...</div>
            </div>
        </div>
    </div>

    <div id="toast" class="toast"></div>

    <script src="admin.js"></script>
</body>

</html>
</code>

frontend/styles.css:
<code>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

:root {
    --bg-primary: #f8fafc;
    --bg-secondary: #ffffff;
    --bg-tertiary: #f1f5f9;
    --bg-hover: #e2e8f0;
    --text-primary: #1e293b;
    --text-secondary: #64748b;
    --text-muted: #94a3b8;
    --accent-blue: #4285f4;
    --accent-blue-hover: #3b78e7;
    --accent-green: #34a853;
    --accent-yellow: #fbbc04;
    --accent-red: #ea4335;
    --border-light: #e2e8f0;
    --border-medium: #cbd5e1;
    --shadow-sm: 0 1px 2px rgba(0, 0, 0, 0.05);
    --shadow-md: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
    --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1);
    --shadow-xl: 0 20px 25px -5px rgba(0, 0, 0, 0.1);
    --radius-sm: 8px;
    --radius-md: 12px;
    --radius-lg: 16px;
    --radius-xl: 24px;
    --radius-full: 9999px;
}

body {
    font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    background: var(--bg-primary);
    color: var(--text-primary);
    line-height: 1.6;
    -webkit-font-smoothing: antialiased;
}

/* Buttons */
.btn {
    display: inline-flex;
    align-items: center;
    justify-content: center;
    gap: 8px;
    padding: 10px 20px;
    font-size: 0.875rem;
    font-weight: 500;
    font-family: inherit;
    border-radius: var(--radius-full);
    border: none;
    cursor: pointer;
    transition: all 0.2s ease;
    text-decoration: none;
}

.btn-primary {
    background: var(--accent-blue);
    color: white;
}

.btn-primary:hover {
    background: var(--accent-blue-hover);
    box-shadow: var(--shadow-md);
}

.btn-primary:disabled {
    opacity: 0.6;
    cursor: not-allowed;
}

.btn-secondary {
    background: var(--bg-tertiary);
    color: var(--text-primary);
}

.btn-secondary:hover {
    background: var(--bg-hover);
}

.btn-ghost {
    background: transparent;
    color: var(--text-secondary);
}

.btn-ghost:hover {
    background: var(--bg-tertiary);
}

.btn-icon {
    width: 48px;
    height: 48px;
    padding: 0;
}

.btn-full {
    width: 100%;
}

/* Forms */
.form-group {
    margin-bottom: 20px;
}

.form-label {
    display: block;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
    margin-bottom: 8px;
}

.form-input {
    width: 100%;
    padding: 12px 16px;
    font-size: 1rem;
    font-family: inherit;
    border: 1px solid var(--border-medium);
    border-radius: var(--radius-md);
    background: var(--bg-secondary);
    color: var(--text-primary);
    transition: all 0.2s ease;
}

.form-input:focus {
    outline: none;
    border-color: var(--accent-blue);
    box-shadow: 0 0 0 3px rgba(66, 133, 244, 0.15);
}

.form-input::placeholder {
    color: var(--text-muted);
}

.input-with-icon {
    position: relative;
}

.input-icon {
    position: absolute;
    left: 16px;
    top: 50%;
    transform: translateY(-50%);
    color: var(--text-muted);
}

.input-with-icon .form-input {
    padding-left: 48px;
}

/* Alerts */
.alert {
    padding: 12px 16px;
    border-radius: var(--radius-md);
    font-size: 0.875rem;
    margin-bottom: 16px;
}

.alert-error {
    background: #fef2f2;
    color: #991b1b;
    border: 1px solid #fecaca;
}

.alert-success {
    background: #f0fdf4;
    color: #166534;
    border: 1px solid #bbf7d0;
}

/* Auth */
.auth-container {
    min-height: 100vh;
    display: flex;
    align-items: center;
    justify-content: center;
    background: linear-gradient(135deg, #e0f2fe 0%, #f0f9ff 50%, #faf5ff 100%);
    padding: 24px;
}

.auth-card {
    width: 100%;
    max-width: 440px;
    background: var(--bg-secondary);
    border-radius: var(--radius-xl);
    box-shadow: var(--shadow-xl);
    padding: 48px;
}

.auth-logo {
    width: 56px;
    height: 56px;
    background: linear-gradient(135deg, var(--accent-blue) 0%, #7c3aed 100%);
    border-radius: var(--radius-lg);
    display: flex;
    align-items: center;
    justify-content: center;
    margin: 0 auto 24px;
}

.auth-title {
    font-size: 1.5rem;
    font-weight: 600;
    text-align: center;
    margin-bottom: 8px;
}

.auth-subtitle {
    font-size: 0.9375rem;
    color: var(--text-secondary);
    text-align: center;
    margin-bottom: 32px;
}

.auth-footer {
    text-align: center;
    margin-top: 24px;
    font-size: 0.875rem;
    color: var(--text-secondary);
}

.auth-footer a {
    color: var(--accent-blue);
    text-decoration: none;
    font-weight: 500;
    margin-left: 4px;
}

.auth-footer a:hover {
    text-decoration: underline;
}

/* App Layout */
.app-container {
    min-height: 100vh;
    display: flex;
    flex-direction: column;
}

/* Navbar */
.navbar {
    background: var(--bg-secondary);
    border-bottom: 1px solid var(--border-light);
    padding: 12px 24px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    position: sticky;
    top: 0;
    z-index: 100;
}

.navbar-brand {
    display: flex;
    align-items: center;
    gap: 12px;
    font-size: 1.25rem;
    font-weight: 600;
}

.navbar-logo {
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, var(--accent-blue) 0%, #7c3aed 100%);
    border-radius: var(--radius-md);
    display: flex;
    align-items: center;
    justify-content: center;
}

/* Dashboard */
.dashboard {
    display: flex;
    min-height: calc(100vh - 65px);
}

/* Sidebar */
.sidebar {
    width: 280px;
    background: var(--bg-secondary);
    border-right: 1px solid var(--border-light);
    padding: 24px 16px;
    flex-shrink: 0;
}

.sidebar-section {
    margin-bottom: 32px;
}

.sidebar-title {
    font-size: 0.75rem;
    font-weight: 600;
    color: var(--text-muted);
    text-transform: uppercase;
    letter-spacing: 0.05em;
    padding: 0 12px;
    margin-bottom: 8px;
}

.sidebar-nav {
    display: flex;
    flex-direction: column;
    gap: 4px;
}

.sidebar-item {
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 12px;
    border-radius: var(--radius-md);
    color: var(--text-secondary);
    font-size: 0.9375rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.2s ease;
}

.sidebar-item:hover {
    background: var(--bg-tertiary);
    color: var(--text-primary);
}

.sidebar-item.active {
    background: #e8f0fe;
    color: var(--accent-blue);
}

.sidebar-item-icon {
    width: 20px;
    height: 20px;
}

.storage-bar {
    height: 4px;
    background: var(--bg-hover);
    border-radius: 2px;
    overflow: hidden;
    margin-bottom: 8px;
}

.storage-fill {
    width: 0%;
    height: 100%;
    background: var(--accent-blue);
    transition: width 0.3s ease;
}

.storage-text {
    font-size: 0.75rem;
    color: var(--text-muted);
}

/* Main Content */
.main-content {
    flex: 1;
    padding: 24px 32px;
    background: var(--bg-primary);
}

/* Upload Zone */
.upload-zone {
    border: 2px dashed var(--border-medium);
    border-radius: var(--radius-lg);
    padding: 48px;
    text-align: center;
    cursor: pointer;
    transition: all 0.2s ease;
    background: var(--bg-secondary);
}

.upload-zone:hover,
.upload-zone.dragging {
    border-color: var(--accent-blue);
    background: #f0f7ff;
}

.upload-icon {
    width: 64px;
    height: 64px;
    margin: 0 auto 16px;
    background: var(--bg-tertiary);
    border-radius: var(--radius-full);
    display: flex;
    align-items: center;
    justify-content: center;
    color: var(--accent-blue);
}

.upload-title {
    font-size: 1rem;
    font-weight: 500;
    color: var(--text-primary);
    margin-bottom: 4px;
}

.upload-subtitle {
    font-size: 0.875rem;
    color: var(--text-muted);
}

.text-accent {
    color: var(--accent-blue);
}

.upload-progress {
    background: var(--bg-secondary);
    border-radius: var(--radius-md);
    padding: 16px;
    margin-top: 16px;
}

.upload-progress-bar {
    height: 4px;
    background: var(--bg-hover);
    border-radius: 2px;
    overflow: hidden;
}

.upload-progress-fill {
    height: 100%;
    background: var(--accent-blue);
    transition: width 0.2s;
}

.upload-progress-text {
    font-size: 0.875rem;
    color: var(--text-secondary);
    margin-top: 8px;
    text-align: center;
}

/* Files */
.section-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 16px;
}

.section-title {
    font-size: 1rem;
    font-weight: 600;
}

.files-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
    gap: 16px;
}

.file-card {
    background: var(--bg-secondary);
    border: 1px solid var(--border-light);
    border-radius: var(--radius-lg);
    padding: 16px;
    transition: all 0.2s ease;
}

.file-card:hover {
    border-color: var(--accent-blue);
    box-shadow: var(--shadow-md);
}

.file-icon {
    width: 48px;
    height: 48px;
    border-radius: var(--radius-md);
    display: flex;
    align-items: center;
    justify-content: center;
    margin-bottom: 12px;
    font-size: 24px;
}

.file-icon.pdf {
    background: #fce4ec;
}

.file-icon.txt {
    background: #f3e5f5;
}

.file-icon.md {
    background: #e3f2fd;
}

.file-name {
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-primary);
    margin-bottom: 4px;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}

.file-meta {
    font-size: 0.75rem;
    color: var(--text-muted);
}

.file-footer {
    display: flex;
    gap: 4px;
    margin-top: 12px;
    padding-top: 12px;
    border-top: 1px solid var(--border-light);
    align-items: center;
}

.file-status {
    font-size: 0.7rem;
    display: flex;
    align-items: center;
    gap: 4px;
}

.file-status.indexed {
    color: var(--accent-green);
}

.file-status.processing {
    color: var(--accent-yellow);
}

.file-actions {
    margin-left: auto;
    display: flex;
    gap: 2px;
}

.file-action-btn {
    width: 28px;
    height: 28px;
    padding: 0;
    background: transparent;
    border: none;
    border-radius: var(--radius-sm);
    cursor: pointer;
    color: var(--text-muted);
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
}

.file-action-btn:hover {
    background: var(--bg-tertiary);
    color: var(--text-primary);
}

.file-action-btn.delete:hover {
    color: var(--accent-red);
}

/* Empty State */
.empty-state {
    text-align: center;
    padding: 64px 24px;
}

.empty-icon {
    width: 80px;
    height: 80px;
    margin: 0 auto 24px;
    background: var(--bg-tertiary);
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    color: var(--text-muted);
}

.empty-state h3 {
    font-size: 1.125rem;
    font-weight: 600;
    margin-bottom: 8px;
}

.empty-state p {
    color: var(--text-muted);
    font-size: 0.875rem;
}

/* Chat */
.chat-container {
    display: flex;
    flex-direction: column;
    height: calc(100vh - 150px);
    background: var(--bg-secondary);
    border-radius: var(--radius-lg);
    border: 1px solid var(--border-light);
    overflow: hidden;
}

.chat-header {
    padding: 16px 24px;
    border-bottom: 1px solid var(--border-light);
}

.chat-header-content {
    display: flex;
    align-items: center;
    gap: 12px;
}

.chat-avatar {
    width: 40px;
    height: 40px;
    background: linear-gradient(135deg, #7c3aed 0%, #4f46e5 100%);
    border-radius: var(--radius-md);
    display: flex;
    align-items: center;
    justify-content: center;
}

.chat-header h3 {
    font-size: 1rem;
    font-weight: 600;
}

.chat-header p {
    font-size: 0.75rem;
    color: var(--text-muted);
}

.chat-messages {
    flex: 1;
    overflow-y: auto;
    padding: 24px;
}

.chat-empty {
    text-align: center;
    padding: 48px 24px;
}

.chat-empty-icon {
    width: 64px;
    height: 64px;
    margin: 0 auto 20px;
    background: linear-gradient(135deg, #f5f3ff 0%, #ede9fe 100%);
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    color: #7c3aed;
}

.chat-empty h3 {
    font-size: 1.125rem;
    font-weight: 600;
    margin-bottom: 8px;
}

.chat-empty p {
    color: var(--text-muted);
    font-size: 0.875rem;
    margin-bottom: 24px;
}

.chat-suggestions {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
    justify-content: center;
}

.suggestion-btn {
    font-size: 0.8125rem;
    padding: 8px 16px;
}

.chat-message {
    max-width: 80%;
    margin-bottom: 16px;
}

.chat-message.user {
    margin-left: auto;
}

.message-bubble {
    padding: 12px 16px;
    border-radius: var(--radius-lg);
    font-size: 0.9375rem;
}

.chat-message.user .message-bubble {
    background: var(--accent-blue);
    color: white;
    border-bottom-right-radius: 4px;
}

.chat-message.assistant .message-bubble {
    background: var(--bg-tertiary);
    color: var(--text-primary);
    border-bottom-left-radius: 4px;
}

.chat-input-container {
    padding: 16px 24px;
    border-top: 1px solid var(--border-light);
}

.chat-input-wrapper {
    display: flex;
    gap: 12px;
}

.chat-input {
    flex: 1;
    padding: 14px 20px;
    border: 1px solid var(--border-medium);
    border-radius: var(--radius-full);
    font-size: 0.9375rem;
    font-family: inherit;
    background: var(--bg-primary);
}

.chat-input:focus {
    outline: none;
    border-color: var(--accent-blue);
}

.chat-input:disabled {
    background: var(--bg-tertiary);
}

.chat-send-btn {
    flex-shrink: 0;
}

.typing-indicator {
    display: flex;
    gap: 4px;
    padding: 12px 16px;
}

.typing-dot {
    width: 8px;
    height: 8px;
    background: var(--accent-blue);
    border-radius: 50%;
    animation: typing 1.4s infinite ease-in-out both;
}

.typing-dot:nth-child(2) {
    animation-delay: 0.15s;
}

.typing-dot:nth-child(3) {
    animation-delay: 0.3s;
}

@keyframes typing {

    0%,
    80%,
    100% {
        transform: scale(0.6);
        opacity: 0.4;
    }

    40% {
        transform: scale(1);
        opacity: 1;
    }
}

/* Toast */
.toast {
    position: fixed;
    bottom: 24px;
    right: 24px;
    background: var(--text-primary);
    color: white;
    padding: 12px 24px;
    border-radius: var(--radius-md);
    font-size: 0.875rem;
    box-shadow: var(--shadow-lg);
    transform: translateY(100px);
    opacity: 0;
    transition: all 0.3s ease;
    z-index: 1000;
}

.toast.show {
    transform: translateY(0);
    opacity: 1;
}

/* Loading */
.loading {
    display: inline-block;
    width: 20px;
    height: 20px;
    border: 2px solid rgba(255, 255, 255, 0.3);
    border-radius: 50%;
    border-top-color: white;
    animation: spin 1s ease-in-out infinite;
}

@keyframes spin {
    to {
        transform: rotate(360deg);
    }
}

/* Audit Button */
.btn-audit {
    display: inline-flex;
    align-items: center;
    gap: 6px;
    padding: 6px 12px;
    background: white;
    border: 1px solid var(--border-medium);
    border-radius: var(--radius-full);
    font-size: 0.75rem;
    font-weight: 500;
    color: var(--text-secondary);
    cursor: pointer;
    transition: all 0.2s;
    margin-top: 4px;
}

.btn-audit:hover {
    background: #f0fdf4;
    border-color: var(--accent-green);
    color: var(--accent-green);
}

.btn-audit:disabled {
    opacity: 0.7;
    cursor: wait;
}

.audit-score {
    font-size: 0.75rem;
    padding: 6px 12px;
    margin-top: 4px;
}



@keyframes spin {
    to {
        transform: rotate(360deg);
    }
}

/* Modal */
.modal-overlay {
    position: fixed;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background: rgba(0, 0, 0, 0.5);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 2000;
    backdrop-filter: blur(4px);
    opacity: 0;
    visibility: hidden;
    transition: all 0.3s ease;
}

.modal-overlay.show {
    opacity: 1;
    visibility: visible;
}

.modal-content {
    background: var(--bg-secondary);
    border-radius: var(--radius-xl);
    width: 100%;
    max-width: 400px;
    padding: 32px;
    transform: scale(0.9);
    transition: all 0.3s ease;
    box-shadow: var(--shadow-xl);
}

.modal-overlay.show .modal-content {
    transform: scale(1);
}

.modal-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 24px;
}

.modal-title {
    font-size: 1.25rem;
    font-weight: 600;
}

.modal-close {
    background: transparent;
    border: none;
    cursor: pointer;
    color: var(--text-muted);
}


/* Mobile Nav */
.mobile-nav {
    display: none;
    position: fixed;
    bottom: 0;
    left: 0;
    width: 100%;
    background: var(--bg-secondary);
    border-top: 1px solid var(--border-light);
    padding: 10px 0;
    justify-content: space-around;
    z-index: 1000;
    box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.08);
}

.mobile-nav-item {
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 4px;
    color: var(--text-muted);
    font-size: 0.7rem;
    font-weight: 500;
    cursor: pointer;
    padding: 4px 16px;
}

.mobile-nav-item.active {
    color: var(--accent-blue);
}

/* Responsive */
@media (max-width: 768px) {
    .sidebar {
        display: none;
    }

    .main-content {
        padding: 16px;
    }

    .auth-card {
        padding: 32px 24px;
    }

    .files-grid {
        grid-template-columns: 1fr;
    }

    .mobile-nav {
        display: flex;
    }

    .main-content {
        padding-bottom: 80px;
    }

    .chat-container {
        height: calc(100vh - 200px);
    }
}



/* Profile Dropdown */
.profile-dropdown {
    position: relative;
}

.profile-toggle {
    display: flex;
    align-items: center;
}

.profile-menu {
    position: absolute;
    top: calc(100% + 8px);
    right: 0;
    min-width: 200px;
    background: var(--bg-secondary);
    border: 1px solid var(--border-light);
    border-radius: var(--radius-md);
    box-shadow: var(--shadow-lg);
    opacity: 0;
    visibility: hidden;
    transform: translateY(-10px);
    transition: all 0.2s ease;
    z-index: 1000;
}

.profile-menu.show {
    opacity: 1;
    visibility: visible;
    transform: translateY(0);
}

.profile-menu-item {
    width: 100%;
    display: flex;
    align-items: center;
    gap: 12px;
    padding: 12px 16px;
    background: none;
    border: none;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-primary);
    cursor: pointer;
    transition: background 0.2s;
    text-align: left;
}

.profile-menu-item:hover {
    background: var(--bg-tertiary);
}

.profile-menu-item:first-child {
    border-radius: var(--radius-md) var(--radius-md) 0 0;
}

.profile-menu-item:last-child {
    border-radius: 0 0 var(--radius-md) var(--radius-md);
}

.profile-menu-divider {
    height: 1px;
    background: var(--border-light);
    margin: 4px 0;
}

/* Document Selector */
.doc-selector {
    padding: 12px 16px;
    border-bottom: 1 px solid var(--border-light);
    background: var(--bg-tertiary);
}

.doc-selector-header {
    display: flex;
    align-items: center;
    justify-content: space-between;
    margin-bottom: 12px;
}

.doc-selector-title {
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-secondary);
}

.doc-selector-actions {
    display: flex;
    gap: 12px;
}

.btn-link {
    background: none;
    border: none;
    color: var(--accent-blue);
    font-size: 0.75rem;
    font-weight: 500;
    cursor: pointer;
    padding: 0;
}

.btn-link:hover {
    text-decoration: underline;
}

.doc-selector-list {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
}

.doc-checkbox {
    display: flex;
    align-items: center;
    gap: 6px;
    padding: 6px 12px;
    background: var(--bg-secondary);
    border: 1px solid var(--border-light);
    border-radius: var(--radius-full);
    font-size: 0.8125rem;
    cursor: pointer;
    transition: all 0.2s;
}

.doc-checkbox:hover {
    border-color: var(--accent-blue);
}

.doc-checkbox input[type="checkbox"] {
    cursor: pointer;
}

.doc-checkbox.selected {
    background: #e8f0fe;
    border-color: var(--accent-blue);
    color: var(--accent-blue);
}

/* Success message styling */
.auth-error.success {
    background-color: #d4edda;
    border-color: #c3e6cb;
    color: #155724;
}

/* Verification needed message - blue/info style */
.auth-error.verification {
    background-color: #d1ecf1;
    border: 1px solid #bee5eb;
    color: #0c5460;
    padding: 15px;
    border-radius: 8px;
    margin-bottom: 15px;
    font-size: 14px;
    line-height: 1.5;
}
</code>

frontend/nginx.conf:
<code>
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    upstream backend {
        server backend:8000;
    }

    server {
        listen 80;
        server_name localhost;

        # Auth proxy (Handles /auth/*)
        location /auth {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # API proxy (Handles /api/* including /api/admin/*)
        location /api {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            client_max_body_size 50M;
        }

        # Health check
        location /health {
            proxy_pass http://backend;
        }

        location /docs {
            proxy_pass http://backend;
        }

        location /openapi.json {
            proxy_pass http://backend;
        }
        # Admin Page - force inline display, NOT download
        location = /admin {
            root /usr/share/nginx/html;
            add_header Content-Type text/html;
            add_header Content-Disposition "inline";
            add_header Cache-Control "no-cache, no-store, must-revalidate";
            try_files /admin.html =404;
        }

        # Frontend static files (must come last)
        location / {
            root /usr/share/nginx/html;
            index index.html;
            try_files $uri $uri/ /index.html;
        }
    }
}

</code>

frontend/app.js:
<code>
// API Configuration
const API_URL = '';

// State
let token = localStorage.getItem('token');
let isSignUp = false;
let files = [];
let activeTab = 'files';
let selectedFileIds = []; // Track selected files for chat filtering
let pollingTimer = null; // For file status polling
let lastUserMessage = ""; // Track for audit

// DOM Elements
const authContainer = document.getElementById('auth-container');
const dashboardContainer = document.getElementById('dashboard-container');
const authForm = document.getElementById('auth-form');
const authError = document.getElementById('auth-error');
const authTitle = document.getElementById('auth-title');
const authSubtitle = document.getElementById('auth-subtitle');
const authBtn = document.getElementById('auth-btn');
const authToggle = document.getElementById('auth-toggle');
const authToggleText = document.getElementById('auth-toggle-text');
const logoutBtn = document.getElementById('logout-btn');
const profileToggle = document.getElementById('profile-toggle');
const profileMenu = document.getElementById('profile-menu');
const userProfileBtn = document.getElementById('user-profile-btn');
const uploadZone = document.getElementById('upload-zone');
const fileInput = document.getElementById('file-input');
const uploadProgress = document.getElementById('upload-progress');
const progressFill = document.getElementById('progress-fill');
const progressPercent = document.getElementById('progress-percent');
const filesGrid = document.getElementById('files-grid');
const emptyState = document.getElementById('empty-state');
const fileCount = document.getElementById('file-count');
const storageFill = document.getElementById('storage-fill');
const refreshBtn = document.getElementById('refresh-btn');
const uploadBtn = document.getElementById('upload-btn');
const filesTab = document.getElementById('files-tab');
const chatTab = document.getElementById('chat-tab');
const chatMessages = document.getElementById('chat-messages');
const chatForm = document.getElementById('chat-form');
const chatInput = document.getElementById('chat-input');
const toast = document.getElementById('toast');

// Initialize
document.addEventListener('DOMContentLoaded', () => {
    setupEventListeners();

    // Check for verification token
    const urlParams = new URLSearchParams(window.location.search);
    const verifyToken = urlParams.get('token');

    if (verifyToken) {
        verifyEmail(verifyToken);
        return; // Skip other checks
    }

    if (token) {
        showDashboard();
        fetchFiles();
    } else {
        showAuth();
    }
});

// Event Listeners
function setupEventListeners() {
    // Auth
    authForm.addEventListener('submit', handleAuth);
    authToggle.addEventListener('click', toggleAuthMode);
    logoutBtn.addEventListener('click', logout);

    // Profile Dropdown
    if (profileToggle && profileMenu) {
        profileToggle.addEventListener('click', (e) => {
            e.stopPropagation();
            profileMenu.classList.toggle('show');
        });

        // Close dropdown when clicking outside
        document.addEventListener('click', (e) => {
            if (!profileMenu.contains(e.target) && !profileToggle.contains(e.target)) {
                profileMenu.classList.remove('show');
            }
        });

        // User Profile button
        if (userProfileBtn) {
            userProfileBtn.addEventListener('click', () => {
                showUserProfile();
            });
        }
    }

    // Upload
    uploadZone.addEventListener('click', () => fileInput.click());
    uploadZone.addEventListener('dragover', handleDragOver);
    uploadZone.addEventListener('dragleave', handleDragLeave);
    uploadZone.addEventListener('drop', handleDrop);
    fileInput.addEventListener('change', handleFileSelect);
    uploadBtn.addEventListener('click', () => fileInput.click());
    refreshBtn.addEventListener('click', fetchFiles);

    // Sidebar tabs + mobile nav
    document.querySelectorAll('.sidebar-item, .mobile-nav-item').forEach(item => {
        item.addEventListener('click', () => switchTab(item.dataset.tab));
    });

    // Chat
    chatForm.addEventListener('submit', handleChat);
    chatInput.addEventListener('input', () => {
        chatForm.querySelector('button').disabled = !chatInput.value.trim();
    });

    // Suggestion buttons
    document.querySelectorAll('.suggestion-btn').forEach(btn => {
        btn.addEventListener('click', () => {
            chatInput.value = btn.textContent;
            chatInput.focus();
            chatForm.querySelector('button').disabled = false;
        });
    });
}

// Auth Functions
function toggleAuthMode(e) {
    e.preventDefault();
    isSignUp = !isSignUp;
    authError.style.display = 'none';

    if (isSignUp) {
        authTitle.textContent = 'Create Account';
        authSubtitle.textContent = 'Start storing and searching your files with AI';
        authBtn.textContent = 'Get Started';
        authToggleText.textContent = 'Already have an account?';
        authToggle.textContent = 'Sign in';
    } else {
        authTitle.textContent = 'Welcome back';
        authSubtitle.textContent = 'Sign in to access your cloud drive';
        authBtn.textContent = 'Sign In';
        authToggleText.textContent = "Don't have an account?";
        authToggle.textContent = 'Sign up';
    }
}

async function handleAuth(e) {
    e.preventDefault();
    const email = document.getElementById('email').value;
    const password = document.getElementById('password').value;

    authBtn.innerHTML = '<span class="loading"></span>';
    authBtn.disabled = true;
    authError.style.display = 'none';
    authError.className = 'auth-error';

    try {
        if (isSignUp) {
            // SIGNUP FLOW
            const res = await fetch(`${API_URL}/auth/register`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ email, password })
            });

            const data = await res.json();
            console.log('DEBUG: Register response status:', res.status);
            console.log('DEBUG: Register response data:', data);

            if (!res.ok) {
                let errorMsg = 'Registration failed';
                if (data.detail) {
                    if (Array.isArray(data.detail)) {
                        // Handle Pydantic validation errors
                        errorMsg = data.detail.map(e => e.msg).join(', ');
                    } else if (typeof data.detail === 'object') {
                        errorMsg = JSON.stringify(data.detail);
                    } else {
                        errorMsg = data.detail;
                    }
                } else if (data.error) {
                    errorMsg = data.error;
                }

                console.log('DEBUG: Final error message:', errorMsg);
                throw new Error(errorMsg);
            }

            // Signup successful - show verification message
            authError.style.display = 'block';
            authError.className = 'auth-error success';
            authError.innerHTML = '‚úÖ Account created! üìß Check your email inbox to verify your account before logging in.';
            authBtn.innerHTML = 'Get Started';
            authBtn.disabled = false;
            setTimeout(() => switchToLogin(), 4000);
            return; // STOP HERE - don't try to login

        } else {
            // LOGIN FLOW
            const formData = new FormData();
            formData.append('username', email);
            formData.append('password', password);

            const response = await fetch(`${API_URL}/auth/login`, {
                method: 'POST',
                body: formData
            });

            const data = await response.json();
            console.log('DEBUG: Login response status:', response.status);
            console.log('DEBUG: Login response data:', data);

            if (!response.ok) {
                // Get the actual error message from backend
                const errorMsg = data.detail || data.error || 'Login failed';
                console.log('DEBUG: Extracted errorMsg:', errorMsg);
                throw new Error(errorMsg);
            }

            // Login successful
            token = data.access_token;
            localStorage.setItem('token', token);
            showDashboard();
            fetchFiles();
        }
    } catch (err) {
        console.log('DEBUG: Caught error:', err);
        const errorMsg = err.message;

        // Check if it's a verification needed message
        if (errorMsg.includes('verify') || errorMsg.includes('email')) {
            authError.className = 'auth-error verification';
            // Add Resend Link
            authError.innerHTML = `
                üìß ${errorMsg.replace('üìß', '').trim()}<br>
                <div style="margin-top: 10px;">
                    <a href="#" onclick="resendVerification(event)" style="text-decoration: underline; font-weight: bold;">
                        Request a new verification link
                    </a>
                </div>
            `;
        } else {
            authError.className = 'auth-error';
            authError.textContent = errorMsg;
        }
        authError.style.display = 'block';
    } finally {
        if (authBtn.disabled) {
            authBtn.innerHTML = isSignUp ? 'Get Started' : 'Sign In';
            authBtn.disabled = false;
        }
    }
}

// Resend Verification Function
async function resendVerification(e) {
    if (e) e.preventDefault();
    const email = document.getElementById('email').value;

    if (!email) {
        alert('Please enter your email address first.');
        return;
    }

    const link = e.target;
    const originalText = link.textContent;
    link.textContent = 'Sending...';
    link.style.pointerEvents = 'none'; // Disable click

    try {
        const response = await fetch(`${API_URL}/auth/resend-verification?email=${encodeURIComponent(email)}`, {
            method: 'POST'
        });

        const data = await response.json();

        if (response.ok) {
            link.textContent = '‚úÖ Sent! Check your inbox.';
            link.style.color = '#155724';
            link.style.textDecoration = 'none';
        } else {
            throw new Error(data.detail || 'Failed to send');
        }
    } catch (err) {
        console.error('Resend failed:', err);
        link.textContent = '‚ùå Failed. Try again.';
        link.style.color = '#721c24';
        setTimeout(() => {
            link.textContent = originalText;
            link.style.pointerEvents = 'auto';
            link.style.color = '';
        }, 3000);
    }
}


async function verifyEmail(tokenStr) {
    // Show loading state
    authContainer.style.display = 'flex';
    dashboardContainer.style.display = 'none';
    authTitle.textContent = 'Verifying Email...';
    authSubtitle.textContent = 'Please wait while we verify your account';
    authForm.style.display = 'none';
    authError.style.display = 'none';

    try {
        const response = await fetch(`${API_URL}/auth/verify-email?token=${tokenStr}`);
        const data = await response.json();

        if (response.ok) {
            // Auto Login
            if (data.access_token) {
                token = data.access_token;
                localStorage.setItem('token', token);
                authError.className = 'auth-error success';
                authError.innerHTML = `‚úÖ ${data.message}<br>Redirecting to dashboard...`;
                authError.style.display = 'block';

                setTimeout(() => {
                    // Remove query params
                    window.history.replaceState({}, document.title, window.location.pathname);
                    showDashboard();
                    fetchFiles();
                }, 2000);
            } else {
                // Fallback if no token returned (legacy)
                authError.className = 'auth-error success';
                authError.textContent = data.message;
                authError.style.display = 'block';
                setTimeout(() => switchToLogin(), 2000);
            }
        } else {
            throw new Error(data.detail || 'Verification failed');
        }
    } catch (err) {
        authTitle.textContent = 'Verification Failed';
        authSubtitle.textContent = 'Please try again or request a new link';
        authError.className = 'auth-error';
        authError.textContent = err.message;
        authError.style.display = 'block';

        // Show login button just in case
        setTimeout(() => {
            authForm.style.display = 'block';
            switchToLogin();
        }, 3000);
    }
}

function logout() {
    token = null;
    localStorage.removeItem('token');
    files = [];
    showAuth();
}

function showAuth() {
    authContainer.style.display = 'flex';
    dashboardContainer.style.display = 'none';
}

function showDashboard() {
    authContainer.style.display = 'none';
    dashboardContainer.style.display = 'flex';
    chatInput.disabled = false;
}



// File Functions
async function fetchFiles() {
    if (pollingTimer) clearTimeout(pollingTimer);

    try {
        const response = await fetch(`${API_URL}/api/files`, {
            headers: { Authorization: `Bearer ${token}` }
        });

        if (!response.ok) throw new Error('Failed to fetch files');

        files = await response.json();
        renderFiles();
        updateDocumentList(); // Update chat document selector

        // Poll if any file is still processing
        const hasProcessing = files.some(f => !f.is_indexed);
        if (hasProcessing) {
            console.log('Files processing... polling in 3s');
            pollingTimer = setTimeout(fetchFiles, 3000);
        }
    } catch (err) {
        console.error(err);
        showToast('Failed to load files: ' + err.message, true);
    }
}

function renderFiles() {
    fileCount.textContent = files.length;
    storageFill.style.width = `${Math.min(files.length * 5, 100)}%`;

    if (files.length === 0) {
        filesGrid.innerHTML = '';
        emptyState.style.display = 'block';
        return;
    }

    emptyState.style.display = 'none';
    filesGrid.innerHTML = files.map(file => {
        const ext = file.filename.split('.').pop().toLowerCase();
        const icon = ext === 'pdf' ? 'üìÑ' : ext === 'txt' ? 'üìù' : 'üìã';
        const size = formatSize(file.size);
        const date = new Date(file.upload_date).toLocaleDateString('en-US', {
            month: 'short', day: 'numeric', year: 'numeric'
        });

        return `
            <div class="file-card" data-id="${file.id}">
                <div class="file-icon ${ext}">${icon}</div>
                <p class="file-name" title="${file.filename}">${file.filename}</p>
                <p class="file-meta">${size} ‚Ä¢ ${date}</p>
                <div class="file-footer">
                    <span class="file-status ${file.is_indexed ? 'indexed' : 'processing'}">
                        ${file.is_indexed ? '‚úì Indexed' : '‚è≥ Processing'}
                    </span>
                    <div class="file-actions">
                        <button class="file-action-btn" onclick="shareFile(${file.id})" title="Share">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <circle cx="18" cy="5" r="3"/><circle cx="6" cy="12" r="3"/><circle cx="18" cy="19" r="3"/>
                                <line x1="8.59" y1="13.51" x2="15.42" y2="17.49"/>
                                <line x1="15.41" y1="6.51" x2="8.59" y2="10.49"/>
                            </svg>
                        </button>
                        <button class="file-action-btn" onclick="downloadFile(${file.id}, '${file.filename}')" title="Download">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4"/>
                                <polyline points="7 10 12 15 17 10"/>
                                <line x1="12" y1="15" x2="12" y2="3"/>
                            </svg>
                        </button>
                        <button class="file-action-btn delete" onclick="deleteFile(${file.id})" title="Delete">
                            <svg width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
                                <polyline points="3 6 5 6 21 6"/>
                                <path d="M19 6v14a2 2 0 0 1-2 2H7a2 2 0 0 1-2-2V6m3 0V4a2 2 0 0 1 2-2h4a2 2 0 0 1 2 2v2"/>
                            </svg>
                        </button>
                    </div>
                </div>
            </div>
        `;
    }).join('');
}

function formatSize(bytes) {
    if (bytes < 1024) return bytes + ' B';
    if (bytes < 1048576) return (bytes / 1024).toFixed(1) + ' KB';
    return (bytes / 1048576).toFixed(1) + ' MB';
}

// Upload Functions
function handleDragOver(e) {
    e.preventDefault();
    uploadZone.classList.add('dragging');
}

function handleDragLeave() {
    uploadZone.classList.remove('dragging');
}

function handleDrop(e) {
    e.preventDefault();
    uploadZone.classList.remove('dragging');
    const file = e.dataTransfer.files[0];
    if (file) uploadFile(file);
}

function handleFileSelect(e) {
    const file = e.target.files[0];
    if (file) uploadFile(file);
}

async function uploadFile(file) {
    uploadProgress.style.display = 'block';
    progressFill.style.width = '0%';
    progressPercent.textContent = '0';

    const formData = new FormData();
    formData.append('file', file);

    try {
        const xhr = new XMLHttpRequest();

        xhr.upload.addEventListener('progress', (e) => {
            if (e.lengthComputable) {
                const percent = Math.round((e.loaded / e.total) * 100);
                progressFill.style.width = percent + '%';
                progressPercent.textContent = percent;
            }
        });

        xhr.onload = () => {
            uploadProgress.style.display = 'none';
            fileInput.value = '';

            if (xhr.status >= 200 && xhr.status < 300) {
                showToast('File uploaded successfully!');
                fetchFiles();
            } else {
                const err = JSON.parse(xhr.responseText);
                showToast(err.detail || 'Upload failed', true);
            }
        };

        xhr.onerror = () => {
            uploadProgress.style.display = 'none';
            showToast('Upload failed', true);
        };

        xhr.open('POST', `${API_URL}/api/upload`);
        xhr.setRequestHeader('Authorization', `Bearer ${token}`);
        xhr.send(formData);
    } catch (err) {
        uploadProgress.style.display = 'none';
        showToast(err.message, true);
    }
}

// File Actions
async function shareFile(fileId) {
    try {
        const response = await fetch(`${API_URL}/api/share`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${token}`
            },
            body: JSON.stringify({ file_id: fileId })
        });

        if (!response.ok) throw new Error('Share failed');

        const data = await response.json();
        const shareUrl = window.location.origin + data.share_url;
        await navigator.clipboard.writeText(shareUrl);
        showToast('Link copied to clipboard!');
    } catch (err) {
        showToast(err.message, true);
    }
}

function downloadFile(fileId, filename) {
    const token = localStorage.getItem('token');

    fetch(`${API_URL}/api/download/${fileId}`, {
        headers: {
            'Authorization': `Bearer ${token}`
        }
    })
        .then(response => {
            if (!response.ok) {
                throw new Error('Download failed');
            }
            return response.blob();
        })
        .then(blob => {
            const url = window.URL.createObjectURL(blob);
            const link = document.createElement('a');
            link.href = url;
            link.download = filename;
            document.body.appendChild(link);
            link.click();
            document.body.removeChild(link);
            window.URL.revokeObjectURL(url);
            showToast('File downloaded successfully');
        })
        .catch(error => {
            console.error('Download error:', error);
            showToast('Failed to download file', true);
        });
}

async function deleteFile(fileId) {
    if (!confirm('Are you sure you want to delete this file?')) return;

    try {
        const response = await fetch(`${API_URL}/api/delete/${fileId}`, {
            method: 'DELETE',
            headers: { Authorization: `Bearer ${token}` }
        });

        if (!response.ok) throw new Error('Delete failed');

        showToast('File deleted');
        fetchFiles();
    } catch (err) {
        showToast(err.message, true);
    }
}

// Chat Functions
async function handleChat(e) {
    e.preventDefault();
    const query = chatInput.value.trim();
    if (!query) return;

    lastUserMessage = query; // Save for audit

    // Clear empty state
    const chatEmpty = chatMessages.querySelector('.chat-empty');
    if (chatEmpty) chatEmpty.remove();

    // Add user message
    addChatMessage(query, 'user');
    chatInput.value = '';
    chatForm.querySelector('button').disabled = true;

    // Add typing indicator
    const typingId = addTypingIndicator();

    try {
        // Build request with optional file filtering
        const requestBody = { query };
        if (selectedFileIds.length > 0) {
            requestBody.file_ids = selectedFileIds;
        }

        const response = await fetch(`${API_URL}/api/query`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${token}`
            },
            body: JSON.stringify(requestBody)
        });

        removeTypingIndicator(typingId);

        if (!response.ok) {
            const err = await response.json();
            throw new Error(err.detail || 'Query failed');
        }

        const data = await response.json();
        addChatMessage(data.answer, 'assistant', data.sources, false, data.contexts);
    } catch (err) {
        removeTypingIndicator(typingId);
        addChatMessage('Sorry, I encountered an error. Please try again.', 'assistant', null, true);
        console.error('Chat error:', err);
    }
}


async function auditAnswer(btn, payload) {
    const scoreSpan = btn.nextElementSibling;

    // UI Loading
    btn.disabled = true;
    btn.innerHTML = "‚è≥ Scanning...";

    try {
        const response = await fetch(`${API_URL}/api/evaluate`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${token}`
            },
            body: JSON.stringify(payload)
        });

        if (!response.ok) throw new Error("Evaluation failed");

        const data = await response.json();
        const score = data.faithfulness;

        // Render Result
        let color = score > 0.7 ? "var(--accent-green)" : "#ea4335";
        let icon = score > 0.7 ? "‚úÖ" : "‚ö†Ô∏è";
        let label = score > 0.7 ? "Likely Accurate" : "Possible Hallucination";

        btn.style.display = 'none';
        scoreSpan.style.display = 'inline-block';
        scoreSpan.innerHTML = `${icon} Faithfulness: <strong style="color:${color}">${(score * 100).toFixed(0)}%</strong>`;

    } catch (err) {
        console.error(err);
        btn.innerHTML = "‚ùå Error";
        btn.disabled = false;
    }
}

function addChatMessage(content, role, sources = null, isError = false, contexts = []) {
    const div = document.createElement('div');
    div.className = `chat-message ${role}`;

    let sourcesHtml = '';
    if (sources && sources.length > 0) {
        sourcesHtml = `
            <div style="margin-top:12px;padding-top:12px;border-top:1px solid var(--border-light);font-size:0.75rem;color:var(--text-muted)">
                <strong>Sources:</strong>
                ${sources.slice(0, 2).map((s, i) => `<div>üìÑ Chunk #${s.metadata?.chunk_index || i}</div>`).join('')}
            </div>
        `;
    }

    let auditHtml = '';
    if (role === 'assistant' && contexts && contexts.length > 0 && !isError) {
        const payload = JSON.stringify({
            question: lastUserMessage,
            answer: content,
            contexts: contexts
        }).replace(/"/g, '&quot;');

        auditHtml = `
            <div class="message-actions" style="margin-top:8px;">
                <button class="btn-audit" onclick="auditAnswer(this, ${payload})">
                    üõ°Ô∏è Check Accuracy
                </button>
                <span class="audit-score" style="display:none"></span>
            </div>
        `;
    }

    div.innerHTML = `
        <div class="message-bubble" ${isError ? 'style="background:#fef2f2;color:#991b1b"' : ''}>
            ${content.replace(/\n/g, '<br>')}
            ${sourcesHtml}
        </div>
        ${auditHtml}
    `;

    chatMessages.appendChild(div);
    chatMessages.scrollTop = chatMessages.scrollHeight;
}

function addTypingIndicator() {
    const id = Date.now();
    const div = document.createElement('div');
    div.className = 'chat-message assistant';
    div.id = `typing-${id}`;
    div.innerHTML = `
        <div class="message-bubble">
            <div class="typing-indicator">
                <span class="typing-dot"></span>
                <span class="typing-dot"></span>
                <span class="typing-dot"></span>
            </div>
        </div>
    `;
    chatMessages.appendChild(div);
    chatMessages.scrollTop = chatMessages.scrollHeight;
    return id;
}

function removeTypingIndicator(id) {
    const el = document.getElementById(`typing-${id}`);
    if (el) el.remove();
}

// Tab Switching
function switchTab(tab) {
    activeTab = tab;
    document.querySelectorAll('.sidebar-item, .mobile-nav-item').forEach(item => {
        item.classList.toggle('active', item.dataset.tab === tab);
    });

    filesTab.style.display = tab === 'files' ? 'block' : 'none';
    chatTab.style.display = tab === 'chat' ? 'block' : 'none';
}

// Toast Notifications
function showToast(message, isError = false) {
    toast.textContent = message;
    toast.className = 'toast show';
    if (isError) toast.classList.add('error');

    setTimeout(() => {
        toast.classList.remove('show');
        if (isError) toast.classList.remove('error');
    }, 3000);
}


// Document Selector Functions
function updateDocumentList() {
    const docList = document.getElementById('doc-list');
    if (!files || files.length === 0) {
        docList.innerHTML = '<div style="padding: 8px; color: var(--text-muted); font-size: 0.8125rem;">No files uploaded yet</div>';
        return;
    }

    docList.innerHTML = files.map(file => `
        <label class="doc-checkbox ${selectedFileIds.includes(file.id) ? 'selected' : ''}">
            <input type="checkbox" 
                   value="${file.id}" 
                   ${selectedFileIds.includes(file.id) ? 'checked' : ''}
                   onchange="toggleFileSelection(${file.id})">
            ${file.filename}
        </label>
    `).join('');

    updateSelectedCount();
}

function toggleFileSelection(fileId) {
    const index = selectedFileIds.indexOf(fileId);
    if (index > -1) {
        selectedFileIds.splice(index, 1);
    } else {
        selectedFileIds.push(fileId);
    }
    updateDocumentList();
}

function selectAllDocs() {
    selectedFileIds = files.map(f => f.id);
    updateDocumentList();
}

function clearAllDocs() {
    selectedFileIds = [];
    updateDocumentList();
}

function updateSelectedCount() {
    const countEl = document.getElementById('selected-count');
    if (selectedFileIds.length === 0) {
        countEl.textContent = 'All documents';
    } else if (selectedFileIds.length === files.length) {
        countEl.textContent = `All ${files.length} documents`;
    } else {
        countEl.textContent = `${selectedFileIds.length} of ${files.length} documents`;
    }
}

// Add event listeners for document selector
document.getElementById('select-all-docs')?.addEventListener('click', selectAllDocs);
document.getElementById('clear-all-docs')?.addEventListener('click', clearAllDocs);

/* User Profile Logic */
function showUserProfile() {
    // Hide dropdown
    const profileMenu = document.getElementById('profile-menu');
    if (profileMenu) profileMenu.classList.remove('show');

    // Show Modal
    const modal = document.getElementById('profile-modal');
    if (modal) {
        modal.classList.add('show');
        modal.style.visibility = 'visible';
        modal.style.opacity = '1';
    }

    // Fetch Data
    const token = localStorage.getItem('token');
    // Ensure API_URL is defined (it is global constant at top usually, but verify)
    // Assuming API_URL is global. If not, use relative /api/
    const url = typeof API_URL !== 'undefined' ? `${API_URL}/auth/me` : '/auth/me';

    fetch(url, {
        headers: { Authorization: `Bearer ${token}` }
    })
        .then(res => res.json())
        .then(data => {
            if (data.email) {
                document.getElementById('profile-email').textContent = data.email;
                document.getElementById('profile-role').textContent = data.role === 'admin' ? 'Administrator' : 'Standard User';
                document.getElementById('profile-date').textContent = new Date(data.created_at).toLocaleDateString();
            } else {
                showToast('Failed to load profile data', true);
            }
        })
        .catch(err => {
            showToast('Failed to load profile', true);
            console.error(err);
        });
}

function closeProfileModal() {
    const modal = document.getElementById('profile-modal');
    if (modal) {
        modal.classList.remove('show');
        modal.style.visibility = 'hidden';
        modal.style.opacity = '0';
    }
}

</code>

backend/migrate.py:
<code>

from sqlalchemy import create_engine, text
from app.config import settings

def run_migration():
    print("Running migration...")
    engine = create_engine(settings.DATABASE_URL)
    
    with engine.connect() as conn:
        conn.execution_options(isolation_level="AUTOCOMMIT")
        
        # Add can_upload to users
        try:
            print("Adding can_upload column...")
            conn.execute(text("ALTER TABLE users ADD COLUMN IF NOT EXISTS can_upload BOOLEAN DEFAULT TRUE;"))
            print("Column added.")
        except Exception as e:
            print(f"Error adding column (might exist): {e}")

        # Create audit_logs table
        try:
            print("Creating audit_logs table...")
            conn.execute(text("""
            CREATE TABLE IF NOT EXISTS audit_logs (
                id SERIAL PRIMARY KEY,
                timestamp TIMESTAMP WITHOUT TIME ZONE DEFAULT (now() at time zone 'utc'),
                actor_id INTEGER,
                action VARCHAR,
                target_id INTEGER,
                target_type VARCHAR,
                metadata_json VARCHAR,
                FOREIGN KEY (actor_id) REFERENCES users(id)
            );
            """))
            print("Table created.")
        except Exception as e:
            print(f"Error creating table: {e}")

if __name__ == "__main__":
    run_migration()

</code>

backend/app/auth.py:
<code>
from datetime import datetime, timedelta
from typing import Optional
from jose import JWTError, jwt
from passlib.context import CryptContext
from fastapi import Depends, HTTPException, status
from fastapi.security import OAuth2PasswordBearer
from sqlalchemy.orm import Session
from .config import settings
from . import database, models, schemas

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def verify_password(plain_password, hashed_password):
    # Truncate to 72 bytes for bcrypt compatibility
    return pwd_context.verify(plain_password[:72], hashed_password)

def get_password_hash(password):
    # Truncate to 72 bytes for bcrypt compatibility
    return pwd_context.hash(password[:72])

def create_access_token(data: dict, expires_delta: Optional[timedelta] = None):
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)
    return encoded_jwt

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="auth/login")

def get_current_user(token: str = Depends(oauth2_scheme), db: Session = Depends(database.get_db)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        email: str = payload.get("sub")
        role: str = payload.get("role")
        
        if email is None:
            raise credentials_exception
        
        # Handle admin tokens specially - they don't have DB entries
        if role == "admin":
            # Create a mock user object for admin
            admin_user = models.User(
                id=0,  # Special ID for admin
                email=email,
                is_active=True,
                can_upload=True
            )
            return admin_user
        
        # Regular user lookup
        token_data = schemas.TokenData(email=email)
        user = db.query(models.User).filter(models.User.email == token_data.email).first()
        if user is None:
            raise credentials_exception
        return user
    except JWTError:
        raise credentials_exception

def get_admin_user(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
        role: str = payload.get("role")
        if role != "admin":
             raise HTTPException(status_code=403, detail="Not an admin")
        # Return a mock admin user object with id attribute
        admin_user = models.User(
            id=0,  # Special admin ID
            email=payload.get("sub", "admin"),
            is_active=True,
            can_upload=True
        )
        return admin_user
    except JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Could not validate admin credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

</code>

backend/app/config.py:
<code>
from pydantic_settings import BaseSettings
from typing import Optional
import os

class Settings(BaseSettings):
    # Environment
    ENVIRONMENT: str = "development"  # development, staging, production
    DEBUG: bool = True
    
    # Database
    DATABASE_URL: str
    DATABASE_POOL_SIZE: int = 5
    DATABASE_MAX_OVERFLOW: int = 10
    
    # Security
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    REFRESH_TOKEN_EXPIRE_DAYS: int = 7
    
    # Admin Credentials (MUST be set via .env)
    ADMIN_USERNAME: str = ""
    ADMIN_PASSWORD: str = ""
    
    # MinIO
    MINIO_ENDPOINT: str
    MINIO_ACCESS_KEY: str
    MINIO_SECRET_KEY: str
    MINIO_SECURE: bool = False
    
    # ChromaDB
    CHROMA_HOST: str = "chromadb"
    CHROMA_PORT: int = 8000
    
    # Redis
    REDIS_URL: str = "redis://redis:6379/0"
    CACHE_TTL: int = 300  # 5 minutes
    
    # Groq API (LLM) - MUST be set via .env
    GROQ_API_KEY: str = ""
    GROQ_MODEL: str = "llama-3.3-70b-versatile"
    GROQ_TIMEOUT: int = 30
    
    # File Upload
    MAX_FILE_SIZE: int = 50 * 1024 * 1024  # 50MB
    ALLOWED_EXTENSIONS: str = ".pdf,.txt,.md"
    
    # Rate Limiting
    RATE_LIMIT_PER_MINUTE: int = 60
    
    # CORS
    CORS_ORIGINS: str = "http://localhost:3000,http://localhost"
    
    # Logging
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = "json"  # json or text
    
    # Email Configuration (for Magic Links)
    SMTP_SERVER: str = "smtp.gmail.com"
    SMTP_PORT: int = 587
    SMTP_USERNAME: str = ""  # Set via .env for real email
    SMTP_PASSWORD: str = ""  # Set via .env (Gmail app password)
    EMAIL_FROM: str = "noreply@clouddrive.com"
    
    # Security Settings
    REQUIRE_EMAIL_VERIFICATION: bool = True  # Email verification enabled
    PASSWORD_MIN_LENGTH: int = 8
    MAX_LOGIN_ATTEMPTS: int = 5
    LOCKOUT_DURATION_MINUTES: int = 30
    VERIFICATION_TOKEN_EXPIRE_HOURS: int = 24
    
    # Rate Limiting (Auth)
    SIGNUP_RATE_LIMIT: str = "3/hour"
    LOGIN_RATE_LIMIT: str = "5/15minutes"
    
    # Google OAuth (optional)
    GOOGLE_CLIENT_ID: str = ""
    GOOGLE_CLIENT_SECRET: str = ""
    GOOGLE_REDIRECT_URI: str = "http://localhost:3000/auth/google/callback"
    
    @property
    def cors_origins_list(self) -> list:
        return [origin.strip() for origin in self.CORS_ORIGINS.split(",")]
    
    @property
    def allowed_extensions_list(self) -> list:
        return [ext.strip() for ext in self.ALLOWED_EXTENSIONS.split(",")]
    
    @property
    def is_production(self) -> bool:
        return self.ENVIRONMENT == "production"
    
    class Config:
        env_file = ".env"
        case_sensitive = True

settings = Settings()

</code>

backend/app/logging_config.py:
<code>
import logging
import sys
from datetime import datetime

# Configure structured logging
class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_record = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        if hasattr(record, 'request_id'):
            log_record['request_id'] = record.request_id
        if record.exc_info:
            log_record['exception'] = self.formatException(record.exc_info)
        return str(log_record)

def setup_logging(log_level: str = "INFO"):
    """Configure application logging"""
    logger = logging.getLogger("ai_cloud_drive")
    logger.setLevel(getattr(logging, log_level.upper()))
    
    # Console handler with JSON format
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(JSONFormatter())
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

</code>

backend/app/models.py:
<code>
from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, Boolean
from sqlalchemy.orm import relationship
from datetime import datetime
from .database import Base

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String, unique=True, index=True)
    hashed_password = Column(String, nullable=True)  # Nullable for passwordless users
    google_id = Column(String, unique=True, nullable=True, index=True)  # Google OAuth ID
    name = Column(String, nullable=True)  # User display name
    profile_photo = Column(String, nullable=True)  # MinIO path to profile photo
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    last_login = Column(DateTime, nullable=True)
    
    # Magic Link (Passwordless Auth)
    magic_link_token = Column(String, nullable=True, index=True)
    magic_link_expires = Column(DateTime, nullable=True)
    
    # Email verification (auto-verified for OAuth/Magic Link users)
    is_verified = Column(Boolean, default=False)
    verification_token = Column(String, nullable=True)
    verification_sent_at = Column(DateTime, nullable=True)
    
    # Account security
    failed_login_attempts = Column(Integer, default=0)
    locked_until = Column(DateTime, nullable=True)
    can_upload = Column(Boolean, default=True) # Admin control

    files = relationship("File", back_populates="owner")
    chats = relationship("ChatHistory", back_populates="user")


class AuditLog(Base):
    __tablename__ = "audit_logs"

    id = Column(Integer, primary_key=True, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow)
    actor_id = Column(Integer, ForeignKey("users.id"), nullable=True) # Admin or System (null)
    action = Column(String) # e.g. "suspend_user", "delete_file"
    target_id = Column(Integer, nullable=True) # ID of affected user/file
    target_type = Column(String, nullable=True) # "user", "file"
    metadata_json = Column(String, nullable=True) # JSON details

    actor = relationship("User", foreign_keys=[actor_id])



class ChatHistory(Base):
    __tablename__ = "chat_history"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"))
    query = Column(String)
    answer = Column(String)
    timestamp = Column(DateTime, default=datetime.utcnow)

    user = relationship("User", back_populates="chats")

class File(Base):
    __tablename__ = "files"

    id = Column(Integer, primary_key=True, index=True)
    filename = Column(String, index=True)
    file_path = Column(String) # MinIO path
    content_type = Column(String)
    size = Column(Integer)
    upload_date = Column(DateTime, default=datetime.utcnow)
    is_indexed = Column(Boolean, default=False)
    share_token = Column(String, unique=True, nullable=True) # For public sharing
    
    owner_id = Column(Integer, ForeignKey("users.id"))
    owner = relationship("User", back_populates="files")

class FileShare(Base):
    __tablename__ = "file_shares"
    
    id = Column(Integer, primary_key=True, index=True)
    file_id = Column(Integer, ForeignKey("files.id"))
    shared_with_id = Column(Integer, ForeignKey("users.id"))
    permission = Column(String, default="read") # read, write
    created_at = Column(DateTime, default=datetime.utcnow)


</code>

backend/app/validators.py:
<code>
import re
import html
from typing import Optional
from pydantic import validator
from fastapi import HTTPException

# Password requirements
PASSWORD_MIN_LENGTH = 6

def validate_password_strength(password: str) -> str:
    """Validate password meets security requirements"""
    if len(password) < PASSWORD_MIN_LENGTH:
        raise ValueError(f"Password must be at least {PASSWORD_MIN_LENGTH} characters")
    return password

def sanitize_filename(filename: str) -> str:
    """Sanitize filename to prevent path traversal and injection"""
    # Remove any path components
    filename = filename.replace('/', '').replace('\\', '')
    # Remove null bytes
    filename = filename.replace('\x00', '')
    # Only allow alphanumeric, dots, dashes, underscores
    filename = re.sub(r'[^a-zA-Z0-9._-]', '_', filename)
    # Prevent hidden files
    if filename.startswith('.'):
        filename = '_' + filename[1:]
    # Limit length
    if len(filename) > 255:
        name, ext = filename.rsplit('.', 1) if '.' in filename else (filename, '')
        filename = name[:250] + ('.' + ext if ext else '')
    return filename

def sanitize_query(query: str, max_length: int = 1000) -> str:
    """Sanitize user query input"""
    # Trim whitespace
    query = query.strip()
    # Limit length
    if len(query) > max_length:
        query = query[:max_length]
    # Escape HTML entities
    query = html.escape(query)
    return query

def validate_email_domain(email: str, blocked_domains: list = None) -> str:
    """Validate email domain is not in blocklist"""
    blocked = blocked_domains or ['tempmail.com', 'throwaway.com', 'guerrillamail.com']
    domain = email.split('@')[-1].lower()
    if domain in blocked:
        raise ValueError("Disposable email addresses are not allowed")
    return email

# SQL injection prevention patterns
SQL_INJECTION_PATTERNS = [
    r"(\%27)|(\')|(\-\-)|(\%23)|(#)",
    r"((\%3D)|(=))[^\n]*((\%27)|(\')|(\-\-)|(\%3B)|(;))",
    r"\w*((\%27)|(\'))((\%6F)|o|(\%4F))((\%72)|r|(\%52))",
    r"((\%27)|(\'))union",
]

def check_sql_injection(value: str) -> bool:
    """Check for SQL injection patterns"""
    for pattern in SQL_INJECTION_PATTERNS:
        if re.search(pattern, value, re.IGNORECASE):
            return True
    return False

def validate_input(value: str, field_name: str = "input") -> str:
    """Validate input for common attacks"""
    if check_sql_injection(value):
        raise HTTPException(status_code=400, detail=f"Invalid {field_name}: potentially malicious content detected")
    return value

</code>

backend/app/database.py:
<code>
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import QueuePool
from .config import settings

SQLALCHEMY_DATABASE_URL = settings.DATABASE_URL

# Production-ready connection pooling
engine = create_engine(
    SQLALCHEMY_DATABASE_URL,
    poolclass=QueuePool,
    pool_size=settings.DATABASE_POOL_SIZE,
    max_overflow=settings.DATABASE_MAX_OVERFLOW,
    pool_pre_ping=True,  # Verify connections before use
    pool_recycle=3600,   # Recycle connections after 1 hour
    echo=settings.DEBUG  # Log SQL in debug mode
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()

def get_db():
    """Database session dependency with proper cleanup"""
    db = SessionLocal()
    try:
        yield db
    except Exception:
        db.rollback()
        raise
    finally:
        db.close()

</code>

backend/app/cache.py:
<code>
import redis
import json
import hashlib
from typing import Optional, Any
from functools import wraps
from .config import settings

class RedisCache:
    """Redis caching utility for query results"""
    
    def __init__(self):
        self.client = redis.from_url(settings.REDIS_URL, decode_responses=True)
        self.default_ttl = 300  # 5 minutes
    
    def _make_key(self, prefix: str, *args, **kwargs) -> str:
        """Generate cache key from arguments"""
        key_data = json.dumps({"args": args, "kwargs": kwargs}, sort_keys=True)
        key_hash = hashlib.md5(key_data.encode()).hexdigest()[:12]
        return f"{prefix}:{key_hash}"
    
    def get(self, key: str) -> Optional[Any]:
        """Get value from cache"""
        try:
            value = self.client.get(key)
            if value:
                return json.loads(value)
        except Exception as e:
            print(f"Cache get error: {e}")
        return None
    
    def set(self, key: str, value: Any, ttl: int = None) -> bool:
        """Set value in cache"""
        try:
            self.client.setex(
                key,
                ttl or self.default_ttl,
                json.dumps(value)
            )
            return True
        except Exception as e:
            print(f"Cache set error: {e}")
            return False
    
    def delete(self, key: str) -> bool:
        """Delete key from cache"""
        try:
            self.client.delete(key)
            return True
        except Exception as e:
            print(f"Cache delete error: {e}")
            return False
    
    def invalidate_user_cache(self, user_id: int):
        """Invalidate all cache for a user"""
        try:
            pattern = f"user:{user_id}:*"
            keys = self.client.keys(pattern)
            if keys:
                self.client.delete(*keys)
        except Exception as e:
            print(f"Cache invalidation error: {e}")

# Singleton instance
cache = RedisCache()

def cached(prefix: str, ttl: int = 300):
    """Decorator for caching function results"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Skip cache for certain conditions
            skip_cache = kwargs.pop('skip_cache', False)
            if skip_cache:
                return await func(*args, **kwargs)
            
            cache_key = cache._make_key(prefix, *args, **kwargs)
            
            # Try to get from cache
            cached_result = cache.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # Execute function and cache result
            result = await func(*args, **kwargs)
            cache.set(cache_key, result, ttl)
            return result
        return wrapper
    return decorator

</code>

backend/app/__init__.py:
<code>
# App package

</code>

backend/app/schemas.py:
<code>
from pydantic import BaseModel, EmailStr
from typing import Optional, List
from datetime import datetime

class UserBase(BaseModel):
    email: EmailStr

class UserCreate(UserBase):
    password: str

class User(UserBase):
    id: int
    is_active: bool
    is_verified: bool
    name: Optional[str] = None
    profile_photo: Optional[str] = None
    created_at: Optional[datetime] = None

    class Config:
        from_attributes = True

class Token(BaseModel):
    access_token: str
    token_type: str

class TokenData(BaseModel):
    email: Optional[str] = None

class FileBase(BaseModel):
    filename: str

class File(FileBase):
    id: int
    content_type: str
    size: int
    upload_date: datetime
    is_indexed: bool
    owner_id: int
    share_token: Optional[str] = None

    class Config:
        from_attributes = True

# Profile Management
class ProfileUpdate(BaseModel):
    name: Optional[str] = None


</code>

backend/app/main.py:
<code>
from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded
from starlette.exceptions import HTTPException as StarletteHTTPException
import traceback

from .database import engine, Base
from .config import settings
from .routes import auth, files, query, share, admin, profile  # , google_auth, magic_auth - TODO: Uncomment after build
from .middleware import SecurityHeadersMiddleware, RequestIDMiddleware
from .logging_config import logger

# Create tables
Base.metadata.create_all(bind=engine)

# Rate limiter
limiter = Limiter(
    key_func=get_remote_address,
    default_limits=[f"{settings.RATE_LIMIT_PER_MINUTE}/minute"]
)

app = FastAPI(
    title="AI Cloud Drive",
    description="Self-hosted file storage with AI-powered search",
    version="1.0.0",
    docs_url="/docs" if settings.DEBUG else None,  # Disable docs in production
    redoc_url="/redoc" if settings.DEBUG else None,
)


# Rate limiter
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# Security middleware
app.add_middleware(SecurityHeadersMiddleware)
app.add_middleware(RequestIDMiddleware)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.cors_origins_list,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS"],
    allow_headers=["*"],
    max_age=600,  # Cache preflight for 10 minutes
)

# Global exception handlers
@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request: Request, exc: StarletteHTTPException):
    request_id = getattr(request.state, 'request_id', 'unknown')
    logger.error(f"HTTP {exc.status_code}: {exc.detail}", extra={"request_id": request_id})
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "request_id": request_id
        }
    )

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request: Request, exc: RequestValidationError):
    request_id = getattr(request.state, 'request_id', 'unknown')
    logger.warning(f"Validation error: {exc.errors()}", extra={"request_id": request_id})
    return JSONResponse(
        status_code=422,
        content={
            "error": "Validation error",
            "details": exc.errors(),
            "request_id": request_id
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    request_id = getattr(request.state, 'request_id', 'unknown')
    logger.error(
        f"Unhandled exception: {str(exc)}\n{traceback.format_exc()}",
        extra={"request_id": request_id}
    )
    # Don't expose internal errors in production
    error_message = str(exc) if settings.DEBUG else "Internal server error"
    return JSONResponse(
        status_code=500,
        content={
            "error": error_message,
            "request_id": request_id
        }
    )

# Include routers
app.include_router(auth.router)
# app.include_router(google_auth.router)  # TODO: Uncomment after build completes
# app.include_router(magic_auth.router)  # TODO: Uncomment after build completes
app.include_router(files.router)
app.include_router(query.router)
app.include_router(share.router)
app.include_router(admin.router)
app.include_router(profile.router)

@app.get("/")
def read_root():
    return {
        "message": "Welcome to AI Cloud Drive API",
        "version": "1.0.0",
        "environment": settings.ENVIRONMENT
    }

@app.get("/health")
def health_check():
    """Health check endpoint for load balancers and orchestrators"""
    return {
        "status": "healthy",
        "environment": settings.ENVIRONMENT,
        "debug": settings.DEBUG
    }

@app.get("/ready")
def readiness_check():
    """Readiness check - verify all dependencies are available"""
    checks = {"database": False, "redis": False, "minio": False}
    
    # Check database
    try:
        from .database import SessionLocal
        db = SessionLocal()
        db.execute("SELECT 1")
        db.close()
        checks["database"] = True
    except Exception:
        pass
    
    # Check Redis
    try:
        from .cache import cache
        cache.client.ping()
        checks["redis"] = True
    except Exception:
        pass
    
    # Check MinIO
    try:
        from .storage.minio_client import minio_client
        minio_client.client.list_buckets()
        checks["minio"] = True
    except Exception:
        pass
    
    all_ready = all(checks.values())
    return JSONResponse(
        status_code=200 if all_ready else 503,
        content={"ready": all_ready, "checks": checks}
    )

</code>

backend/app/middleware.py:
<code>
from fastapi import Request
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import Response
import uuid
import time
from .logging_config import logger

class SecurityHeadersMiddleware(BaseHTTPMiddleware):
    """Add security headers to all responses"""
    
    async def dispatch(self, request: Request, call_next):
        response = await call_next(request)
        
        # Security headers
        response.headers["X-Content-Type-Options"] = "nosniff"
        response.headers["X-Frame-Options"] = "DENY"
        response.headers["X-XSS-Protection"] = "1; mode=block"
        response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"
        response.headers["Permissions-Policy"] = "geolocation=(), microphone=(), camera=()"
        
        # Content Security Policy - Allow scripts from same origin and inline
        response.headers["Content-Security-Policy"] = (
            "default-src 'self'; "
            "script-src 'self' 'unsafe-inline'; "
            "style-src 'self' 'unsafe-inline' https://fonts.googleapis.com; "
            "font-src 'self' https://fonts.gstatic.com; "
            "img-src 'self' data: blob:; "
            "connect-src 'self'; "
            "frame-ancestors 'none'; "
            "base-uri 'self'; "
            "form-action 'self'"
        )
        
        # Cache control for API responses
        if request.url.path.startswith("/api"):
            response.headers["Cache-Control"] = "no-store, no-cache, must-revalidate"
            response.headers["Pragma"] = "no-cache"
        
        return response

class RequestIDMiddleware(BaseHTTPMiddleware):
    """Add unique request ID for tracking"""
    
    async def dispatch(self, request: Request, call_next):
        request_id = str(uuid.uuid4())[:8]
        request.state.request_id = request_id
        
        start_time = time.time()
        response = await call_next(request)
        process_time = time.time() - start_time
        
        response.headers["X-Request-ID"] = request_id
        response.headers["X-Process-Time"] = str(round(process_time * 1000, 2))
        
        # Log request
        logger.info(
            f"{request.method} {request.url.path} - {response.status_code} - {round(process_time * 1000, 2)}ms",
            extra={"request_id": request_id}
        )
        
        return response

class HTTPSRedirectMiddleware(BaseHTTPMiddleware):
    """Redirect HTTP to HTTPS in production"""
    
    async def dispatch(self, request: Request, call_next):
        # Only redirect in production (when X-Forwarded-Proto is set)
        forwarded_proto = request.headers.get("X-Forwarded-Proto")
        if forwarded_proto == "http":
            url = request.url.replace(scheme="https")
            return Response(status_code=301, headers={"Location": str(url)})
        return await call_next(request)

</code>

backend/app/tasks/celery_app.py:
<code>
from celery import Celery
from ..config import settings
from ..storage.minio_client import minio_client
from ..rag import indexer
from ..database import SessionLocal
from .. import models

celery = Celery(
    "tasks",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL
)

@celery.task
def process_file_task(file_id: int, object_name: str, content_type: str, user_id: int):
    print(f"Starting background processing for file {file_id}")
    
    # 1. Download file content from MinIO
    try:
        response = minio_client.get_file_content(object_name)
        file_content = response.read()
        response.close()
        response.release_conn()
    except Exception as e:
        print(f"Error downloading file from MinIO: {e}")
        return

    # 2. Process and Index
    try:
        indexer.process_and_index_file(file_id, file_content, content_type, user_id)
        
        # 3. Update DB status
        db = SessionLocal()
        try:
            db_file = db.query(models.File).filter(models.File.id == file_id).first()
            if db_file:
                db_file.is_indexed = True
                db.commit()
                print(f"Successfully indexed file {file_id}")
        finally:
            db.close()
            
    except Exception as e:
        print(f"Error processing file {file_id}: {e}")

</code>

backend/app/tasks/__init__.py:
<code>
# Tasks package

</code>

backend/app/rag/__init__.py:
<code>
# RAG package

</code>

backend/app/rag/llm.py:
<code>
import requests
from typing import List, Dict
from ..config import settings
import logging

logger = logging.getLogger(__name__)

# Production-grade system prompt
SYSTEM_PROMPT = """You are an expert AI research assistant helping users understand and analyze their documents.

Your responsibilities:
1. Provide accurate, comprehensive answers based ONLY on the provided context
2. Cite specific sections when making claims
3. If the context doesn't contain enough information, clearly state this
4. Use clear, professional language
5. Organize complex information into structured responses

Guidelines:
- Be precise and factual
- Use bullet points for clarity when appropriate
- Quote relevant passages when helpful
- Acknowledge limitations in the available information
- If asked tocompare or analyze, provide balanced insights
"""

def _format_context(chunks: List[Dict]) -> str:
    """Format chunks into well-structured context."""
    if not chunks:
        return "No relevant context found."
    
    context_parts = []
    for idx, chunk in enumerate(chunks, 1):
        metadata = chunk.get("metadata", {})
        content = chunk.get("content", "")
        
        # Add metadata if available
        meta_info = []
        if "section_heading" in metadata:
            meta_info.append(f"Section: {metadata['section_heading']}")
        if "position" in metadata:
            meta_info.append(f"Position: {metadata['position']}")
        
        meta_str = f" ({', '.join(meta_info)})" if meta_info else ""
        
        context_parts.append(f"[Source {idx}{meta_str}]\n{content}\n")
    
    return "\n---\n".join(context_parts)

def generate_response(query: str, context_chunks: List[Dict]) -> str:
    """
    Generate high-quality response using Groq API.
    
    Uses production-grade prompt engineering for better answers.
    """
    # Format context with structure
    context = _format_context(context_chunks)
    
    # Limit context size
    MAX_CONTEXT_LENGTH = 8000
    if len(context) > MAX_CONTEXT_LENGTH:
        context = context[:MAX_CONTEXT_LENGTH] + "\n\n[Context truncated due to length...]"
    
    # Build messages with production prompt
    messages = [
        {
            "role": "system",
            "content": SYSTEM_PROMPT
        },
        {
            "role": "user",
            "content": f"""Context from documents:
{context}

Question: {query}

Please provide a comprehensive answer based on the context above. If the context contains relevant information, explain it clearly and cite specific sources. If the information is incomplete or missing, state this explicitly."""
        }
    ]
    
    try:
        response = requests.post(
            "https://api.groq.com/openai/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {settings.GROQ_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": settings.GROQ_MODEL,
                "messages": messages,
                "temperature": 0.3,  # Lower for more focused answers
                "max_tokens": 1024,
                "top_p": 0.95
            },
            timeout=settings.GROQ_TIMEOUT
        )
        response.raise_for_status()
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            return result["choices"][0]["message"]["content"]
        else:
            return "No response generated."
            
    except requests.exceptions.HTTPError as e:
        error_detail = ""
        try:
            error_detail = e.response.json()
            logger.error(f"Groq API error: {error_detail}")
        except:
            logger.error(f"Groq API error: {e.response.text}")
        
        if e.response.status_code == 400:
            return "Error: Invalid request to AI service. The context may be too complex. Try a simpler question."
        elif e.response.status_code == 401:
            return "Error: Invalid Groq API key."
        elif e.response.status_code == 429:
            return "Error: Groq API rate limit exceeded. Please try again later."
        else:
            return f"Error: Groq API returned {e.response.status_code}"
    except requests.exceptions.ConnectionError:
        return "Error: Could not connect to Groq API. Check your internet connection."
    except requests.exceptions.Timeout:
        return "Error: Groq API request timed out."
    except Exception as e:
        logger.error(f"Unexpected error in generate_response: {str(e)}")
        return f"Error generating response: {str(e)}"

</code>

backend/app/rag/engine.py:
<code>
from typing import List, Dict, Optional
from .indexer import get_collection, embedding_model
from .retrievers.reranker import reranker
import logging

logger = logging.getLogger(__name__)

from .retrievers.hybrid import hybrid_retriever

def query_documents(query_text: str, user_id: int, file_ids: Optional[List[int]] = None, n_results: int = 3) -> List[Dict]:
    """
    Research-Grade query with Hybrid Search & Re-ranking (Phase 3).
    """
    logger.info(f"Querying: '{query_text}' for user {user_id}")
    
    # 1. Embed Query (for Vector Search)
    query_embedding = embedding_model.encode([query_text]).tolist()
    
    # 2. Build ChromaDB filter
    where_filter = {"user_id": user_id}
    
    # 3. Parallel Search: Vector + BM25
    collection = get_collection()
    initial_n = n_results * 5 if file_ids else n_results * 3
    
    # A. Vector Search
    vector_results_raw = collection.query(
        query_embeddings=query_embedding,
        n_results=initial_n,
        where=where_filter
    )
    
    vector_candidates = []
    if vector_results_raw["documents"] and vector_results_raw["documents"][0]:
        for i in range(len(vector_results_raw["documents"][0])):
            metadata = vector_results_raw["metadatas"][0][i]
            if file_ids and metadata.get("file_id") not in file_ids:
                continue
            vector_candidates.append({
                "content": vector_results_raw["documents"][0][i],
                "metadata": metadata,
                "score": vector_results_raw["distances"][0][i]
            })

    # B. BM25 Search
    # Note: Currently searches ALL docs in memory index. Filter by user_id post-hoc if needed.
    # For now, simplistic integration:
    bm25_candidates_raw = hybrid_retriever.search_bm25(query_text, k=initial_n)
    bm25_candidates = [
        res for res in bm25_candidates_raw 
        if res["metadata"].get("user_id") == user_id and 
        (not file_ids or res["metadata"].get("file_id") in file_ids)
    ]
    
    # 4. Fuse Results (RRF)
    candidates = hybrid_retriever.reciprocal_rank_fusion(vector_candidates, bm25_candidates)
    
    logger.info(f"Hybrid Search: {len(vector_candidates)} vector, {len(bm25_candidates)} bm25 -> {len(candidates)} fused")
    
    # 5. Re-rank for precision
    if candidates:
        # Limit to reasonable number before expensive re-ranking
        rerank_input = candidates[:initial_n] 
        reranked = reranker.rerank(query_text, rerank_input, top_k=n_results)
        
        # Expand Context: Swap Content with Parent if available
        final_results = []
        for res in reranked:
            metadata = res.get("metadata", {})
            if metadata.get("is_child", False) and metadata.get("parent_content"):
                res["content"] = metadata["parent_content"]
            final_results.append(res)
            
        return final_results
    
    return []

</code>

backend/app/rag/indexer.py:
<code>
import io
import tempfile
import os
from pydantic import BaseModel
from typing import List, Optional
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer
from pypdf import PdfReader
from ..config import settings
from .parsers.pdf_parser import pdf_parser
from .parsers.chunker import semantic_chunker
import logging

logger = logging.getLogger(__name__)

# Initialize ChromaDB Client (Lazy)
_chroma_client = None
_collection = None

def get_collection():
    global _chroma_client, _collection
    if _collection is None:
        _chroma_client = chromadb.HttpClient(host=settings.CHROMA_HOST, port=8000)
        _collection = _chroma_client.get_or_create_collection(name="documents")
    return _collection

# Initialize Embedding Model
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

class DocumentChunk(BaseModel):
    id: str
    text: str
    metadata: dict
    embedding: Optional[List[float]] = None

def extract_text_from_file(file_content: bytes, content_type: str, file_id: int) -> tuple:
    """
    Extract text using production-grade parsers.
    
    Returns:
        Tuple of (text, metadata)
    """
    if "pdf" in content_type.lower():
        # Use advanced PDF parser
        try:
            # Save to temp file (PyMuPDF requires file path)
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(file_content)
                tmp_path = tmp_file.name
            
            try:
                result = pdf_parser.parse_pdf(tmp_path)
                
                if result["success"]:
                    logger.info(f"Successfully parsed PDF: {len(result['text'])} chars, {len(result['tables'])} tables")
                    return result["text"], result["metadata"]
                else:
                    logger.error(f"PDF parsing failed: {result.get('error', 'Unknown error')}")
                    # Fallback to basic extraction
                    return _fallback_pdf_extract(file_content), {}
            finally:
                # Clean up temp file
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)
                    
        except Exception as e:
            logger.error(f"Advanced PDF extraction failed: {str(e)}, falling back to basic extraction")
            return _fallback_pdf_extract(file_content), {}
            
    elif "text" in content_type or "markdown" in content_type:
        text = file_content.decode("utf-8", errors="ignore")
        return text, {"content_type": content_type}
    else:
        return "", {}

def _fallback_pdf_extract(file_content: bytes) -> str:
    """Fallback PDF extraction using pypdf."""
    try:
        reader = PdfReader(io.BytesIO(file_content))
        text = ""
        for page in reader.pages:
            text += page.extract_text() + "\n"
        return text
    except:
        return ""

def process_and_index_file(file_id: int, file_content: bytes, content_type: str, user_id: int):
    """
    Production-grade file processing and indexing.
    
    Uses:
    - Advanced PDF parsing (PyMuPDF + pdfplumber)
    - Semantic chunking (LangChain)
    - Metadata enrichment
    """
    logger.info(f"Processing file {file_id} for user {user_id}")
    
    # 1. Extract Text with Advanced Parser
    text, doc_metadata = extract_text_from_file(file_content, content_type, file_id)
    
    if not text or not text.strip():
        logger.warning(f"No text extracted for file {file_id}")
        return

    # 2. Semantic Chunking
    base_metadata = {
        "file_id": file_id,
        "user_id": user_id,
        **doc_metadata
    }
    
    chunks = semantic_chunker.chunk_text(text, metadata=base_metadata)
    logger.info(f"Created {len(chunks)} semantic chunks for file {file_id}")
    
    if not chunks:
        logger.warning(f"No chunks created for file {file_id}")
        return
    
    # 3. Create Embeddings
    chunk_texts = [chunk["content"] for chunk in chunks]
    embeddings = embedding_model.encode(chunk_texts, show_progress_bar=False).tolist()
    
    # 4. Prepare Data for ChromaDB
    ids = [f"file_{file_id}_chunk_{i}" for i in range(len(chunks))]
    metadatas = [chunk["metadata"] for chunk in chunks]
    
    # 5. Add to ChromaDB
    try:
        collection = get_collection()
        collection.add(
            documents=chunk_texts,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
        logger.info(f"Successfully indexed file {file_id} with {len(chunks)} chunks")
    except Exception as e:
        logger.error(f"Failed to index file {file_id}: {str(e)}")
        raise

</code>

backend/app/rag/retrievers/reranker.py:
<code>
"""
Re-Ranking Module for Precision Improvement

Uses cross-encoder models to re-score and re-rank retrieved chunks.
Significantly improves relevance of top results.
"""

from sentence_transformers import CrossEncoder
from typing import List, Dict, Tuple
import logging

logger = logging.getLogger(__name__)


class ChunkReranker:
    """Production-grade re-ranking using cross-encoder models."""
    
    def __init__(self, model_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2'):
        """
        Initialize re-ranker with cross-encoder model.
        
        Args:
            model_name: HuggingFace model name for cross-encoder
        """
        try:
            self.model = CrossEncoder(model_name)
            self.logger = logger
            self.logger.info(f"Loaded cross-encoder model: {model_name}")
        except Exception as e:
            self.logger.error(f"Failed to load cross-encoder: {str(e)}")
            self.model = None
    
    def rerank(
        self,
        query: str,
        chunks: List[Dict],
        top_k: int = 3
    ) -> List[Dict]:
        """
        Re-rank chunks based on query relevance.
        
        Args:
            query: User query
            chunks: List of chunks from initial retrieval
            top_k: Number of top chunks to return
            
        Returns:
            Re-ranked and filtered chunks
        """
        if not self.model:
            self.logger.warning("Re-ranker not available, returning original chunks")
            return chunks[:top_k]
        
        if not chunks:
            return []
        
        try:
            # Prepare query-chunk pairs for cross-encoder
            pairs = [(query, chunk.get("content", "")) for chunk in chunks]
            
            # Get relevance scores
            scores = self.model.predict(pairs)
            
            # Combine chunks with scores
            scored_chunks = []
            for chunk, score in zip(chunks, scores):
                chunk_copy = chunk.copy()
                chunk_copy["rerank_score"] = float(score)
                scored_chunks.append(chunk_copy)
            
            # Sort by score (descending)
            scored_chunks.sort(key=lambda x: x["rerank_score"], reverse=True)
            
            # Return top-k
            top_chunks = scored_chunks[:top_k]
            
            self.logger.info(
                f"Re-ranked {len(chunks)} chunks, returning top {len(top_chunks)}"
            )
            
            return top_chunks
            
        except Exception as e:
            self.logger.error(f"Re-ranking failed: {str(e)}")
            return chunks[:top_k]
    
    def get_scores(self, query: str, texts: List[str]) -> List[float]:
        """
        Get relevance scores for query-text pairs.
        
        Args:
            query: User query
            texts: List of text snippets
            
        Returns:
            List of relevance scores
        """
        if not self.model:
            return [0.0] * len(texts)
        
        try:
            pairs = [(query, text) for text in texts]
            scores = self.model.predict(pairs)
            return [float(score) for score in scores]
        except Exception as e:
            self.logger.error(f"Scoring failed: {str(e)}")
            return [0.0] * len(texts)


# Singleton instance
reranker = ChunkReranker()

</code>

backend/app/rag/retrievers/hybrid.py:
<code>
import logging
from typing import List, Dict, Any, Optional
from rank_bm25 import BM25Okapi
from ..indexer import get_collection, embedding_model

logger = logging.getLogger(__name__)

class HybridRetriever:
    """
    Implements Hybrid Search (Vector + BM25) with Reciprocal Rank Fusion (RRF).
    
    Why: Vectors are great for semantics ("dog" ~= "puppy"), but bad at 
    exact keyword matching (e.g. acronyms "RAG vs DAG"). BM25 fixes this.
    """
    
    def __init__(self):
        self.bm25 = None
        self.bm25_corpus = []     # List of tokenized docs
        self.doc_map = {}         # Map index -> full document object
        self.is_initialized = False

    def _tokenize(self, text: str) -> List[str]:
        return text.lower().split()

    def build_index(self):
        """
        Builds/Rebuilds the in-memory BM25 index from all documents in ChromaDB.
        Note: In production, this should be an async task or use a persistent text index (Elastic/Postgres).
        For this scale, in-memory is fine.
        """
        try:
            logger.info("Building BM25 index...")
            collection = get_collection()
            
            # Fetch all documents
            results = collection.get()
            docs = results["documents"]
            metadatas = results["metadatas"]
            ids = results["ids"]
            
            if not docs:
                logger.warning("No documents found for BM25 index.")
                return

            self.bm25_corpus = []
            self.doc_map = {}
            
            for idx, (doc_text, meta, doc_id) in enumerate(zip(docs, metadatas, ids)):
                tokens = self._tokenize(doc_text)
                self.bm25_corpus.append(tokens)
                self.doc_map[idx] = {
                    "content": doc_text,
                    "metadata": meta,
                    "id": doc_id
                }
                
            self.bm25 = BM25Okapi(self.bm25_corpus)
            self.is_initialized = True
            logger.info(f"BM25 index built with {len(docs)} documents.")
            
        except Exception as e:
            logger.error(f"Failed to build BM25 index: {e}")

    def search_bm25(self, query: str, k: int = 5) -> List[Dict]:
        if not self.is_initialized:
            self.build_index()
            
        if not self.bm25:
             return []
             
        tokenized_query = self._tokenize(query)
        # Get raw scores
        scores = self.bm25.get_scores(tokenized_query)
        
        # Get top K indices
        top_n = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]
        
        results = []
        for idx in top_n:
            if scores[idx] > 0: # Filter zero matches
                doc = self.doc_map[idx].copy()
                doc["score"] = scores[idx]
                results.append(doc)
                
        return results

    def reciprocal_rank_fusion(self, vector_results: List[Dict], bm25_results: List[Dict], k: int = 60) -> List[Dict]:
        """
        Combine results using RRF.
        Score = 1 / (k + rank)
        """
        fused_scores = {}
        doc_store = {}
        
        # Helper to normalize access
        def process_list(results, prefix):
            for rank, doc in enumerate(results):
                # Unique ID is essential
                doc_id = doc.get("id") or doc.get("metadata", {}).get("file_id") # Simplify for now
                if not doc_id:
                     # If from semantic query, we might not have ID easily if not passed?
                     # Actually Chroma returns IDs. Let's ensure query_documents returns them.
                     pass 
                
                # Use content as key if ID not unique enough (e.g. chunks)
                # Actually, let's assume content+metadata['chunk_index'] unique key
                key = doc["content"][:50] # loose key
                
                if key not in doc_store:
                    doc_store[key] = doc
                
                if key not in fused_scores:
                    fused_scores[key] = 0.0
                
                # specific RRF formula
                fused_scores[key] += 1 / (k + rank + 1)

        process_list(vector_results, "vec")
        process_list(bm25_results, "bm25")
        
        # Sort by fused score
        reranked_keys = sorted(fused_scores, key=fused_scores.get, reverse=True)
        
        return [doc_store[key] for key in reranked_keys]

# Singleton
hybrid_retriever = HybridRetriever()

</code>

backend/app/rag/retrievers/__init__.py:
<code>
# retrievers package

</code>

backend/app/rag/parsers/pdf_parser.py:
<code>
"""
Advanced PDF Parser with Production-Grade Features

Features:
- Better text extraction with layout preservation
- Table detection and extraction
- Multi-column layout handling
- OCR fallback for scanned PDFs
- Metadata extraction
"""

import fitz  # PyMuPDF
import pdfplumber
from typing import Dict, List, Optional, Tuple
import logging

logger = logging.getLogger(__name__)


class AdvancedPDFParser:
    """Production-grade PDF parser with advanced extraction capabilities."""
    
    def __init__(self):
        self.logger = logger
    
    
    def extract_text_pymupdf(self, pdf_path: str) -> Tuple[str, Dict]:
        """
        Extract text using LlamaParse (if key exists) or PyMuPDF (fallback).
        """
        import os
        llama_key = os.getenv("LLAMA_CLOUD_API_KEY")
        
        # 1. Try LlamaParse for Research-Grade Math/Tables
        if llama_key:
            try:
                self.logger.info("Attempting LlamaParse extraction...")
                # Lazy import to avoid hard dependency if not used
                from llama_parse import LlamaParse
                
                parser = LlamaParse(
                    api_key=llama_key,
                    result_type="markdown",  # Crucial for math ($E=mc^2$)
                    verbose=True
                )
                
                # Verify file exists before sending
                if not os.path.exists(pdf_path):
                    raise FileNotFoundError(f"File not found: {pdf_path}")
                    
                documents = parser.load_data(pdf_path)
                
                if documents:
                    full_text = "\n\n".join([doc.text for doc in documents])
                    metadata = {
                        "title": "LlamaParse Document",
                        "total_pages": len(documents),
                        "source": "llama_parse"
                    }
                    self.logger.info(f"LlamaParse success: {len(full_text)} chars")
                    return full_text, metadata
                    
            except Exception as e:
                self.logger.error(f"LlamaParse failed: {e}. Falling back to PyMuPDF.")
                # Fall through to PyMuPDF
        
        # 2. PyMuPDF Fallback (Existing Logic)
        try:
            doc = fitz.open(pdf_path)
            
            # Extract metadata
            metadata = {
                "title": doc.metadata.get("title", ""),
                "author": doc.metadata.get("author", ""),
                "subject": doc.metadata.get("subject", ""),
                "total_pages": len(doc),
                "created": doc.metadata.get("creationDate", ""),
            }
            
            # Extract text with layout preservation
            full_text = []
            
            for page_num, page in enumerate(doc, start=1):
                # Get text blocks (preserves layout better)
                blocks = page.get_text("blocks")
                
                page_text = []
                for block in blocks:
                    # block[4] is the text content
                    if len(block) >= 5:
                        text = block[4].strip()
                        if text:
                            page_text.append(text)
                
                if page_text:
                    # Add page marker for context
                    full_text.append(f"\n--- Page {page_num} ---\n")
                    full_text.append("\n\n".join(page_text))
            
            doc.close()
            
            extracted_text = "\n".join(full_text)
            self.logger.info(f"Extracted {len(extracted_text)} characters from {metadata['total_pages']} pages")
            
            return extracted_text, metadata
            
        except Exception as e:
            self.logger.error(f"PyMuPDF extraction failed: {str(e)}")
            raise
    
    def extract_tables(self, pdf_path: str) -> List[Dict]:
        """
        Extract tables from PDF using pdfplumber.
        
        Returns:
            List of table dictionaries with page numbers
        """
        tables_found = []
        
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for page_num, page in enumerate(pdf.pages, start=1):
                    # Extract tables from this page
                    tables = page.extract_tables()
                    
                    for table_idx, table in enumerate(tables):
                        if table:
                            # Convert table to markdown-like format
                            table_text = self._table_to_text(table)
                            
                            tables_found.append({
                                "page": page_num,
                                "table_index": table_idx,
                                "content": table_text,
                                "rows": len(table),
                                "cols": len(table[0]) if table else 0
                            })
            
            self.logger.info(f"Extracted {len(tables_found)} tables")
            return tables_found
            
        except Exception as e:
            self.logger.warning(f"Table extraction failed: {str(e)}")
            return []
    
    def _table_to_text(self, table: List[List]) -> str:
        """Convert table data to readable text format."""
        if not table:
            return ""
        
        lines = []
        for row in table:
            # Clean and join cells
            cells = [str(cell).strip() if cell else "" for cell in row]
            lines.append(" | ".join(cells))
        
        return "\n".join(lines)
    
    def parse_pdf(self, pdf_path: str) -> Dict:
        """
        Main parsing function that combines all extraction methods.
        
        Returns:
            Dictionary with text, tables, and metadata
        """
        result = {
            "text": "",
            "tables": [],
            "metadata": {},
            "success": False
        }
        
        try:
            # 1. Extract main text with PyMuPDF
            text, metadata = self.extract_text_pymupdf(pdf_path)
            result["text"] = text
            result["metadata"] = metadata
            
            # 2. Extract tables separately
            tables = self.extract_tables(pdf_path)
            result["tables"] = tables
            
            # 3. Integrate tables into text if found
            if tables:
                table_sections = []
                for table in tables:
                    table_sections.append(
                        f"\n\n[Table from Page {table['page']}]\n{table['content']}\n"
                    )
                
                # Append tables to main text
                result["text"] += "\n\n" + "\n".join(table_sections)
            
            result["success"] = True
            self.logger.info(f"Successfully parsed PDF: {len(result['text'])} chars, {len(tables)} tables")
            
        except Exception as e:
            self.logger.error(f"PDF parsing failed: {str(e)}")
            result["error"] = str(e)
        
        return result


# Singleton instance
pdf_parser = AdvancedPDFParser()

</code>

backend/app/rag/parsers/chunker.py:
<code>
"""
Semantic Chunking with Context Preservation

Implements intelligent text splitting that:
- Preserves semantic boundaries
- Maintains document structure
- Adds rich metadata
- Optimizes chunk size for embeddings
"""

from langchain_text_splitters import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer, util
from typing import List, Dict, Optional
import logging
import re
import numpy as np

logger = logging.getLogger(__name__)

class SemanticChunker:
    """
    Production-grade Semantic Chunking.
    
    Splits text based on semantic similarity between sentences rather than 
    arbitrary character counts. Finds "natural breaks" in conversation/text.
    """
    
    def __init__(
        self,
        model_name: str = 'all-MiniLM-L6-v2',
        breakpoint_percentile_threshold: int = 95,
        buffer_size: int = 1
    ):
        """
        Args:
            model_name: Embedding model for semantic comparison
            breakpoint_percentile_threshold: Higher = fewer chunks (more strict splitting)
            buffer_size: Number of sentences to look ahead/behind for context
        """
        try:
            self.model = SentenceTransformer(model_name)
        except Exception as e:
            logger.error(f"Failed to load embedding model: {e}")
            self.model = None
            
        self.breakpoint_percentile_threshold = breakpoint_percentile_threshold
        self.buffer_size = buffer_size
        self.logger = logger
        
        # Fallback splitter
        self.fallback_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200
        )

    def _split_into_sentences(self, text: str) -> List[str]:
        # Simple robust sentence splitting
        # Look for periods, question marks, exclamations followed by space and capital letter
        sentences = re.split(r'(?<=[.?!])\s+(?=[A-Z])', text)
        return [s.strip() for s in sentences if s.strip()]

    def _combine_sentences(self, sentences: List[dict], buffer_size: int = 1) -> List[dict]:
        # Add window context to sentences for better embedding representation
        for i in range(len(sentences)):
            combined_text = ""
            # Add previous sentences
            for j in range(i - buffer_size, i):
                if j >= 0:
                    combined_text += sentences[j]['sentence'] + " "
            
            combined_text += sentences[i]['sentence']
            
            # Add next sentences
            for j in range(i + 1, i + 1 + buffer_size):
                if j < len(sentences):
                    combined_text += " " + sentences[j]['sentence']
            
            sentences[i]['combined_sentence'] = combined_text
        return sentences

    def chunk_text(self, text: str, metadata: Optional[Dict] = None) -> List[Dict]:
        """
        Chunk using semantic analysis.
        
        1. Split into sentences
        2. Embed sentences (with context buffer)
        3. Calculate cosine distances between adjacent sentences
        4. Split where distance is high (similarity is low)
        """
        if not text or not text.strip():
            return []
            
        # Fallback if model failed to load
        if not self.model:
            logger.warning("Semantic chunking model not loaded, using fallback.")
            chunks = self.fallback_splitter.split_text(text)
            return [{"content": c, "metadata": metadata or {}} for c in chunks]

        # 1. Split sentences
        single_sentences_list = self._split_into_sentences(text)
        if len(single_sentences_list) < 2:
             return [{"content": text, "metadata": metadata or {}}]
             
        sentences = [{'sentence': x, 'index': i} for i, x in enumerate(single_sentences_list)]
        
        # 2. Add Context Buffer & Embed
        sentences = self._combine_sentences(sentences, self.buffer_size)
        embeddings = self.model.encode([x['combined_sentence'] for x in sentences])
        
        # 3. Calculate Cosine Distances
        distances = []
        for i in range(len(embeddings) - 1):
            sim = util.pytorch_cos_sim(embeddings[i], embeddings[i+1]).item()
            distance = 1 - sim
            distances.append(distance)
            
        # 4. Determine Threshold
        # value at the Xth percentile (e.g. 95th percentile of distances = top 5% most different)
        # Any distance higher than this is a breakpoint.
        if not distances:
            breakpoint_distance_threshold = 0
        else:
            breakpoint_distance_threshold = np.percentile(distances, self.breakpoint_percentile_threshold)
            
        # 5. Group Chunks
        indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold]
        
        chunks = []
        start_index = 0
        
        # Iterate through breakpoints
        for index in indices_above_thresh:
            # The split happens AFTER the sentence at 'index'
            end_index = index + 1 # exclusive because list slicing is exclusive
            
            group = sentences[start_index:end_index]
            combined_text = " ".join([d['sentence'] for d in group])
            chunks.append(combined_text)
            start_index = end_index
            
        # Add the last chunk
        if start_index < len(sentences):
            group = sentences[start_index:]
            combined_text = " ".join([d['sentence'] for d in group])
            chunks.append(combined_text)
            
        # Format for return
        enriched_chunks = []
        total_chunks = len(chunks)
        
        for idx, chunk_text in enumerate(chunks):
            chunk_metadata = {
                "chunk_index": idx,
                "total_chunks": total_chunks,
                "chunk_method": "semantic",
                **(metadata or {})
            }
            enriched_chunks.append({
                "content": chunk_text,
                "metadata": chunk_metadata
            })
            
        logger.info(f"Semantic Chunking: {len(text)} chars -> {len(single_sentences_list)} sentences -> {total_chunks} chunks")
        return enriched_chunks

# ... (SemanticChunker class remains above)

class ParentChildChunker:
    """
    Implements 'Small-to-Big' Retrieval Strategy.
    
    1. Splits text into large 'Parent' chunks (e.g., 1024-2048 chars) for full context.
    2. Splits each Parent into small 'Child' chunks (e.g., 256-512 chars) for precise retrieval.
    3. Child chunks store the Parent's content in metadata.
    """
    
    def __init__(self, parent_chunk_size=1024, child_chunk_size=256, chunk_overlap=0):
        self.parent_splitter = RecursiveCharacterTextSplitter(
            chunk_size=parent_chunk_size, 
            chunk_overlap=chunk_overlap
        )
        self.child_splitter = RecursiveCharacterTextSplitter(
            chunk_size=child_chunk_size, 
            chunk_overlap=chunk_overlap
        )
        self.semantic_chunker = SemanticChunker() # Use semantic for finding good parents?
        
    def chunk_text(self, text: str, metadata: Optional[Dict] = None) -> List[Dict]:
        if not text or not text.strip():
            return []
            
        # 1. Create Parent Chunks (Legacy: fixed size, Future: Semantic Parents)
        # Using Semantic Chunker for Parents ensures parents are topic-coherent
        parents = self.semantic_chunker.chunk_text(text, metadata)
        
        all_children = []
        
        for p_idx, parent in enumerate(parents):
            parent_text = parent["content"]
            parent_meta = parent["metadata"]
            
            # 2. Create Child Chunks from this Parent
            children_texts = self.child_splitter.split_text(parent_text)
            
            for c_idx, child_text in enumerate(children_texts):
                # 3. Link Child to Parent
                child_meta = parent_meta.copy()
                child_meta.update({
                    "parent_content": parent_text,  # The "Big" chunk
                    "is_child": True,
                    "parent_index": p_idx,
                    "child_index": c_idx,
                    "chunk_method": "parent_child"
                })
                
                all_children.append({
                    "content": child_text, # The "Small" chunk (for vector search)
                    "metadata": child_meta
                })
        
        logger.info(f"Parent-Child Chunking: {len(parents)} parents -> {len(all_children)} children")
        return all_children

# Singleton instance (switched to Parent-Child as default for Research-Grade)
# You can swap this back to semantic_chunker if desired
semantic_chunker = ParentChildChunker()

</code>

backend/app/rag/parsers/__init__.py:
<code>
# parsers package

</code>

backend/app/storage/__init__.py:
<code>
# Storage package

</code>

backend/app/storage/minio_client.py:
<code>
from minio import Minio
from minio.error import S3Error
from ..config import settings
import io

class MinioClient:
    def __init__(self):
        self.client = Minio(
            settings.MINIO_ENDPOINT,
            access_key=settings.MINIO_ACCESS_KEY,
            secret_key=settings.MINIO_SECRET_KEY,
            secure=False  # Set to True for HTTPS
        )
        self.bucket_name = "ai-cloud-drive"
        self._create_bucket_if_not_exists()

    def _create_bucket_if_not_exists(self):
        if not self.client.bucket_exists(self.bucket_name):
            self.client.make_bucket(self.bucket_name)

    def upload_file(self, file_data, file_name, content_type, user_id):
        object_name = f"user_{user_id}/{file_name}"
        try:
            # Check if file_data is bytes or file-like
            if isinstance(file_data, bytes):
                data = io.BytesIO(file_data)
                length = len(file_data)
            else:
                data = file_data
                file_data.seek(0, 2)
                length = file_data.tell()
                file_data.seek(0)
            
            self.client.put_object(
                self.bucket_name,
                object_name,
                data,
                length,
                content_type=content_type
            )
            return object_name
        except S3Error as e:
            print(f"MinIO Upload Error: {e}")
            raise e

    def get_file_url(self, object_name):
        return self.client.presigned_get_object(self.bucket_name, object_name)

    def get_file_content(self, object_name):
        try:
            response = self.client.get_object(self.bucket_name, object_name)
            return response
        except S3Error as e:
             print(f"MinIO Download Error: {e}")
             raise e

    def delete_file(self, object_name):
        self.client.remove_object(self.bucket_name, object_name)

minio_client = MinioClient()

</code>

backend/app/routes/auth.py:
<code>
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from fastapi.security import OAuth2PasswordRequestForm
from datetime import datetime, timedelta
from .. import schemas, models, database, auth
from ..validators import validate_password_strength, validate_email_domain
from ..logging_config import logger
from pydantic import BaseModel

router = APIRouter(
    prefix="/auth",
    tags=["auth"]
)

@router.post("/register", response_model=schemas.User)
def register(user: schemas.UserCreate, db: Session = Depends(database.get_db)):
    # Validate password strength
    try:
        validate_password_strength(user.password)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # Check for disposable emails
    try:
        validate_email_domain(user.email)
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    
    # Check if email exists
    db_user = db.query(models.User).filter(models.User.email == user.email).first()
    if db_user:
        raise HTTPException(status_code=400, detail="Email already registered")
    
    hashed_password = auth.get_password_hash(user.password)
    
    # Create user with verification token if email verification is enabled
    from ..config import settings
    if settings.REQUIRE_EMAIL_VERIFICATION:
        import secrets
        verification_token = secrets.token_urlsafe(32)
        db_user = models.User(
            email=user.email,
            hashed_password=hashed_password,
            is_verified=False,
            verification_token=verification_token,
            verification_sent_at=datetime.utcnow()
        )
        
        # Send verification email
        from ..email.service import email_service
        verification_link = f"http://localhost:3000/verify-email?token={verification_token}"
        
        if settings.SMTP_USERNAME and settings.SMTP_PASSWORD:
            email_service.send_verification_email(user.email, verification_link)
            logger.info(f"Verification email sent to: {user.email}")
        else:
            logger.warning(f"Email not configured. Verification link: {verification_link}")
    else:
        # Auto-verify if email verification is disabled
        db_user = models.User(
            email=user.email,
            hashed_password=hashed_password,
            is_verified=True
        )
    
    db.add(db_user)
    db.commit()
    db.refresh(db_user)
    
    logger.info(f"New user registered: {user.email}")
    return db_user

@router.post("/login", response_model=schemas.Token)
def login(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(database.get_db)):
    user = db.query(models.User).filter(models.User.email == form_data.username).first()
    if not user or not auth.verify_password(form_data.password, user.hashed_password):
        logger.warning(f"Failed login attempt for: {form_data.username}")
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    if not user.is_active:
        raise HTTPException(status_code=400, detail="Account is deactivated")
    
    # Check email verification if required
    from ..config import settings
    if settings.REQUIRE_EMAIL_VERIFICATION and not user.is_verified:
        raise HTTPException(
            status_code=403, 
            detail="üìß Please verify your email first! Check your inbox for a verification link from Cloud Drive. Can't find it? Check spam folder or request a new link."
        )
    
    # Update last login
    user.last_login = datetime.utcnow()
    db.commit()

    access_token_expires = timedelta(minutes=auth.settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": user.email, "user_id": user.id}, 
        expires_delta=access_token_expires
    )
    
    logger.info(f"User logged in: {user.email}")
    return {"access_token": access_token, "token_type": "bearer"}

@router.get("/me", response_model=schemas.User)
def get_current_user_info(current_user: models.User = Depends(auth.get_current_user)):
    """Get current user information"""
    return current_user

# Admin Auth
class AdminLogin(BaseModel):
    username: str
    password: str

@router.post("/admin/login")
def admin_login(creds: AdminLogin):
    if creds.username != auth.settings.ADMIN_USERNAME or creds.password != auth.settings.ADMIN_PASSWORD:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect admin credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    # Create token with admin scope/flag (for now just a separate token key or subject prefix)
    access_token_expires = timedelta(minutes=auth.settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": f"admin:{creds.username}", "role": "admin"}, 
        expires_delta=access_token_expires
    )
    return {"access_token": access_token, "token_type": "bearer"}

# Email Verification
@router.get("/verify-email")
def verify_email(token: str, db: Session = Depends(database.get_db)):
    """Verify user email with token."""
    user = db.query(models.User).filter(
        models.User.verification_token == token
    ).first()
    
    if not user:
        raise HTTPException(status_code=400, detail="Invalid verification token")
    
    # Check token expiration (24 hours)
    from ..config import settings
    if user.verification_sent_at:
        expiry_hours = settings.VERIFICATION_TOKEN_EXPIRE_HOURS
        token_age = datetime.utcnow() - user.verification_sent_at
        if token_age.total_seconds() > expiry_hours * 3600:
            raise HTTPException(status_code=400, detail="Verification token expired")
    
    # Verify user
    user.is_verified = True
    user.verification_token = None
    user.verification_sent_at = None
    db.commit()
    
    logger.info(f"User verified: {user.email}")

    # Auto-login: Generate access token
    access_token_expires = timedelta(minutes=auth.settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": user.email, "user_id": user.id}, 
        expires_delta=access_token_expires
    )
    
    return {
        "message": "Email verified successfully!",
        "access_token": access_token, 
        "token_type": "bearer"
    }

@router.post("/resend-verification")
def resend_verification(email: str, db: Session = Depends(database.get_db)):
    """Resend verification email."""
    user = db.query(models.User).filter(models.User.email == email).first()
    
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    if user.is_verified:
        raise HTTPException(status_code=400, detail="Email already verified")
    
    # Generate new token
    import secrets
    user.verification_token = secrets.token_urlsafe(32)
    user.verification_sent_at = datetime.utcnow()
    db.commit()
    
    # Send email
    from ..email.service import email_service
    from ..config import settings
    verification_link = f"http://localhost:3000/verify-email?token={user.verification_token}"
    
    if settings.SMTP_USERNAME and settings.SMTP_PASSWORD:
        email_service.send_verification_email(email, verification_link)
        logger.info(f"Verification email resent to: {email}")
        return {"message": "Verification email sent!"}
    else:
        logger.warning(f"Email not configured. Verification link: {verification_link}")
        return {"message": "Email not configured", "link": verification_link}

@router.get("/me")
def read_users_me(current_user: models.User = Depends(auth.get_current_user), db: Session = Depends(database.get_db)):
    """Get current user profile."""
    # Count files efficiently
    file_count = db.query(models.File).filter(models.File.owner_id == current_user.id).count()
    
    return {
        "id": current_user.id,
        "email": current_user.email,
        "is_verified": current_user.is_verified,
        "created_at": current_user.created_at,
        "role": "admin" if current_user.id == 0 else "user",
        "file_count": file_count
    }

</code>

backend/app/routes/google_auth.py:
<code>
"""
Google OAuth Authentication Routes

Provides endpoints for Google Sign-In authentication.
"""

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import RedirectResponse
from pydantic import BaseModel
from sqlalchemy.orm import Session
from authlib.integrations.starlette_client import OAuth
from authlib.jose import jwt
from datetime import datetime, timedelta
import httpx

from .. import database, models, auth
from ..config import settings

router = APIRouter(prefix="/auth/google", tags=["google-auth"])

# Initialize OAuth
oauth = OAuth()
oauth.register(
    name='google',
    client_id=settings.GOOGLE_CLIENT_ID,
    client_secret=settings.GOOGLE_CLIENT_SECRET,
    server_metadata_url='https://accounts.google.com/.well-known/openid-configuration',
    client_kwargs={'scope': 'openid email profile'}
)


class GoogleAuthRequest(BaseModel):
    """Request model for Google credential verification."""
    credential: str  # Google JWT token


@router.get("/login")
async def google_login():
    """
    Initiate Google OAuth flow.
    Redirects user to Google sign-in page.
    """
    if not settings.GOOGLE_CLIENT_ID or not settings.GOOGLE_CLIENT_SECRET:
        raise HTTPException(
            status_code=500,
            detail="Google OAuth not configured. Please set GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET."
        )
    
    redirect_uri = settings.GOOGLE_REDIRECT_URI
    return await oauth.google.authorize_redirect(redirect_uri)


@router.get("/callback")
async def google_callback(code: str, db: Session = Depends(database.get_db)):
    """
    Handle OAuth callback from Google.
    Exchanges code for user info and creates/updates user.
    """
    try:
        # Exchange code for token
        token = await oauth.google.authorize_access_token(code=code)
        
        # Get user info from Google
        user_info = token.get('userinfo')
        if not user_info:
            raise HTTPException(status_code=400, detail="Failed to get user info from Google")
        
        # Extract user data
        google_id = user_info.get('sub')
        email = user_info.get('email')
        name = user_info.get('name')
        picture = user_info.get('picture')
        
        if not google_id or not email:
            raise HTTPException(status_code=400, detail="Invalid user data from Google")
        
        # Find or create user
        user = db.query(models.User).filter(models.User.google_id == google_id).first()
        
        if not user:
            # Check if user exists with this email (from old auth)
            user = db.query(models.User).filter(models.User.email == email).first()
            if user:
                # Link Google account to existing user
                user.google_id = google_id
                user.is_verified = True
            else:
                # Create new user
                user = models.User(
                    email=email,
                    google_id=google_id,
                    name=name,
                    is_verified=True,  # Auto-verified via Google
                    is_active=True
                )
                db.add(user)
        
        # Update user info
        if name and not user.name:
            user.name = name
        user.last_login = datetime.utcnow()
        
        db.commit()
        db.refresh(user)
        
        # Create access token
        access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
        access_token = auth.create_access_token(
            data={"sub": user.email},
            expires_delta=access_token_expires
        )
        
        # Redirect to frontend with token
        return RedirectResponse(
            url=f"http://localhost:3000?token={access_token}"
        )
        
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"OAuth failed: {str(e)}")


@router.post("/verify")
async def verify_google_token(
    request: GoogleAuthRequest,
    db: Session = Depends(database.get_db)
):
    """
    Verify Google JWT token (for frontend direct integration).
    This is used when using Google Sign-In JavaScript library.
    """
    try:
        # Verify the Google JWT token
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"https://oauth2.googleapis.com/tokeninfo?id_token={request.credential}"
            )
            
            if response.status_code != 200:
                raise HTTPException(status_code=401, detail="Invalid Google token")
            
            user_info = response.json()
            
            # Verify token is for our app
            if user_info.get('aud') != settings.GOOGLE_CLIENT_ID:
                raise HTTPException(status_code=401, detail="Token not for this application")
            
            # Extract user data
            google_id = user_info.get('sub')
            email = user_info.get('email')
            name = user_info.get('name')
            picture = user_info.get('picture')
            email_verified = user_info.get('email_verified', False)
            
            if not google_id or not email:
                raise HTTPException(status_code=400, detail="Invalid user data")
            
            # Find or create user
            user = db.query(models.User).filter(models.User.google_id == google_id).first()
            
            if not user:
                # Check if email exists
                user = db.query(models.User).filter(models.User.email == email).first()
                if user:
                    # Link Google account
                    user.google_id = google_id
                    user.is_verified = True
                else:
                    # Create new user
                    user = models.User(
                        email=email,
                        google_id=google_id,
                        name=name,
                        is_verified=True,
                        is_active=True
                    )
                    db.add(user)
            
            # Update info
            if name and not user.name:
                user.name = name
            user.last_login = datetime.utcnow()
            
            db.commit()
            db.refresh(user)
            
            # Create our access token
            access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
            access_token = auth.create_access_token(
                data={"sub": user.email},
                expires_delta=access_token_expires
            )
            
            return {
                "access_token": access_token,
                "token_type": "bearer",
                "user": {
                    "email": user.email,
                    "name": user.name
                }
            }
            
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Verification failed: {str(e)}")

</code>

backend/app/routes/files.py:
<code>
from fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File as FastAPIFile, Response
from fastapi.responses import StreamingResponse
from sqlalchemy.orm import Session
from typing import List
from .. import schemas, models, database, auth
from ..storage.minio_client import minio_client
from ..tasks.celery_app import process_file_task
import mimetypes

router = APIRouter(
    prefix="/api",
    tags=["files"]
)

@router.post("/upload", response_model=schemas.File)
async def upload_file(
    file: UploadFile = FastAPIFile(...),
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    # Permissions Check
    if not current_user.can_upload:
        raise HTTPException(status_code=403, detail="Uploads are disabled for your account")

    # Rate Limit: File Count
    MAX_FILES_COUNT = 50
    current_file_count = db.query(models.File).filter(models.File.owner_id == current_user.id).count()
    if current_file_count >= MAX_FILES_COUNT:
        raise HTTPException(status_code=400, detail=f"File limit reached ({MAX_FILES_COUNT} files). Please delete some files.")

    # Constants
    MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB
    ALLOWED_TYPES = ["application/pdf", "text/plain", "text/markdown", "text/x-markdown"]
    ALLOWED_EXTENSIONS = [".pdf", ".txt", ".md"]
    
    # Validate file extension
    file_ext = "." + file.filename.split(".")[-1].lower() if "." in file.filename else ""
    if file_ext not in ALLOWED_EXTENSIONS:
        raise HTTPException(status_code=400, detail=f"File type not allowed. Allowed: {', '.join(ALLOWED_EXTENSIONS)}")

    # Read file content
    file_content = await file.read()
    file_size = len(file_content)
    
    # Validate file size
    if file_size > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail=f"File too large. Maximum size: 50MB")
    
    if file_size == 0:
        raise HTTPException(status_code=400, detail="Cannot upload empty file")

    # Upload to MinIO
    try:
        object_name = minio_client.upload_file(
            file_data=file_content,
            file_name=file.filename,
            content_type=file.content_type,
            user_id=current_user.id
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to upload to storage: {str(e)}")

    # Save metadata to DB
    db_file = models.File(
        filename=file.filename,
        file_path=object_name,
        content_type=file.content_type,
        size=file_size,
        owner_id=current_user.id,
        is_indexed=False 
    )
    db.add(db_file)
    db.commit()
    db.refresh(db_file)

    # Trigger Async Task (Phase 5)
    process_file_task.delay(db_file.id, object_name, file.content_type, current_user.id)

    return db_file

@router.get("/files", response_model=List[schemas.File])
def get_files(
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    files = db.query(models.File).filter(models.File.owner_id == current_user.id).all()
    return files

@router.get("/download/{file_id}")
def download_file(
    file_id: int,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    # Admin can download any file, regular users can only download their own
    file = db.query(models.File).filter(models.File.id == file_id).first()
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    # Check if user is admin or file owner
    # Admin users have email format "admin:username"
    from ..config import settings
    is_admin = (
        current_user.email == settings.ADMIN_USERNAME or
        current_user.email == f"admin:{settings.ADMIN_USERNAME}" or
        current_user.email.startswith("admin:")
    )
    
    if not is_admin and file.owner_id != current_user.id:
        raise HTTPException(status_code=403, detail="Not authorized to download this file")


    try:
        response = minio_client.get_file_content(file.file_path)
        
        # Determine media type using standard library or fallback to application/octet-stream
        media_type = file.content_type or "application/octet-stream"
        
        return StreamingResponse(
            response, 
            media_type=media_type,
            headers={"Content-Disposition": f'attachment; filename="{file.filename}"'}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to download file: {str(e)}")

@router.delete("/delete/{file_id}")
def delete_file(
    file_id: int,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    file = db.query(models.File).filter(models.File.id == file_id, models.File.owner_id == current_user.id).first()
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    # Delete from MinIO
    try:
        minio_client.delete_file(file.file_path)
    except Exception as e:
        print(f"Warning: Failed to delete from MinIO: {e}")
        # Continue to delete from DB even if MinIO fails (orphaned check later?)
    
    # Delete from DB
    db.delete(file)
    db.commit()
    
    return {"message": "File deleted successfully"}

</code>

backend/app/routes/query.py:
<code>
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from .. import database, models, auth
from ..rag import engine
from ..rag.llm import generate_response

router = APIRouter(
    prefix="/api",
    tags=["query"]
)

class QueryRequest(BaseModel):
    query: str
    file_ids: Optional[List[int]] = None  # Optional list of file IDs to search

class QueryResponse(BaseModel):
    answer: str
    sources: List[Dict[str, Any]]
    contexts: List[str] # Added for audit
    metadata: Optional[Dict[str, Any]] = None # Added for latency

class EvaluateRequest(BaseModel):
    question: str
    answer: str
    contexts: List[str]

@router.post("/query", response_model=QueryResponse)
def query_documents(
    request: QueryRequest,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    import time
    start_time = time.time()
    
    try:
        if current_user.id == 0:
             pass # Mock admin handling if needed
             
        # 1. Retrieve relevant chunks
        t0 = time.time()
        results = engine.query_documents(
            request.query, 
            user_id=current_user.id,
            file_ids=request.file_ids
        )
        t_retrieval = time.time() - t0
        
        contexts = []
        if not results:
            answer = "I couldn't find any relevant information in your uploaded documents."
            sources = []
        else:
            # 2. Generate answer using LLM
            t1 = time.time()
            answer = generate_response(request.query, results)
            t_generation = time.time() - t1
            sources = results
            contexts = [res["content"] for res in results]
        
        # 3. Save to Chat History (Skip for admin/id=0 to avoid FK error)
        if current_user.id != 0:
            chat_entry = models.ChatHistory(
                user_id=current_user.id,
                query=request.query,
                answer=answer
            )
            db.add(chat_entry)
            db.commit()

        total_time = time.time() - start_time
        
        return {
            "answer": answer,
            "sources": sources,
            "contexts": contexts,
            "metadata": {
                "retrieval_time": t_retrieval if results else 0,
                "generation_time": t_generation if results else 0,
                "total_time": total_time
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Query failed: {str(e)}")

@router.post("/evaluate")
async def evaluate_response(req: EvaluateRequest):
    """
    Run RAGAS Faithfulness check on a specific Q&A pair.
    """
    try:
        import os
        from ragas import evaluate
        from ragas.metrics import faithfulness
        from datasets import Dataset
        from langchain_groq import ChatGroq
        
        api_key = os.getenv("GROQ_API_KEY")
        if not api_key:
            raise HTTPException(status_code=500, detail="GROQ_API_KEY not set")
            
        # 1. Configure LLM
        # Ragas needs an LLM to judge faithfulness
        llm = ChatGroq(model="llama3-70b-8192", api_key=api_key)
        
        # 2. Format data
        data = {
            'question': [req.question],
            'answer': [req.answer],
            'contexts': [req.contexts], 
            # Ground truth optional for faithfulness
        }
        dataset = Dataset.from_dict(data)
        
        # 3. Run Evaluation
        results = evaluate(
            dataset=dataset,
            metrics=[faithfulness],
            llm=llm
        )
        
        return {
            "faithfulness": results['faithfulness']
        }
        
    except Exception as e:
        print(f"Evaluation error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

</code>

backend/app/routes/profile.py:
<code>
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from sqlalchemy.orm import Session
from .. import database, models, schemas, auth
from ..storage import minio_client
import uuid
import io

router = APIRouter(
    prefix="/api/profile",
    tags=["profile"]
)

@router.get("", response_model=schemas.User)
def get_profile(current_user: models.User = Depends(auth.get_current_user)):
    """Get current user profile"""
    return current_user

@router.put("", response_model=schemas.User)
def update_profile(
    profile: schemas.ProfileUpdate,
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(database.get_db)
):
    """Update user profile name"""
    if profile.name is not None:
        current_user.name = profile.name
    
    db.commit()
    db.refresh(current_user)
    return current_user

@router.post("/photo")
async def upload_profile_photo(
    file: UploadFile = File(...),
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(database.get_db)
):
    """Upload user profile photo to MinIO"""
    # Validate file type
    if not file.content_type.startswith('image/'):
        raise HTTPException(status_code=400, detail="File must be an image")
    
    # Generate unique filename
    file_ext = file.filename.split('.')[-1] if '.' in file.filename else 'jpg'
    unique_filename = f"profiles/{current_user.id}/{uuid.uuid4()}.{file_ext}"
    
    try:
        # Delete old profile photo if exists
        if current_user.profile_photo:
            try:
                minio_client.remove_object("ai-drive", current_user.profile_photo)
            except:
                pass  # Ignore if old photo doesn't exist
        
        # Upload to MinIO
        file_content = await file.read()
        minio_client.put_object(
            "ai-drive",
            unique_filename,
            io.BytesIO(file_content),
            length=len(file_content),
            content_type=file.content_type
        )
        
        # Update user record
        current_user.profile_photo = unique_filename
        db.commit()
        
        return {"message": "Profile photo uploaded successfully", "photo_path": unique_filename}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

@router.delete("/photo")
def delete_profile_photo(
    current_user: models.User = Depends(auth.get_current_user),
    db: Session = Depends(database.get_db)
):
    """Delete user profile photo"""
    if not current_user.profile_photo:
        raise HTTPException(status_code=404, detail="No profile photo to delete")
    
    try:
        # Delete from MinIO
        minio_client.remove_object("ai-drive", current_user.profile_photo)
        
        # Update user record
        current_user.profile_photo = None
        db.commit()
        
        return {"message": "Profile photo deleted successfully"}
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Delete failed: {str(e)}")

@router.get("/photo/{user_id}")
def get_profile_photo(user_id: int, db: Session = Depends(database.get_db)):
    """Get profile photo URL for a user"""
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user or not user.profile_photo:
        raise HTTPException(status_code=404, detail="Profile photo not found")
    
    try:
        # Generate presigned URL (valid for 1 hour)
        url = minio_client.presigned_get_object("ai-drive", user.profile_photo, expires=3600)
        return {"photo_url": url}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get photo: {str(e)}")

</code>

backend/app/routes/__init__.py:
<code>
# Routes package

</code>

backend/app/routes/admin.py:
<code>

from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
from datetime import datetime, timedelta
from .. import database, models, schemas, auth
from pydantic import BaseModel

router = APIRouter(
    prefix="/api/admin",
    tags=["admin"],
    dependencies=[Depends(auth.get_admin_user)]
)

# Admin Schemas (Internal use for now)
class AdminUserStats(schemas.User):
    files_count: int
    queries_total: int
    queries_24h: int
    storage_used: int
    failed_queries: int
    last_login: datetime | None
    created_at: datetime | None
    can_upload: bool
    is_verified: bool

    class Config:
        from_attributes = True

class AuditLogView(BaseModel):
    id: int
    timestamp: datetime
    actor_email: str
    action: str
    target_id: int | None
    target_type: str | None
    metadata_json: str | None

    class Config:
        from_attributes = True

class AdminFileView(BaseModel):
    id: int
    filename: str
    size: int
    upload_date: datetime
    content_type: str | None
    owner_email: str

    class Config:
        from_attributes = True

class AdminChatView(BaseModel):
    id: int
    query: str
    answer: str | None
    timestamp: datetime
    user_email: str

    class Config:
        from_attributes = True

# --- Helpers ---
def log_audit(db: Session, actor_id: int, action: str, target_id: int = None, target_type: str = None, meta: dict = None):
    import json
    log = models.AuditLog(
        actor_id=actor_id,
        action=action,
        target_id=target_id,
        target_type=target_type,
        metadata_json=json.dumps(meta) if meta else None
    )
    db.add(log)
    db.commit()

# --- Endpoints ---

@router.get("/users", response_model=List[AdminUserStats])
def get_all_users(
    skip: int = 0, 
    limit: int = 100, 
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_admin_user)
):
    users = db.query(models.User).order_by(models.User.created_at.desc()).offset(skip).limit(limit).all()
    
    # Enrichment
    results = []
    now = datetime.utcnow()
    day_ago = now - timedelta(days=1)

    for u in users:
        u_dict = u.__dict__
        u_dict['files_count'] = len(u.files)
        u_dict['storage_used'] = sum(f.size for f in u.files)
        u_dict['queries_total'] = len(u.chats)
        # Inefficient loop for 24h, but ok for small scale. 
        # For production, use optimized SQL query.
        u_dict['queries_24h'] = sum(1 for c in u.chats if c.timestamp > day_ago)
        u_dict['failed_queries'] = sum(1 for c in u.chats if c.answer and c.answer.startswith("Error"))
        results.append(u_dict)
        
    return results

@router.get("/files", response_model=List[AdminFileView])
def get_all_files(
    skip: int = 0, 
    limit: int = 100, 
    db: Session = Depends(database.get_db)
):
    files = db.query(models.File).order_by(models.File.upload_date.desc()).offset(skip).limit(limit).all()
    
    results = []
    for f in files:
        results.append({
            "id": f.id,
            "filename": f.filename,
            "size": f.size,
            "upload_date": f.upload_date,
            "content_type": f.content_type,
            "owner_email": f.owner.email if f.owner else "Unknown"
        })
    return results

@router.get("/chats", response_model=List[AdminChatView])
def get_all_chats(
    skip: int = 0, 
    limit: int = 100, 
    db: Session = Depends(database.get_db)
):
    chats = db.query(models.ChatHistory).order_by(models.ChatHistory.timestamp.desc()).offset(skip).limit(limit).all()
    
    results = []
    for c in chats:
        results.append({
            "id": c.id,
            "query": c.query,
            "answer": c.answer,
            "timestamp": c.timestamp,
            "user_email": c.user.email if c.user else "Unknown"
        })
    return results

@router.delete("/users/{user_id}")
def delete_user(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    from ..storage.minio_client import minio_client
    
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    user_email = user.email  # Save for audit log
    deleted_files_count = 0
    
    try:
        # 1. Delete user's files from MinIO and database
        user_files = db.query(models.File).filter(models.File.owner_id == user_id).all()
        for file in user_files:
            try:
                # Delete from MinIO storage
                if file.file_path:
                    minio_client.delete_file(file.file_path)
            except Exception as e:
                print(f"Warning: Could not delete file from MinIO: {file.file_path} - {e}")
            # Delete file record from DB
            db.delete(file)
            deleted_files_count += 1
        
        # 2. Delete user's chat history
        db.query(models.ChatHistory).filter(models.ChatHistory.user_id == user_id).delete()
        
        # 3. Delete the user
        db.delete(user)
        db.commit()
        
        # Log the action
        log_audit(db, admin.id, "delete_user", user_id, "user", {
            "email": user_email, 
            "files_deleted": deleted_files_count
        })
        
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=400, detail=f"Cannot delete user: {str(e)}")
        
    return {"message": f"User deleted along with {deleted_files_count} files"}

@router.post("/users/{user_id}/verify")
def verify_user_manually(user_id: int, db: Session = Depends(database.get_db)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user:
        raise HTTPException(status_code=404, detail="User not found")
    
    user.is_verified = True
    user.verification_token = None
    db.commit()
    log_audit(db, None, "verify_user", user.id, "user", {"email": user.email}) # Actor ID None (or fetch current user)
    return {"message": f"User {user.email} manually verified"}

@router.post("/users/{user_id}/suspend")
def suspend_user(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.is_active = False
    db.commit()
    log_audit(db, admin.id, "suspend_user", user.id, "user", {"email": user.email})
    return {"message": "User suspended"}

@router.post("/users/{user_id}/unsuspend")
def unsuspend_user(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.is_active = True
    db.commit()
    log_audit(db, admin.id, "unsuspend_user", user.id, "user", {"email": user.email})
    return {"message": "User unsuspended"}

@router.post("/users/{user_id}/disable-upload")
def disable_upload(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.can_upload = False
    db.commit()
    log_audit(db, admin.id, "disable_upload", user.id, "user", {"email": user.email})
    return {"message": "Uploads disabled for user"}

@router.post("/users/{user_id}/enable-upload")
def enable_upload(user_id: int, db: Session = Depends(database.get_db), admin: models.User = Depends(auth.get_admin_user)):
    user = db.query(models.User).filter(models.User.id == user_id).first()
    if not user: raise HTTPException(404, "User not found")
    user.can_upload = True
    db.commit()
    log_audit(db, admin.id, "enable_upload", user.id, "user", {"email": user.email})
    return {"message": "Uploads enabled for user"}

@router.get("/audit-logs", response_model=List[AuditLogView])
def get_audit_logs(skip: int = 0, limit: int = 50, db: Session = Depends(database.get_db)):
    logs = db.query(models.AuditLog).order_by(models.AuditLog.timestamp.desc()).offset(skip).limit(limit).all()
    results = []
    for log in logs:
        results.append({
            "id": log.id,
            "timestamp": log.timestamp,
            "actor_email": log.actor.email if log.actor else "System",
            "action": log.action,
            "target_id": log.target_id,
            "target_type": log.target_type,
            "metadata_json": log.metadata_json
        })
    return results

</code>

backend/app/routes/magic_auth.py:
<code>
"""
Magic Link (Passwordless) Authentication Routes

Provides endpoints for passwordless email-based authentication.
Users receive a secure login link via email.
"""

from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.responses import RedirectResponse
from pydantic import BaseModel, EmailStr
from sqlalchemy.orm import Session
from datetime import datetime, timedelta
import secrets
import logging

from .. import database, models, auth
from ..config import settings
from ..email.service import email_service

router = APIRouter(prefix="/auth/magic-link", tags=["magic-link-auth"])
logger = logging.getLogger(__name__)


class MagicLinkRequest(BaseModel):
    """Request model for magic link generation."""
    email: EmailStr


@router.post("/request")
async def request_magic_link(
    request: MagicLinkRequest,
    db: Session = Depends(database.get_db)
):
    """
    Request a magic link for passwordless login.
    Creates account if doesn't exist.
    """
    email = request.email.lower()
    
    # Find or create user
    user = db.query(models.User).filter(models.User.email == email).first()
    
    if not user:
        # Create new user (passwordless)
        user = models.User(
            email=email,
            is_verified=True,  # Auto-verified via magic link
            is_active=True
        )
        db.add(user)
    
    # Generate secure token
    token = secrets.token_urlsafe(32)
    expires = datetime.utcnow() + timedelta(minutes=15)
    
    # Store token
    user.magic_link_token = token
    user.magic_link_expires = expires
    
    db.commit()
    
    # Generate magic link URL
    # For development, use localhost; for production, use actual domain
    base_url = "http://localhost:3000"  # TODO: Make configurable
    magic_link = f"{base_url}/auth/magic-link/verify?token={token}"
    
    # Send email or log to console
    if settings.SMTP_USERNAME and settings.SMTP_PASSWORD:
        # Send real email
        success = email_service.send_magic_link_email(email, magic_link)
        if not success:
            logger.error(f"Failed to send magic link to {email}")
            # Still return success but log link for development
            logger.info(f"Magic link for {email}: {magic_link}")
    else:
        # Development mode: log to console
        logger.info(f"\n{'='*60}")
        logger.info(f"MAGIC LINK for {email}:")
        logger.info(f"{magic_link}")
        logger.info(f"Expires: {expires}")
        logger.info(f"{'='*60}\n")
    
    return {
        "success": True,
        "message": "Magic link sent! Check your email.",
        "email": email,
        # Include link in response for development (remove in production)
        "magic_link": magic_link if not (settings.SMTP_USERNAME and settings.SMTP_PASSWORD) else None
    }


@router.get("/verify")
async def verify_magic_link(
    token: str,
    db: Session = Depends(database.get_db)
):
    """
    Verify magic link token and log user in.
    Single-use token that expires after 15 minutes.
    """
    # Find user with this token
    user = db.query(models.User).filter(
        models.User.magic_link_token == token
    ).first()
    
    if not user:
        raise HTTPException(
            status_code=400,
            detail="Invalid or expired magic link"
        )
    
    # Check expiration
    if not user.magic_link_expires or user.magic_link_expires < datetime.utcnow():
        # Clear expired token
        user.magic_link_token = None
        user.magic_link_expires = None
        db.commit()
        
        raise HTTPException(
            status_code=400,
            detail="Magic link has expired. Please request a new one."
        )
    
    # Valid token - log user in
    # Clear token (single-use)
    user.magic_link_token = None
    user.magic_link_expires = None
    user.last_login = datetime.utcnow()
    user.is_verified = True
    
    db.commit()
    db.refresh(user)
    
    # Create access token
    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = auth.create_access_token(
        data={"sub": user.email},
        expires_delta=access_token_expires
    )
    
    # Redirect to frontend with token
    return RedirectResponse(
        url=f"/?token={access_token}&email={user.email}"
    )

</code>

backend/app/routes/share.py:
<code>
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from pydantic import BaseModel
from typing import Optional
import secrets
from .. import models, database, auth
from ..storage.minio_client import minio_client
from fastapi.responses import StreamingResponse

router = APIRouter(
    prefix="/api",
    tags=["share"]
)

class ShareRequest(BaseModel):
    file_id: int
    
class ShareResponse(BaseModel):
    share_url: str
    share_token: str

@router.post("/share", response_model=ShareResponse)
def create_share_link(
    request: ShareRequest,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    """Create a public share link for a file"""
    file = db.query(models.File).filter(
        models.File.id == request.file_id,
        models.File.owner_id == current_user.id
    ).first()
    
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    # Generate or return existing token
    if not file.share_token:
        file.share_token = secrets.token_urlsafe(16)
        db.commit()
    
    return {
        "share_url": f"/api/shared/{file.share_token}",
        "share_token": file.share_token
    }

@router.delete("/share/{file_id}")
def revoke_share_link(
    file_id: int,
    db: Session = Depends(database.get_db),
    current_user: models.User = Depends(auth.get_current_user)
):
    """Revoke a share link"""
    file = db.query(models.File).filter(
        models.File.id == file_id,
        models.File.owner_id == current_user.id
    ).first()
    
    if not file:
        raise HTTPException(status_code=404, detail="File not found")
    
    file.share_token = None
    db.commit()
    
    return {"message": "Share link revoked"}

@router.get("/shared/{share_token}")
def download_shared_file(
    share_token: str,
    db: Session = Depends(database.get_db)
):
    """Download a file via share link (no auth required)"""
    file = db.query(models.File).filter(
        models.File.share_token == share_token
    ).first()
    
    if not file:
        raise HTTPException(status_code=404, detail="Shared file not found or link expired")
    
    try:
        response = minio_client.get_file_content(file.file_path)
        media_type = file.content_type or "application/octet-stream"
        
        return StreamingResponse(
            response,
            media_type=media_type,
            headers={"Content-Disposition": f'attachment; filename="{file.filename}"'}
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to download: {str(e)}")

</code>

backend/app/email/service.py:
<code>
"""
Email Service for sending verification and notification emails.

Uses SMTP to send emails. Supports multiple providers (Gmail, SendGrid, etc.)
"""

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import Optional
import logging
from ..config import settings

logger = logging.getLogger(__name__)


class EmailService:
    """Handles email sending operations."""
    
    def __init__(self):
        self.smtp_server = settings.SMTP_SERVER
        self.smtp_port = settings.SMTP_PORT
        self.username = settings.SMTP_USERNAME
        self.password = settings.SMTP_PASSWORD
        self.from_email = settings.EMAIL_FROM
    
    def send_email(
        self,
        to_email: str,
        subject: str,
        html_content: str,
        text_content: Optional[str] = None
    ) -> bool:
        """
        Send an email.
        
        Args:
            to_email: Recipient email address
            subject: Email subject
            html_content: HTML email body
            text_content: Plain text fallback (optional)
            
        Returns:
            True if sent successfully, False otherwise
        """
        try:
            # Create message
            msg = MIMEMultipart('alternative')
            msg['Subject'] = subject
            msg['From'] = self.from_email
            msg['To'] = to_email
            
            # Add text and HTML parts
            if text_content:
                text_part = MIMEText(text_content, 'plain')
                msg.attach(text_part)
            
            html_part = MIMEText(html_content, 'html')
            msg.attach(html_part)
            
            # Send email
            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
                server.starttls()
                server.login(self.username, self.password)
                server.send_message(msg)
            
            logger.info(f"Email sent successfully to {to_email}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to send email to {to_email}: {str(e)}")
            return False
    
    def send_verification_email(self, to_email: str, verification_link: str) -> bool:
        """Send email verification link."""
        subject = "Verify Your Email - Cloud Drive"
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <body style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;">
            <div style="background: #f5f5f5; padding: 20px; border-radius: 8px;">
                <h2 style="color: #333;">Welcome to Cloud Drive!</h2>
                <p style="color: #666; line-height: 1.6;">
                    Thank you for signing up. Please verify your email address to activate your account.
                </p>
                <div style="margin: 30px 0;">
                    <a href="{verification_link}" 
                       style="background: #4285f4; color: white; padding: 12px 30px; 
                              text-decoration: none; border-radius: 4px; display: inline-block;">
                        Verify Email Address
                    </a>
                </div>
                <p style="color: #999; font-size: 14px;">
                    Or copy and paste this link into your browser:<br>
                    <span style="color: #4285f4;">{verification_link}</span>
                </p>
                <p style="color: #999; font-size: 12px; margin-top: 30px;">
                    This link will expire in 24 hours. If you didn't create an account, 
                    you can safely ignore this email.
                </p>
            </div>
        </body>
        </html>
        """
        
        text_content = f"""
        Welcome to Cloud Drive!
        
        Please verify your email address by clicking the link below:
        {verification_link}
        
        This link will expire in 24 hours.
        
        If you didn't create an account, you can safely ignore this email.
        """
        
        return self.send_email(to_email, subject, html_content, text_content)
    
    def send_lockout_notification(self, to_email: str, locked_until: str) -> bool:
        """Send account lockout notification."""
        subject = "Account Locked - Cloud Drive"
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <body style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;">
            <div style="background: #fff3cd; padding: 20px; border-radius: 8px; border-left: 4px solid #ffc107;">
                <h2 style="color: #856404;">Account Temporarily Locked</h2>
                <p style="color: #856404; line-height: 1.6;">
                    Your account has been temporarily locked due to multiple failed login attempts.
                </p>
                <p style="color: #856404;">
                    <strong>Locked until:</strong> {locked_until}
                </p>
                <p style="color: #856404; font-size: 14px; margin-top: 20px;">
                    If this wasn't you, please reset your password immediately.
                </p>
            </div>
        </body>
        </html>
        """
        
        return self.send_email(to_email, subject, html_content)
    
    def send_magic_link_email(self, to_email: str, magic_link: str) -> bool:
        """Send magic link for passwordless login."""
        subject = "Sign in to Cloud Drive"
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <body style="font-family: Arial, sans-serif; max-width: 600px; margin: 0 auto; padding: 20px;">
            <div style="background: #f5f5f5; padding: 30px; border-radius: 8px;">
                <h2 style="color: #333;">Sign in to Cloud Drive</h2>
                <p style="color: #666; font-size: 16px; line-height: 1.6;">
                    Click the button below to securely sign in to your account.
                </p>
                <div style="margin: 30px 0;">
                    <a href="{magic_link}" 
                       style="background: #4285f4; color: white; padding: 14px 40px; 
                              text-decoration: none; border-radius: 4px; 
                              display: inline-block; font-size: 16px; font-weight: 500;">
                        Sign In to Cloud Drive
                    </a>
                </div>
                <p style="color: #999; font-size: 14px;">
                    This link will expire in 15 minutes.<br>
                    If you didn't request this, you can safely ignore this email.
                </p>
                <p style="color: #999; font-size: 12px; margin-top: 30px; word-break: break-all;">
                    Or copy and paste this link into your browser:<br>
                    <span style="color: #4285f4;">{magic_link}</span>
                </p>
            </div>
        </body>
        </html>
        """
        
        text_content = f"""
        Sign in to Cloud Drive
        
        Click the link below to sign in:
        {magic_link}
        
        This link will expire in 15 minutes.
        
        If you didn't request this, you can safely ignore this email.
        """
        
        return self.send_email(to_email, subject, html_content, text_content)


# Singleton instance
email_service = EmailService()

</code>

backend/app/email/__init__.py:
<code>
# email package

</code>

